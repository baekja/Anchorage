{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 6732871558718221900\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 9128091648\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 1914379731163613099\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib   # 이는 나중에 GPU를 사용하고자 할때 필요함.\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.1'"
      ]
     },
     "execution_count": 702,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No.</th>\n",
       "      <th>Author</th>\n",
       "      <th>Year</th>\n",
       "      <th>Test type</th>\n",
       "      <th>Remark</th>\n",
       "      <th>Specimen</th>\n",
       "      <th>fy</th>\n",
       "      <th>Ld</th>\n",
       "      <th>fcm</th>\n",
       "      <th>db</th>\n",
       "      <th>...</th>\n",
       "      <th>cos,avg</th>\n",
       "      <th>cth</th>\n",
       "      <th>ch</th>\n",
       "      <th>Nh</th>\n",
       "      <th>Bottom cover</th>\n",
       "      <th>Ah/Ab</th>\n",
       "      <th>Fsu at La, test</th>\n",
       "      <th>dtr</th>\n",
       "      <th>Ntr</th>\n",
       "      <th>st</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Wright</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stub-beam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1-TH01-P-NS-2DB-292</td>\n",
       "      <td>517.500000</td>\n",
       "      <td>12.70</td>\n",
       "      <td>28.460000</td>\n",
       "      <td>25.4</td>\n",
       "      <td>...</td>\n",
       "      <td>101.80</td>\n",
       "      <td>305.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.47</td>\n",
       "      <td>9.395954</td>\n",
       "      <td>376.153911</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Wright</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stub-beam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1-TH02-P-NS-2DB-292</td>\n",
       "      <td>517.500000</td>\n",
       "      <td>12.70</td>\n",
       "      <td>28.460000</td>\n",
       "      <td>25.4</td>\n",
       "      <td>...</td>\n",
       "      <td>101.80</td>\n",
       "      <td>305.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.39</td>\n",
       "      <td>9.395954</td>\n",
       "      <td>388.271356</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Wright</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stub-beam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1-TH03-P-NS-2DB-292</td>\n",
       "      <td>517.500000</td>\n",
       "      <td>12.70</td>\n",
       "      <td>28.460000</td>\n",
       "      <td>25.4</td>\n",
       "      <td>...</td>\n",
       "      <td>101.80</td>\n",
       "      <td>305.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.12</td>\n",
       "      <td>9.395954</td>\n",
       "      <td>364.470642</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Wright</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stub-beam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2-TH04-NP-3S1-208-19</td>\n",
       "      <td>517.500000</td>\n",
       "      <td>285.75</td>\n",
       "      <td>33.630000</td>\n",
       "      <td>25.4</td>\n",
       "      <td>...</td>\n",
       "      <td>101.80</td>\n",
       "      <td>305.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.96</td>\n",
       "      <td>9.395954</td>\n",
       "      <td>482.092746</td>\n",
       "      <td>9.500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Wright</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stub-beam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2-TH05-NP-3S1-208-19</td>\n",
       "      <td>517.500000</td>\n",
       "      <td>285.75</td>\n",
       "      <td>33.630000</td>\n",
       "      <td>25.4</td>\n",
       "      <td>...</td>\n",
       "      <td>101.80</td>\n",
       "      <td>305.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.80</td>\n",
       "      <td>9.395954</td>\n",
       "      <td>462.692993</td>\n",
       "      <td>9.500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Shao</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pullout</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8-5-F4.1-4#5-6</td>\n",
       "      <td>889.655172</td>\n",
       "      <td>154.94</td>\n",
       "      <td>35.724138</td>\n",
       "      <td>25.4</td>\n",
       "      <td>...</td>\n",
       "      <td>769.62</td>\n",
       "      <td>769.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>457.241379</td>\n",
       "      <td>15.875</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Shao</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pullout</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8-5-F4.1-4#5-6</td>\n",
       "      <td>889.655172</td>\n",
       "      <td>172.72</td>\n",
       "      <td>37.655172</td>\n",
       "      <td>25.4</td>\n",
       "      <td>...</td>\n",
       "      <td>769.62</td>\n",
       "      <td>769.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>466.896552</td>\n",
       "      <td>15.875</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Shao</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pullout</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8-5-F4.1-6#5-6</td>\n",
       "      <td>889.655172</td>\n",
       "      <td>160.02</td>\n",
       "      <td>37.655172</td>\n",
       "      <td>25.4</td>\n",
       "      <td>...</td>\n",
       "      <td>774.70</td>\n",
       "      <td>774.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>412.413793</td>\n",
       "      <td>15.875</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Shao</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pullout</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8-5-F4.1-6#5-6</td>\n",
       "      <td>889.655172</td>\n",
       "      <td>167.64</td>\n",
       "      <td>37.655172</td>\n",
       "      <td>25.4</td>\n",
       "      <td>...</td>\n",
       "      <td>762.00</td>\n",
       "      <td>762.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>488.275862</td>\n",
       "      <td>15.875</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Shao</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pullout</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8-5-F4.1-6#5-6</td>\n",
       "      <td>889.655172</td>\n",
       "      <td>175.26</td>\n",
       "      <td>37.655172</td>\n",
       "      <td>25.4</td>\n",
       "      <td>...</td>\n",
       "      <td>769.62</td>\n",
       "      <td>769.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>459.310345</td>\n",
       "      <td>15.875</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>478 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     No.  Author  Year  Test type Remark              Specimen          fy  \\\n",
       "0    1.0  Wright   NaN  Stub-beam    NaN   1-TH01-P-NS-2DB-292  517.500000   \n",
       "1    2.0  Wright   NaN  Stub-beam    NaN   1-TH02-P-NS-2DB-292  517.500000   \n",
       "2    3.0  Wright   NaN  Stub-beam    NaN   1-TH03-P-NS-2DB-292  517.500000   \n",
       "3    4.0  Wright   NaN  Stub-beam    NaN  2-TH04-NP-3S1-208-19  517.500000   \n",
       "4    5.0  Wright   NaN  Stub-beam    NaN  2-TH05-NP-3S1-208-19  517.500000   \n",
       "..   ...     ...   ...        ...    ...                   ...         ...   \n",
       "473  NaN    Shao   NaN    Pullout    NaN        8-5-F4.1-4#5-6  889.655172   \n",
       "474  NaN    Shao   NaN    Pullout    NaN        8-5-F4.1-4#5-6  889.655172   \n",
       "475  NaN    Shao   NaN    Pullout    NaN        8-5-F4.1-6#5-6  889.655172   \n",
       "476  NaN    Shao   NaN    Pullout    NaN        8-5-F4.1-6#5-6  889.655172   \n",
       "477  NaN    Shao   NaN    Pullout    NaN        8-5-F4.1-6#5-6  889.655172   \n",
       "\n",
       "         Ld        fcm    db  ...  cos,avg     cth   ch   Nh  Bottom cover  \\\n",
       "0     12.70  28.460000  25.4  ...   101.80  305.00  0.0  1.0         45.47   \n",
       "1     12.70  28.460000  25.4  ...   101.80  305.00  0.0  1.0         45.39   \n",
       "2     12.70  28.460000  25.4  ...   101.80  305.00  0.0  1.0         47.12   \n",
       "3    285.75  33.630000  25.4  ...   101.80  305.00  0.0  1.0         47.96   \n",
       "4    285.75  33.630000  25.4  ...   101.80  305.00  0.0  1.0         50.80   \n",
       "..      ...        ...   ...  ...      ...     ...  ...  ...           ...   \n",
       "473  154.94  35.724138  25.4  ...   769.62  769.62  NaN  1.0           NaN   \n",
       "474  172.72  37.655172  25.4  ...   769.62  769.62  NaN  1.0           NaN   \n",
       "475  160.02  37.655172  25.4  ...   774.70  774.70  NaN  1.0           NaN   \n",
       "476  167.64  37.655172  25.4  ...   762.00  762.00  NaN  1.0           NaN   \n",
       "477  175.26  37.655172  25.4  ...   769.62  769.62  NaN  1.0           NaN   \n",
       "\n",
       "        Ah/Ab  Fsu at La, test     dtr  Ntr     st  \n",
       "0    9.395954       376.153911   0.000  0.0   12.7  \n",
       "1    9.395954       388.271356   0.000  0.0   12.7  \n",
       "2    9.395954       364.470642   0.000  0.0   12.7  \n",
       "3    9.395954       482.092746   9.500  3.0  127.0  \n",
       "4    9.395954       462.692993   9.500  3.0  127.0  \n",
       "..        ...              ...     ...  ...    ...  \n",
       "473  5.100000       457.241379  15.875  2.0   25.4  \n",
       "474  5.100000       466.896552  15.875  2.0   25.4  \n",
       "475  5.100000       412.413793  15.875  3.0   25.4  \n",
       "476  5.100000       488.275862  15.875  3.0   25.4  \n",
       "477  5.100000       459.310345  15.875  3.0   25.4  \n",
       "\n",
       "[478 rows x 21 columns]"
      ]
     },
     "execution_count": 703,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel(\"../01. 데이터/Data for headed bars_for DataFrame_220725.xlsx\", skiprows = 17)\n",
    "df = pd.DataFrame(df, columns = [\"No.\", \"Author\", \"Year\", \"Test type\", \"Remark\", \"Specimen\", \"fy\", \"Ld\", \"fcm\", \"db\", \"b\", \"cos,avg\",\n",
    "                                 \"cth\", \"ch\", \"Nh\", \"Bottom cover\", \"Ah/Ab\", \"Fsu at La, test\", \"dtr\", \"Ntr\", \"st\"]) # st 제거시\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"Test type\"] == \"Joint type\"]  # 실험방법이 Joint type일 경우: 성능이 크게 개선됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_Fsu =  df[\"Fsu at La, test\"]\n",
    "#df[\"Fsu at La, test\"] = np.log1p(df[\"Fsu at La, test\"]) # 스케일링을 한다면 굳이 로그 함수를 사용하지 않아도 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134           NaN\n",
       "135           NaN\n",
       "136           NaN\n",
       "137    119.721038\n",
       "138           NaN\n",
       "          ...    \n",
       "426    837.931034\n",
       "427    568.965517\n",
       "428    607.586207\n",
       "429    626.206897\n",
       "430    675.862069\n",
       "Name: Fsu at La, test, Length: 297, dtype: float64"
      ]
     },
     "execution_count": 706,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y= df[\"Fsu at La, test\"]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 297 entries, 134 to 430\n",
      "Data columns (total 21 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   No.              297 non-null    float64\n",
      " 1   Author           297 non-null    object \n",
      " 2   Year             297 non-null    float64\n",
      " 3   Test type        297 non-null    object \n",
      " 4   Remark           202 non-null    object \n",
      " 5   Specimen         297 non-null    object \n",
      " 6   fy               297 non-null    float64\n",
      " 7   Ld               297 non-null    float64\n",
      " 8   fcm              297 non-null    float64\n",
      " 9   db               297 non-null    float64\n",
      " 10  b                297 non-null    float64\n",
      " 11  cos,avg          297 non-null    float64\n",
      " 12  cth              297 non-null    float64\n",
      " 13  ch               297 non-null    float64\n",
      " 14  Nh               297 non-null    float64\n",
      " 15  Bottom cover     293 non-null    float64\n",
      " 16  Ah/Ab            297 non-null    float64\n",
      " 17  Fsu at La, test  274 non-null    float64\n",
      " 18  dtr              297 non-null    float64\n",
      " 19  Ntr              297 non-null    float64\n",
      " 20  st               297 non-null    float64\n",
      "dtypes: float64(17), object(4)\n",
      "memory usage: 51.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()   # dtr, Ntr 데이터가 상대적으로 모자라니, 이 둘을 feature에서 제거함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint type    297\n",
      "Name: Test type, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fy</th>\n",
       "      <th>Ld</th>\n",
       "      <th>fcm</th>\n",
       "      <th>db</th>\n",
       "      <th>b</th>\n",
       "      <th>cos,avg</th>\n",
       "      <th>cth</th>\n",
       "      <th>ch</th>\n",
       "      <th>Nh</th>\n",
       "      <th>Bottom cover</th>\n",
       "      <th>Ah/Ab</th>\n",
       "      <th>st</th>\n",
       "      <th>Test_type_Joint type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>447.700000</td>\n",
       "      <td>888.000</td>\n",
       "      <td>24.200000</td>\n",
       "      <td>57.300</td>\n",
       "      <td>350.00</td>\n",
       "      <td>146.35</td>\n",
       "      <td>50.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>853.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>888.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>447.700000</td>\n",
       "      <td>684.000</td>\n",
       "      <td>24.200000</td>\n",
       "      <td>57.300</td>\n",
       "      <td>350.00</td>\n",
       "      <td>146.35</td>\n",
       "      <td>254.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>853.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>684.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>447.700000</td>\n",
       "      <td>684.000</td>\n",
       "      <td>24.200000</td>\n",
       "      <td>57.300</td>\n",
       "      <td>350.00</td>\n",
       "      <td>146.35</td>\n",
       "      <td>254.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>853.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>684.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>447.700000</td>\n",
       "      <td>479.000</td>\n",
       "      <td>24.200000</td>\n",
       "      <td>57.300</td>\n",
       "      <td>350.00</td>\n",
       "      <td>146.35</td>\n",
       "      <td>459.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>853.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>479.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>450.600000</td>\n",
       "      <td>372.000</td>\n",
       "      <td>24.600000</td>\n",
       "      <td>35.800</td>\n",
       "      <td>220.00</td>\n",
       "      <td>92.10</td>\n",
       "      <td>50.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>369.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>372.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>931.034483</td>\n",
       "      <td>485.902</td>\n",
       "      <td>43.586207</td>\n",
       "      <td>35.814</td>\n",
       "      <td>563.88</td>\n",
       "      <td>71.12</td>\n",
       "      <td>86.36</td>\n",
       "      <td>350.012</td>\n",
       "      <td>2.0</td>\n",
       "      <td>508.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>101.600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>799.310345</td>\n",
       "      <td>495.300</td>\n",
       "      <td>37.448276</td>\n",
       "      <td>35.814</td>\n",
       "      <td>558.80</td>\n",
       "      <td>71.12</td>\n",
       "      <td>93.98</td>\n",
       "      <td>154.559</td>\n",
       "      <td>3.0</td>\n",
       "      <td>508.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>495.300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>931.034483</td>\n",
       "      <td>489.966</td>\n",
       "      <td>43.586207</td>\n",
       "      <td>35.814</td>\n",
       "      <td>556.26</td>\n",
       "      <td>71.12</td>\n",
       "      <td>87.63</td>\n",
       "      <td>153.289</td>\n",
       "      <td>3.0</td>\n",
       "      <td>508.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>489.966</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>799.310345</td>\n",
       "      <td>492.252</td>\n",
       "      <td>37.448276</td>\n",
       "      <td>35.814</td>\n",
       "      <td>553.72</td>\n",
       "      <td>64.77</td>\n",
       "      <td>96.52</td>\n",
       "      <td>158.369</td>\n",
       "      <td>3.0</td>\n",
       "      <td>508.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>101.600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>931.034483</td>\n",
       "      <td>488.950</td>\n",
       "      <td>43.586207</td>\n",
       "      <td>35.814</td>\n",
       "      <td>553.72</td>\n",
       "      <td>68.58</td>\n",
       "      <td>86.36</td>\n",
       "      <td>154.559</td>\n",
       "      <td>3.0</td>\n",
       "      <td>508.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>101.600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>297 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             fy       Ld        fcm      db       b  cos,avg     cth       ch  \\\n",
       "134  447.700000  888.000  24.200000  57.300  350.00   146.35   50.00    0.000   \n",
       "135  447.700000  684.000  24.200000  57.300  350.00   146.35  254.00    0.000   \n",
       "136  447.700000  684.000  24.200000  57.300  350.00   146.35  254.00    0.000   \n",
       "137  447.700000  479.000  24.200000  57.300  350.00   146.35  459.00    0.000   \n",
       "138  450.600000  372.000  24.600000  35.800  220.00    92.10   50.00    0.000   \n",
       "..          ...      ...        ...     ...     ...      ...     ...      ...   \n",
       "426  931.034483  485.902  43.586207  35.814  563.88    71.12   86.36  350.012   \n",
       "427  799.310345  495.300  37.448276  35.814  558.80    71.12   93.98  154.559   \n",
       "428  931.034483  489.966  43.586207  35.814  556.26    71.12   87.63  153.289   \n",
       "429  799.310345  492.252  37.448276  35.814  553.72    64.77   96.52  158.369   \n",
       "430  931.034483  488.950  43.586207  35.814  553.72    68.58   86.36  154.559   \n",
       "\n",
       "      Nh  Bottom cover  Ah/Ab       st  Test_type_Joint type  \n",
       "134  1.0         853.0    5.0  888.000                     1  \n",
       "135  1.0         853.0    5.0  684.000                     1  \n",
       "136  1.0         853.0    5.0  684.000                     1  \n",
       "137  1.0         853.0    5.0  479.000                     1  \n",
       "138  1.0         369.0    5.0  372.000                     1  \n",
       "..   ...           ...    ...      ...                   ...  \n",
       "426  2.0         508.0    6.5  101.600                     1  \n",
       "427  3.0         508.0    5.5  495.300                     1  \n",
       "428  3.0         508.0    6.5  489.966                     1  \n",
       "429  3.0         508.0    5.5  101.600                     1  \n",
       "430  3.0         508.0    6.5  101.600                     1  \n",
       "\n",
       "[297 rows x 13 columns]"
      ]
     },
     "execution_count": 708,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X = df[[\"fy\", \"Ld\", \"fcm\", \"db\", \"b\", \"cos,avg\", \"cth\", \"ch\", \"Nh\", \"Bottom cover\", \"Ah/Ab\", \"dtr\", \"Ntr\", \"st\"]] # 최대변수 사용\n",
    "#X = df[[\"fy\", \"Ld\", \"fcm\", \"db\", \"b\", \"cos,avg\", \"cth\", \"ch\", \"Nh\", \"Bottom cover\", \"Ah/Ab\", \"st\"]] # 누락값 많은 변수 미사용\n",
    "# Test type - One-hot encoding\n",
    "X = df[[\"Test type\", \"fy\", \"Ld\", \"fcm\", \"db\", \"b\", \"cos,avg\", \"cth\", \"ch\", \"Nh\", \"Bottom cover\", \"Ah/Ab\", \"st\"]] # 범주형 데이터: Test type 포함\n",
    "print(X[\"Test type\"].value_counts()) # 범주 갯수 확인\n",
    "X = pd.get_dummies(data = X, columns = [\"Test type\"], prefix = \"Test_type\") # One-hot Endcoding 실행 -> (0, 0, 0, 1, 0), (1, 0, 0, 0, 0), ...\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137    119.721038\n",
       "141    118.787276\n",
       "145    112.745098\n",
       "146    312.500000\n",
       "147    417.000000\n",
       "          ...    \n",
       "426    837.931034\n",
       "427    568.965517\n",
       "428    607.586207\n",
       "429    626.206897\n",
       "430    675.862069\n",
       "Name: Fsu at La, test, Length: 274, dtype: float64"
      ]
     },
     "execution_count": 709,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2 = y[~y.isnull()]\n",
    "y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fy</th>\n",
       "      <th>Ld</th>\n",
       "      <th>fcm</th>\n",
       "      <th>db</th>\n",
       "      <th>b</th>\n",
       "      <th>cos,avg</th>\n",
       "      <th>cth</th>\n",
       "      <th>ch</th>\n",
       "      <th>Nh</th>\n",
       "      <th>Bottom cover</th>\n",
       "      <th>Ah/Ab</th>\n",
       "      <th>st</th>\n",
       "      <th>Test_type_Joint type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>447.700000</td>\n",
       "      <td>479.000</td>\n",
       "      <td>24.200000</td>\n",
       "      <td>57.300</td>\n",
       "      <td>350.00</td>\n",
       "      <td>146.35</td>\n",
       "      <td>459.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>853.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>479.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>450.600000</td>\n",
       "      <td>217.000</td>\n",
       "      <td>24.600000</td>\n",
       "      <td>35.800</td>\n",
       "      <td>220.00</td>\n",
       "      <td>92.10</td>\n",
       "      <td>205.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>369.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>217.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>454.800000</td>\n",
       "      <td>161.000</td>\n",
       "      <td>25.100000</td>\n",
       "      <td>25.400</td>\n",
       "      <td>160.00</td>\n",
       "      <td>67.30</td>\n",
       "      <td>153.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>278.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>161.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>606.000000</td>\n",
       "      <td>301.000</td>\n",
       "      <td>47.900000</td>\n",
       "      <td>43.000</td>\n",
       "      <td>541.80</td>\n",
       "      <td>43.00</td>\n",
       "      <td>56.00</td>\n",
       "      <td>369.800</td>\n",
       "      <td>2.0</td>\n",
       "      <td>138.166667</td>\n",
       "      <td>5.0</td>\n",
       "      <td>301.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>606.000000</td>\n",
       "      <td>301.000</td>\n",
       "      <td>47.900000</td>\n",
       "      <td>43.000</td>\n",
       "      <td>541.80</td>\n",
       "      <td>43.00</td>\n",
       "      <td>56.00</td>\n",
       "      <td>369.800</td>\n",
       "      <td>2.0</td>\n",
       "      <td>138.166667</td>\n",
       "      <td>5.0</td>\n",
       "      <td>370.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>931.034483</td>\n",
       "      <td>485.902</td>\n",
       "      <td>43.586207</td>\n",
       "      <td>35.814</td>\n",
       "      <td>563.88</td>\n",
       "      <td>71.12</td>\n",
       "      <td>86.36</td>\n",
       "      <td>350.012</td>\n",
       "      <td>2.0</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>6.5</td>\n",
       "      <td>101.600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>799.310345</td>\n",
       "      <td>495.300</td>\n",
       "      <td>37.448276</td>\n",
       "      <td>35.814</td>\n",
       "      <td>558.80</td>\n",
       "      <td>71.12</td>\n",
       "      <td>93.98</td>\n",
       "      <td>154.559</td>\n",
       "      <td>3.0</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>5.5</td>\n",
       "      <td>495.300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>931.034483</td>\n",
       "      <td>489.966</td>\n",
       "      <td>43.586207</td>\n",
       "      <td>35.814</td>\n",
       "      <td>556.26</td>\n",
       "      <td>71.12</td>\n",
       "      <td>87.63</td>\n",
       "      <td>153.289</td>\n",
       "      <td>3.0</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>6.5</td>\n",
       "      <td>489.966</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>799.310345</td>\n",
       "      <td>492.252</td>\n",
       "      <td>37.448276</td>\n",
       "      <td>35.814</td>\n",
       "      <td>553.72</td>\n",
       "      <td>64.77</td>\n",
       "      <td>96.52</td>\n",
       "      <td>158.369</td>\n",
       "      <td>3.0</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>5.5</td>\n",
       "      <td>101.600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>931.034483</td>\n",
       "      <td>488.950</td>\n",
       "      <td>43.586207</td>\n",
       "      <td>35.814</td>\n",
       "      <td>553.72</td>\n",
       "      <td>68.58</td>\n",
       "      <td>86.36</td>\n",
       "      <td>154.559</td>\n",
       "      <td>3.0</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>6.5</td>\n",
       "      <td>101.600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>274 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             fy       Ld        fcm      db       b  cos,avg     cth       ch  \\\n",
       "137  447.700000  479.000  24.200000  57.300  350.00   146.35  459.00    0.000   \n",
       "141  450.600000  217.000  24.600000  35.800  220.00    92.10  205.00    0.000   \n",
       "145  454.800000  161.000  25.100000  25.400  160.00    67.30  153.00    0.000   \n",
       "146  606.000000  301.000  47.900000  43.000  541.80    43.00   56.00  369.800   \n",
       "147  606.000000  301.000  47.900000  43.000  541.80    43.00   56.00  369.800   \n",
       "..          ...      ...        ...     ...     ...      ...     ...      ...   \n",
       "426  931.034483  485.902  43.586207  35.814  563.88    71.12   86.36  350.012   \n",
       "427  799.310345  495.300  37.448276  35.814  558.80    71.12   93.98  154.559   \n",
       "428  931.034483  489.966  43.586207  35.814  556.26    71.12   87.63  153.289   \n",
       "429  799.310345  492.252  37.448276  35.814  553.72    64.77   96.52  158.369   \n",
       "430  931.034483  488.950  43.586207  35.814  553.72    68.58   86.36  154.559   \n",
       "\n",
       "      Nh  Bottom cover  Ah/Ab       st  Test_type_Joint type  \n",
       "137  1.0    853.000000    5.0  479.000                     1  \n",
       "141  1.0    369.000000    5.0  217.000                     1  \n",
       "145  1.0    278.000000    5.0  161.000                     1  \n",
       "146  2.0    138.166667    5.0  301.000                     1  \n",
       "147  2.0    138.166667    5.0  370.000                     1  \n",
       "..   ...           ...    ...      ...                   ...  \n",
       "426  2.0    508.000000    6.5  101.600                     1  \n",
       "427  3.0    508.000000    5.5  495.300                     1  \n",
       "428  3.0    508.000000    6.5  489.966                     1  \n",
       "429  3.0    508.000000    5.5  101.600                     1  \n",
       "430  3.0    508.000000    6.5  101.600                     1  \n",
       "\n",
       "[274 rows x 13 columns]"
      ]
     },
     "execution_count": 710,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X[~y.isnull()]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baekjw\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fy</th>\n",
       "      <th>Ld</th>\n",
       "      <th>fcm</th>\n",
       "      <th>db</th>\n",
       "      <th>b</th>\n",
       "      <th>cos,avg</th>\n",
       "      <th>cth</th>\n",
       "      <th>ch</th>\n",
       "      <th>Nh</th>\n",
       "      <th>Bottom cover</th>\n",
       "      <th>Ah/Ab</th>\n",
       "      <th>st</th>\n",
       "      <th>Test_type_Joint type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>447.700000</td>\n",
       "      <td>479.000</td>\n",
       "      <td>24.200000</td>\n",
       "      <td>57.300</td>\n",
       "      <td>350.00</td>\n",
       "      <td>146.35</td>\n",
       "      <td>459.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>853.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>479.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>450.600000</td>\n",
       "      <td>217.000</td>\n",
       "      <td>24.600000</td>\n",
       "      <td>35.800</td>\n",
       "      <td>220.00</td>\n",
       "      <td>92.10</td>\n",
       "      <td>205.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>369.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>217.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>454.800000</td>\n",
       "      <td>161.000</td>\n",
       "      <td>25.100000</td>\n",
       "      <td>25.400</td>\n",
       "      <td>160.00</td>\n",
       "      <td>67.30</td>\n",
       "      <td>153.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>278.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>161.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>606.000000</td>\n",
       "      <td>301.000</td>\n",
       "      <td>47.900000</td>\n",
       "      <td>43.000</td>\n",
       "      <td>541.80</td>\n",
       "      <td>43.00</td>\n",
       "      <td>56.00</td>\n",
       "      <td>369.800</td>\n",
       "      <td>2.0</td>\n",
       "      <td>138.166667</td>\n",
       "      <td>5.0</td>\n",
       "      <td>301.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>606.000000</td>\n",
       "      <td>301.000</td>\n",
       "      <td>47.900000</td>\n",
       "      <td>43.000</td>\n",
       "      <td>541.80</td>\n",
       "      <td>43.00</td>\n",
       "      <td>56.00</td>\n",
       "      <td>369.800</td>\n",
       "      <td>2.0</td>\n",
       "      <td>138.166667</td>\n",
       "      <td>5.0</td>\n",
       "      <td>370.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>931.034483</td>\n",
       "      <td>485.902</td>\n",
       "      <td>43.586207</td>\n",
       "      <td>35.814</td>\n",
       "      <td>563.88</td>\n",
       "      <td>71.12</td>\n",
       "      <td>86.36</td>\n",
       "      <td>350.012</td>\n",
       "      <td>2.0</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>6.5</td>\n",
       "      <td>101.600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>799.310345</td>\n",
       "      <td>495.300</td>\n",
       "      <td>37.448276</td>\n",
       "      <td>35.814</td>\n",
       "      <td>558.80</td>\n",
       "      <td>71.12</td>\n",
       "      <td>93.98</td>\n",
       "      <td>154.559</td>\n",
       "      <td>3.0</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>5.5</td>\n",
       "      <td>495.300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>931.034483</td>\n",
       "      <td>489.966</td>\n",
       "      <td>43.586207</td>\n",
       "      <td>35.814</td>\n",
       "      <td>556.26</td>\n",
       "      <td>71.12</td>\n",
       "      <td>87.63</td>\n",
       "      <td>153.289</td>\n",
       "      <td>3.0</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>6.5</td>\n",
       "      <td>489.966</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>799.310345</td>\n",
       "      <td>492.252</td>\n",
       "      <td>37.448276</td>\n",
       "      <td>35.814</td>\n",
       "      <td>553.72</td>\n",
       "      <td>64.77</td>\n",
       "      <td>96.52</td>\n",
       "      <td>158.369</td>\n",
       "      <td>3.0</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>5.5</td>\n",
       "      <td>101.600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>931.034483</td>\n",
       "      <td>488.950</td>\n",
       "      <td>43.586207</td>\n",
       "      <td>35.814</td>\n",
       "      <td>553.72</td>\n",
       "      <td>68.58</td>\n",
       "      <td>86.36</td>\n",
       "      <td>154.559</td>\n",
       "      <td>3.0</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>6.5</td>\n",
       "      <td>101.600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>270 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             fy       Ld        fcm      db       b  cos,avg     cth       ch  \\\n",
       "137  447.700000  479.000  24.200000  57.300  350.00   146.35  459.00    0.000   \n",
       "141  450.600000  217.000  24.600000  35.800  220.00    92.10  205.00    0.000   \n",
       "145  454.800000  161.000  25.100000  25.400  160.00    67.30  153.00    0.000   \n",
       "146  606.000000  301.000  47.900000  43.000  541.80    43.00   56.00  369.800   \n",
       "147  606.000000  301.000  47.900000  43.000  541.80    43.00   56.00  369.800   \n",
       "..          ...      ...        ...     ...     ...      ...     ...      ...   \n",
       "426  931.034483  485.902  43.586207  35.814  563.88    71.12   86.36  350.012   \n",
       "427  799.310345  495.300  37.448276  35.814  558.80    71.12   93.98  154.559   \n",
       "428  931.034483  489.966  43.586207  35.814  556.26    71.12   87.63  153.289   \n",
       "429  799.310345  492.252  37.448276  35.814  553.72    64.77   96.52  158.369   \n",
       "430  931.034483  488.950  43.586207  35.814  553.72    68.58   86.36  154.559   \n",
       "\n",
       "      Nh  Bottom cover  Ah/Ab       st  Test_type_Joint type  \n",
       "137  1.0    853.000000    5.0  479.000                     1  \n",
       "141  1.0    369.000000    5.0  217.000                     1  \n",
       "145  1.0    278.000000    5.0  161.000                     1  \n",
       "146  2.0    138.166667    5.0  301.000                     1  \n",
       "147  2.0    138.166667    5.0  370.000                     1  \n",
       "..   ...           ...    ...      ...                   ...  \n",
       "426  2.0    508.000000    6.5  101.600                     1  \n",
       "427  3.0    508.000000    5.5  495.300                     1  \n",
       "428  3.0    508.000000    6.5  489.966                     1  \n",
       "429  3.0    508.000000    5.5  101.600                     1  \n",
       "430  3.0    508.000000    6.5  101.600                     1  \n",
       "\n",
       "[270 rows x 13 columns]"
      ]
     },
     "execution_count": 711,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X.fillna(0, inplace = True)   # 빈 데이터를을 모두 0으로 채우는 것은 잘못된 결과를 주어서 위험합니다. 차라리 다음과 같이 데이터를 없애는 게 낫습니다.\n",
    "X.dropna(inplace = True)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137    119.721038\n",
       "141    118.787276\n",
       "145    112.745098\n",
       "146    312.500000\n",
       "147    417.000000\n",
       "          ...    \n",
       "426    837.931034\n",
       "427    568.965517\n",
       "428    607.586207\n",
       "429    626.206897\n",
       "430    675.862069\n",
       "Name: Fsu at La, test, Length: 270, dtype: float64"
      ]
     },
     "execution_count": 712,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2 = y2[X.index] # 목표값도 X와 동일하게 indexing\n",
    "y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [],
   "source": [
    "##학습과 실험 데이터를 분류하고 train과 valid 데이터를 분류한뒤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, Valid, Test Set으로 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Train + Valid : Test  = 0.9 : 0.1 --> 먼저 9:1로 나누고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((243, 13), (27, 13), (243,), (27,))"
      ]
     },
     "execution_count": 716,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y2, test_size=0.10, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Train : Valid = 8: 2  --> 9중 20%를 valid로 가져옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((194, 13), (49, 13), (194,), (49,))"
      ]
     },
     "execution_count": 718,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.20,random_state=42)\n",
    "\n",
    "X_train.shape, X_valid.shape, y_train.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "## X변수들을 MinMaxScaler로 스케일링을 진행하였습니다.\n",
    "## --> Y도 스케일링 하여야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train))\n",
    "print(type(X_valid))\n",
    "print(type(X_test))\n",
    "print(type(y_train))\n",
    "print(type(y_valid))\n",
    "print(type(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scX = MinMaxScaler()                    # X의 scaler 정의\n",
    "X_train_scaled = scX.fit_transform(X_train)    \n",
    "X_valid_scaled = scX.transform(X_valid)\n",
    "X_test_scaled = scX.transform(X_test)\n",
    "\n",
    "scY = MinMaxScaler()                    # y의 scaler 정의\n",
    "y_train_scaled = scY.fit_transform(y_train.values.reshape(-1,1)) # y_train.values.reshape(-1,1) 는 Pandas Series를 조작하여 차원조절\n",
    "y_valid_scaled = scY.transform(y_valid.values.reshape(-1,1))\n",
    "y_test_scaled = scY.transform(y_test.values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [],
   "source": [
    "##층을 여기서 더 추가하거나 하여도 오히려 성능이 더 떨어지는 결과가 나옵니다.\n",
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model  --> 일단 현재 네트워크 사용: 최종 네트워크는 실험을 통해 결정(성능 vs 비용 비교하여 효율적인 방향으로 설정)\n",
    "model_1 = tf.keras.Sequential([\n",
    "           tf.keras.layers.Dense(500, activation='relu'),\n",
    "           tf.keras.layers.Dense(250, activation='relu'),\n",
    "           tf.keras.layers.Dense(10, activation='relu'),\n",
    "           tf.keras.layers.Dense(100, activation='relu'),\n",
    "           tf.keras.layers.Dense(50, activation='sigmoid'), \n",
    "           tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Comile the model\n",
    "model_1.compile(loss=tf.keras.losses.mae,\n",
    "                 optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                 metrics=['MAE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.2076 - MAE: 0.2076 - val_loss: 0.1705 - val_MAE: 0.1705\n",
      "Epoch 2/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.1925 - MAE: 0.1925 - val_loss: 0.1622 - val_MAE: 0.1622\n",
      "Epoch 3/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.1821 - MAE: 0.1821 - val_loss: 0.1574 - val_MAE: 0.1574\n",
      "Epoch 4/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.1761 - MAE: 0.1761 - val_loss: 0.1564 - val_MAE: 0.1564\n",
      "Epoch 5/1000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.1715 - MAE: 0.1715 - val_loss: 0.1592 - val_MAE: 0.1592\n",
      "Epoch 6/1000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.1696 - MAE: 0.1696 - val_loss: 0.1615 - val_MAE: 0.1615\n",
      "Epoch 7/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1689 - MAE: 0.1689 - val_loss: 0.1630 - val_MAE: 0.1630\n",
      "Epoch 8/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1687 - MAE: 0.1687 - val_loss: 0.1631 - val_MAE: 0.1631\n",
      "Epoch 9/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1678 - MAE: 0.1678 - val_loss: 0.1628 - val_MAE: 0.1628\n",
      "Epoch 10/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1661 - MAE: 0.1661 - val_loss: 0.1594 - val_MAE: 0.1594\n",
      "Epoch 11/1000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.1633 - MAE: 0.1633 - val_loss: 0.1556 - val_MAE: 0.1556\n",
      "Epoch 12/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1616 - MAE: 0.1616 - val_loss: 0.1541 - val_MAE: 0.1541\n",
      "Epoch 13/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1600 - MAE: 0.1600 - val_loss: 0.1529 - val_MAE: 0.1529\n",
      "Epoch 14/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1586 - MAE: 0.1586 - val_loss: 0.1515 - val_MAE: 0.1515\n",
      "Epoch 15/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1571 - MAE: 0.1571 - val_loss: 0.1526 - val_MAE: 0.1526\n",
      "Epoch 16/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1549 - MAE: 0.1549 - val_loss: 0.1497 - val_MAE: 0.1497\n",
      "Epoch 17/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1522 - MAE: 0.1522 - val_loss: 0.1460 - val_MAE: 0.1460\n",
      "Epoch 18/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1502 - MAE: 0.1502 - val_loss: 0.1415 - val_MAE: 0.1415\n",
      "Epoch 19/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1500 - MAE: 0.1500 - val_loss: 0.1395 - val_MAE: 0.1395\n",
      "Epoch 20/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1460 - MAE: 0.1460 - val_loss: 0.1396 - val_MAE: 0.1396\n",
      "Epoch 21/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1444 - MAE: 0.1444 - val_loss: 0.1480 - val_MAE: 0.1480\n",
      "Epoch 22/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1447 - MAE: 0.1447 - val_loss: 0.1467 - val_MAE: 0.1467\n",
      "Epoch 23/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1409 - MAE: 0.1409 - val_loss: 0.1376 - val_MAE: 0.1376\n",
      "Epoch 24/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1371 - MAE: 0.1371 - val_loss: 0.1347 - val_MAE: 0.1347\n",
      "Epoch 25/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1356 - MAE: 0.1356 - val_loss: 0.1356 - val_MAE: 0.1356\n",
      "Epoch 26/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1336 - MAE: 0.1336 - val_loss: 0.1364 - val_MAE: 0.1364\n",
      "Epoch 27/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1307 - MAE: 0.1307 - val_loss: 0.1327 - val_MAE: 0.1327\n",
      "Epoch 28/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1285 - MAE: 0.1285 - val_loss: 0.1309 - val_MAE: 0.1309\n",
      "Epoch 29/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1270 - MAE: 0.1270 - val_loss: 0.1329 - val_MAE: 0.1329\n",
      "Epoch 30/1000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.1261 - MAE: 0.1261 - val_loss: 0.1260 - val_MAE: 0.1260\n",
      "Epoch 31/1000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.1249 - MAE: 0.1249 - val_loss: 0.1250 - val_MAE: 0.1250\n",
      "Epoch 32/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1225 - MAE: 0.1225 - val_loss: 0.1251 - val_MAE: 0.1251\n",
      "Epoch 33/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1192 - MAE: 0.1192 - val_loss: 0.1276 - val_MAE: 0.1276\n",
      "Epoch 34/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1183 - MAE: 0.1183 - val_loss: 0.1236 - val_MAE: 0.1236\n",
      "Epoch 35/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1184 - MAE: 0.1184 - val_loss: 0.1177 - val_MAE: 0.1177\n",
      "Epoch 36/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1161 - MAE: 0.1161 - val_loss: 0.1184 - val_MAE: 0.1184\n",
      "Epoch 37/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1121 - MAE: 0.1121 - val_loss: 0.1180 - val_MAE: 0.1180\n",
      "Epoch 38/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1094 - MAE: 0.1094 - val_loss: 0.1174 - val_MAE: 0.1174\n",
      "Epoch 39/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1075 - MAE: 0.1075 - val_loss: 0.1120 - val_MAE: 0.1120\n",
      "Epoch 40/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1122 - MAE: 0.1122 - val_loss: 0.1084 - val_MAE: 0.1084\n",
      "Epoch 41/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1069 - MAE: 0.1069 - val_loss: 0.1234 - val_MAE: 0.1234\n",
      "Epoch 42/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1109 - MAE: 0.1109 - val_loss: 0.1220 - val_MAE: 0.1220\n",
      "Epoch 43/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1034 - MAE: 0.1034 - val_loss: 0.1076 - val_MAE: 0.1076\n",
      "Epoch 44/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0994 - MAE: 0.0994 - val_loss: 0.1078 - val_MAE: 0.1078\n",
      "Epoch 45/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0991 - MAE: 0.0991 - val_loss: 0.1094 - val_MAE: 0.1094\n",
      "Epoch 46/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1034 - MAE: 0.1034 - val_loss: 0.1206 - val_MAE: 0.1206\n",
      "Epoch 47/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0937 - MAE: 0.0937 - val_loss: 0.1058 - val_MAE: 0.1058\n",
      "Epoch 48/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1058 - MAE: 0.1058 - val_loss: 0.1041 - val_MAE: 0.1041\n",
      "Epoch 49/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0928 - MAE: 0.0928 - val_loss: 0.1102 - val_MAE: 0.1102\n",
      "Epoch 50/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0960 - MAE: 0.0960 - val_loss: 0.1075 - val_MAE: 0.1075\n",
      "Epoch 51/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0897 - MAE: 0.0897 - val_loss: 0.1013 - val_MAE: 0.1013\n",
      "Epoch 52/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0871 - MAE: 0.0871 - val_loss: 0.1039 - val_MAE: 0.1039\n",
      "Epoch 53/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0885 - MAE: 0.0885 - val_loss: 0.1046 - val_MAE: 0.1046\n",
      "Epoch 54/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0843 - MAE: 0.0843 - val_loss: 0.0991 - val_MAE: 0.0991\n",
      "Epoch 55/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0851 - MAE: 0.0851 - val_loss: 0.0989 - val_MAE: 0.0989\n",
      "Epoch 56/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0827 - MAE: 0.0827 - val_loss: 0.0988 - val_MAE: 0.0988\n",
      "Epoch 57/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0855 - MAE: 0.0855 - val_loss: 0.0995 - val_MAE: 0.0995\n",
      "Epoch 58/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0872 - MAE: 0.0872 - val_loss: 0.1038 - val_MAE: 0.1038\n",
      "Epoch 59/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0800 - MAE: 0.0800 - val_loss: 0.1005 - val_MAE: 0.1005\n",
      "Epoch 60/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0841 - MAE: 0.0841 - val_loss: 0.1039 - val_MAE: 0.1039\n",
      "Epoch 61/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0877 - MAE: 0.0877 - val_loss: 0.1048 - val_MAE: 0.1048\n",
      "Epoch 62/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0786 - MAE: 0.0786 - val_loss: 0.0979 - val_MAE: 0.0979\n",
      "Epoch 63/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0837 - MAE: 0.0837 - val_loss: 0.0954 - val_MAE: 0.0954\n",
      "Epoch 64/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0759 - MAE: 0.0759 - val_loss: 0.0987 - val_MAE: 0.0987\n",
      "Epoch 65/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0788 - MAE: 0.0788 - val_loss: 0.0951 - val_MAE: 0.0951\n",
      "Epoch 66/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0757 - MAE: 0.0757 - val_loss: 0.0941 - val_MAE: 0.0941\n",
      "Epoch 67/1000\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0748 - MAE: 0.0748 - val_loss: 0.0962 - val_MAE: 0.0962\n",
      "Epoch 68/1000\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0779 - MAE: 0.0779 - val_loss: 0.0927 - val_MAE: 0.0927\n",
      "Epoch 69/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0809 - MAE: 0.0809 - val_loss: 0.0944 - val_MAE: 0.0944\n",
      "Epoch 70/1000\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0750 - MAE: 0.0750 - val_loss: 0.1106 - val_MAE: 0.1106\n",
      "Epoch 71/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0810 - MAE: 0.0810 - val_loss: 0.0943 - val_MAE: 0.0943\n",
      "Epoch 72/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0916 - MAE: 0.0916 - val_loss: 0.0944 - val_MAE: 0.0944\n",
      "Epoch 73/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0767 - MAE: 0.0767 - val_loss: 0.1111 - val_MAE: 0.1111\n",
      "Epoch 74/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0770 - MAE: 0.0770 - val_loss: 0.0930 - val_MAE: 0.0930\n",
      "Epoch 75/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0795 - MAE: 0.0795 - val_loss: 0.0922 - val_MAE: 0.0922\n",
      "Epoch 76/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0733 - MAE: 0.0733 - val_loss: 0.0938 - val_MAE: 0.0938\n",
      "Epoch 77/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0737 - MAE: 0.0737 - val_loss: 0.0907 - val_MAE: 0.0907\n",
      "Epoch 78/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0762 - MAE: 0.0762 - val_loss: 0.0895 - val_MAE: 0.0895\n",
      "Epoch 79/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0760 - MAE: 0.0760 - val_loss: 0.0969 - val_MAE: 0.0969\n",
      "Epoch 80/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0737 - MAE: 0.0737 - val_loss: 0.0892 - val_MAE: 0.0892\n",
      "Epoch 81/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0703 - MAE: 0.0703 - val_loss: 0.0922 - val_MAE: 0.0922\n",
      "Epoch 82/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0711 - MAE: 0.0711 - val_loss: 0.0912 - val_MAE: 0.0912\n",
      "Epoch 83/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0719 - MAE: 0.0719 - val_loss: 0.0899 - val_MAE: 0.0899\n",
      "Epoch 84/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0690 - MAE: 0.0690 - val_loss: 0.0888 - val_MAE: 0.0888\n",
      "Epoch 85/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0681 - MAE: 0.0681 - val_loss: 0.0892 - val_MAE: 0.0892\n",
      "Epoch 86/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0676 - MAE: 0.0676 - val_loss: 0.0887 - val_MAE: 0.0887\n",
      "Epoch 87/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0679 - MAE: 0.0679 - val_loss: 0.0895 - val_MAE: 0.0895\n",
      "Epoch 88/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0667 - MAE: 0.0667 - val_loss: 0.0883 - val_MAE: 0.0883\n",
      "Epoch 89/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0663 - MAE: 0.0663 - val_loss: 0.0893 - val_MAE: 0.0893\n",
      "Epoch 90/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0674 - MAE: 0.0674 - val_loss: 0.0870 - val_MAE: 0.0870\n",
      "Epoch 91/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0657 - MAE: 0.0657 - val_loss: 0.0869 - val_MAE: 0.0869\n",
      "Epoch 92/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0653 - MAE: 0.0653 - val_loss: 0.0871 - val_MAE: 0.0871\n",
      "Epoch 93/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0643 - MAE: 0.0643 - val_loss: 0.0855 - val_MAE: 0.0855\n",
      "Epoch 94/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0713 - MAE: 0.0713 - val_loss: 0.0855 - val_MAE: 0.0855\n",
      "Epoch 95/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0655 - MAE: 0.0655 - val_loss: 0.0903 - val_MAE: 0.0903\n",
      "Epoch 96/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0649 - MAE: 0.0649 - val_loss: 0.0849 - val_MAE: 0.0849\n",
      "Epoch 97/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0672 - MAE: 0.0672 - val_loss: 0.0885 - val_MAE: 0.0885\n",
      "Epoch 98/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0650 - MAE: 0.0650 - val_loss: 0.0857 - val_MAE: 0.0857\n",
      "Epoch 99/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0669 - MAE: 0.0669 - val_loss: 0.0856 - val_MAE: 0.0856\n",
      "Epoch 100/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0635 - MAE: 0.0635 - val_loss: 0.0833 - val_MAE: 0.0833\n",
      "Epoch 101/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0647 - MAE: 0.0647 - val_loss: 0.0822 - val_MAE: 0.0822\n",
      "Epoch 102/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0616 - MAE: 0.0616 - val_loss: 0.0822 - val_MAE: 0.0822\n",
      "Epoch 103/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0619 - MAE: 0.0619 - val_loss: 0.0823 - val_MAE: 0.0823\n",
      "Epoch 104/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0623 - MAE: 0.0623 - val_loss: 0.0821 - val_MAE: 0.0821\n",
      "Epoch 105/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0619 - MAE: 0.0619 - val_loss: 0.0825 - val_MAE: 0.0825\n",
      "Epoch 106/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0614 - MAE: 0.0614 - val_loss: 0.0861 - val_MAE: 0.0861\n",
      "Epoch 107/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0675 - MAE: 0.0675 - val_loss: 0.0838 - val_MAE: 0.0838\n",
      "Epoch 108/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0720 - MAE: 0.0720 - val_loss: 0.0818 - val_MAE: 0.0818\n",
      "Epoch 109/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0645 - MAE: 0.0645 - val_loss: 0.0825 - val_MAE: 0.0825\n",
      "Epoch 110/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0628 - MAE: 0.0628 - val_loss: 0.0802 - val_MAE: 0.0802\n",
      "Epoch 111/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0616 - MAE: 0.0616 - val_loss: 0.0807 - val_MAE: 0.0807\n",
      "Epoch 112/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0621 - MAE: 0.0621 - val_loss: 0.0790 - val_MAE: 0.0790\n",
      "Epoch 113/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0592 - MAE: 0.0592 - val_loss: 0.0790 - val_MAE: 0.0790\n",
      "Epoch 114/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0589 - MAE: 0.0589 - val_loss: 0.0795 - val_MAE: 0.0795\n",
      "Epoch 115/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0611 - MAE: 0.0611 - val_loss: 0.0800 - val_MAE: 0.0800\n",
      "Epoch 116/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0592 - MAE: 0.0592 - val_loss: 0.0797 - val_MAE: 0.0797\n",
      "Epoch 117/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0592 - MAE: 0.0592 - val_loss: 0.0799 - val_MAE: 0.0799\n",
      "Epoch 118/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0585 - MAE: 0.0585 - val_loss: 0.0780 - val_MAE: 0.0780\n",
      "Epoch 119/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0581 - MAE: 0.0581 - val_loss: 0.0781 - val_MAE: 0.0781\n",
      "Epoch 120/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0622 - MAE: 0.0622 - val_loss: 0.0792 - val_MAE: 0.0792\n",
      "Epoch 121/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0591 - MAE: 0.0591 - val_loss: 0.0801 - val_MAE: 0.0801\n",
      "Epoch 122/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0585 - MAE: 0.0585 - val_loss: 0.0794 - val_MAE: 0.0794\n",
      "Epoch 123/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0572 - MAE: 0.0572 - val_loss: 0.0801 - val_MAE: 0.0801\n",
      "Epoch 124/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0568 - MAE: 0.0568 - val_loss: 0.0789 - val_MAE: 0.0789\n",
      "Epoch 125/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0578 - MAE: 0.0578 - val_loss: 0.0789 - val_MAE: 0.0789\n",
      "Epoch 126/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0585 - MAE: 0.0585 - val_loss: 0.0791 - val_MAE: 0.0791\n",
      "Epoch 127/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0568 - MAE: 0.0568 - val_loss: 0.0803 - val_MAE: 0.0803\n",
      "Epoch 128/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0580 - MAE: 0.0580 - val_loss: 0.0806 - val_MAE: 0.0806\n",
      "Epoch 129/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0576 - MAE: 0.0576 - val_loss: 0.0808 - val_MAE: 0.0808\n",
      "Epoch 130/1000\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0570 - MAE: 0.0570 - val_loss: 0.0796 - val_MAE: 0.0796\n",
      "Epoch 131/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0575 - MAE: 0.0575 - val_loss: 0.0773 - val_MAE: 0.0773\n",
      "Epoch 132/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0564 - MAE: 0.0564 - val_loss: 0.0783 - val_MAE: 0.0783\n",
      "Epoch 133/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0616 - MAE: 0.0616 - val_loss: 0.0758 - val_MAE: 0.0758\n",
      "Epoch 134/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0579 - MAE: 0.0579 - val_loss: 0.0757 - val_MAE: 0.0757\n",
      "Epoch 135/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0611 - MAE: 0.0611 - val_loss: 0.0764 - val_MAE: 0.0764\n",
      "Epoch 136/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0561 - MAE: 0.0561 - val_loss: 0.0761 - val_MAE: 0.0761\n",
      "Epoch 137/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0560 - MAE: 0.0560 - val_loss: 0.0801 - val_MAE: 0.0801\n",
      "Epoch 138/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0603 - MAE: 0.0603 - val_loss: 0.0787 - val_MAE: 0.0787\n",
      "Epoch 139/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0567 - MAE: 0.0567 - val_loss: 0.0787 - val_MAE: 0.0787\n",
      "Epoch 140/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0574 - MAE: 0.0574 - val_loss: 0.0750 - val_MAE: 0.0750\n",
      "Epoch 141/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0557 - MAE: 0.0557 - val_loss: 0.0750 - val_MAE: 0.0750\n",
      "Epoch 142/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0565 - MAE: 0.0565 - val_loss: 0.0749 - val_MAE: 0.0749\n",
      "Epoch 143/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0544 - MAE: 0.0544 - val_loss: 0.0770 - val_MAE: 0.0770\n",
      "Epoch 144/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0565 - MAE: 0.0565 - val_loss: 0.0781 - val_MAE: 0.0781\n",
      "Epoch 145/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0591 - MAE: 0.0591 - val_loss: 0.0780 - val_MAE: 0.0780\n",
      "Epoch 146/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0571 - MAE: 0.0571 - val_loss: 0.0739 - val_MAE: 0.0739\n",
      "Epoch 147/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0624 - MAE: 0.0624 - val_loss: 0.0734 - val_MAE: 0.0734\n",
      "Epoch 148/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0637 - MAE: 0.0637 - val_loss: 0.0841 - val_MAE: 0.0841\n",
      "Epoch 149/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0581 - MAE: 0.0581 - val_loss: 0.0739 - val_MAE: 0.0739\n",
      "Epoch 150/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0535 - MAE: 0.0535 - val_loss: 0.0767 - val_MAE: 0.0767\n",
      "Epoch 151/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0554 - MAE: 0.0554 - val_loss: 0.0744 - val_MAE: 0.0744\n",
      "Epoch 152/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0534 - MAE: 0.0534 - val_loss: 0.0756 - val_MAE: 0.0756\n",
      "Epoch 153/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0546 - MAE: 0.0546 - val_loss: 0.0740 - val_MAE: 0.0740\n",
      "Epoch 154/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0530 - MAE: 0.0530 - val_loss: 0.0761 - val_MAE: 0.0761\n",
      "Epoch 155/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0587 - MAE: 0.0587 - val_loss: 0.0755 - val_MAE: 0.0755\n",
      "Epoch 156/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0530 - MAE: 0.0530 - val_loss: 0.0754 - val_MAE: 0.0754\n",
      "Epoch 157/1000\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0556 - MAE: 0.0556 - val_loss: 0.0758 - val_MAE: 0.0758\n",
      "Epoch 158/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0545 - MAE: 0.0545 - val_loss: 0.0760 - val_MAE: 0.0760\n",
      "Epoch 159/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0545 - MAE: 0.0545 - val_loss: 0.0762 - val_MAE: 0.0762\n",
      "Epoch 160/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0524 - MAE: 0.0524 - val_loss: 0.0758 - val_MAE: 0.0758\n",
      "Epoch 161/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0617 - MAE: 0.0617 - val_loss: 0.0754 - val_MAE: 0.0754\n",
      "Epoch 162/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0570 - MAE: 0.0570 - val_loss: 0.0739 - val_MAE: 0.0739\n",
      "Epoch 163/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0591 - MAE: 0.0591 - val_loss: 0.0742 - val_MAE: 0.0742\n",
      "Epoch 164/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0662 - MAE: 0.0662 - val_loss: 0.0769 - val_MAE: 0.0769\n",
      "Epoch 165/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0571 - MAE: 0.0571 - val_loss: 0.0745 - val_MAE: 0.0745\n",
      "Epoch 166/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0525 - MAE: 0.0525 - val_loss: 0.0766 - val_MAE: 0.0766\n",
      "Epoch 167/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0513 - MAE: 0.0513 - val_loss: 0.0738 - val_MAE: 0.0738\n",
      "Epoch 168/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0543 - MAE: 0.0543 - val_loss: 0.0727 - val_MAE: 0.0727\n",
      "Epoch 169/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0514 - MAE: 0.0514 - val_loss: 0.0723 - val_MAE: 0.0723\n",
      "Epoch 170/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0528 - MAE: 0.0528 - val_loss: 0.0768 - val_MAE: 0.0768\n",
      "Epoch 171/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0527 - MAE: 0.0527 - val_loss: 0.0747 - val_MAE: 0.0747\n",
      "Epoch 172/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0513 - MAE: 0.0513 - val_loss: 0.0741 - val_MAE: 0.0741\n",
      "Epoch 173/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0501 - MAE: 0.0501 - val_loss: 0.0739 - val_MAE: 0.0739\n",
      "Epoch 174/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0497 - MAE: 0.0497 - val_loss: 0.0735 - val_MAE: 0.0735\n",
      "Epoch 175/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0511 - MAE: 0.0511 - val_loss: 0.0741 - val_MAE: 0.0741\n",
      "Epoch 176/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0494 - MAE: 0.0494 - val_loss: 0.0736 - val_MAE: 0.0736\n",
      "Epoch 177/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0499 - MAE: 0.0499 - val_loss: 0.0751 - val_MAE: 0.0751\n",
      "Epoch 178/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0521 - MAE: 0.0521 - val_loss: 0.0754 - val_MAE: 0.0754\n",
      "Epoch 179/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0500 - MAE: 0.0500 - val_loss: 0.0751 - val_MAE: 0.0751\n",
      "Epoch 180/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0493 - MAE: 0.0493 - val_loss: 0.0747 - val_MAE: 0.0747\n",
      "Epoch 181/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0488 - MAE: 0.0488 - val_loss: 0.0737 - val_MAE: 0.0737\n",
      "Epoch 182/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0494 - MAE: 0.0494 - val_loss: 0.0718 - val_MAE: 0.0718\n",
      "Epoch 183/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0506 - MAE: 0.0506 - val_loss: 0.0717 - val_MAE: 0.0717\n",
      "Epoch 184/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0495 - MAE: 0.0495 - val_loss: 0.0721 - val_MAE: 0.0721\n",
      "Epoch 185/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0489 - MAE: 0.0489 - val_loss: 0.0729 - val_MAE: 0.0729\n",
      "Epoch 186/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0483 - MAE: 0.0483 - val_loss: 0.0713 - val_MAE: 0.0713\n",
      "Epoch 187/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0479 - MAE: 0.0479 - val_loss: 0.0745 - val_MAE: 0.0745\n",
      "Epoch 188/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0566 - MAE: 0.0566 - val_loss: 0.0729 - val_MAE: 0.0729\n",
      "Epoch 189/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0480 - MAE: 0.0480 - val_loss: 0.0741 - val_MAE: 0.0741\n",
      "Epoch 190/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0519 - MAE: 0.0519 - val_loss: 0.0706 - val_MAE: 0.0706\n",
      "Epoch 191/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0505 - MAE: 0.0505 - val_loss: 0.0724 - val_MAE: 0.0724\n",
      "Epoch 192/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0507 - MAE: 0.0507 - val_loss: 0.0724 - val_MAE: 0.0724\n",
      "Epoch 193/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0507 - MAE: 0.0507 - val_loss: 0.0724 - val_MAE: 0.0724\n",
      "Epoch 194/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0504 - MAE: 0.0504 - val_loss: 0.0713 - val_MAE: 0.0713\n",
      "Epoch 195/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0482 - MAE: 0.0482 - val_loss: 0.0692 - val_MAE: 0.0692\n",
      "Epoch 196/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0471 - MAE: 0.0471 - val_loss: 0.0692 - val_MAE: 0.0692\n",
      "Epoch 197/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0504 - MAE: 0.0504 - val_loss: 0.0693 - val_MAE: 0.0693\n",
      "Epoch 198/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0530 - MAE: 0.0530 - val_loss: 0.0700 - val_MAE: 0.0700\n",
      "Epoch 199/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0493 - MAE: 0.0493 - val_loss: 0.0727 - val_MAE: 0.0727\n",
      "Epoch 200/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0490 - MAE: 0.0490 - val_loss: 0.0733 - val_MAE: 0.0733\n",
      "Epoch 201/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0484 - MAE: 0.0484 - val_loss: 0.0724 - val_MAE: 0.0724\n",
      "Epoch 202/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0466 - MAE: 0.0466 - val_loss: 0.0726 - val_MAE: 0.0726\n",
      "Epoch 203/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0533 - MAE: 0.0533 - val_loss: 0.0707 - val_MAE: 0.0707\n",
      "Epoch 204/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0520 - MAE: 0.0520 - val_loss: 0.0674 - val_MAE: 0.0674\n",
      "Epoch 205/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0516 - MAE: 0.0516 - val_loss: 0.0688 - val_MAE: 0.0688\n",
      "Epoch 206/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0476 - MAE: 0.0476 - val_loss: 0.0708 - val_MAE: 0.0708\n",
      "Epoch 207/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0477 - MAE: 0.0477 - val_loss: 0.0726 - val_MAE: 0.0726\n",
      "Epoch 208/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0521 - MAE: 0.0521 - val_loss: 0.0700 - val_MAE: 0.0700\n",
      "Epoch 209/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0511 - MAE: 0.0511 - val_loss: 0.0718 - val_MAE: 0.0718\n",
      "Epoch 210/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0460 - MAE: 0.0460 - val_loss: 0.0722 - val_MAE: 0.0722\n",
      "Epoch 211/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0478 - MAE: 0.0478 - val_loss: 0.0702 - val_MAE: 0.0702\n",
      "Epoch 212/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0460 - MAE: 0.0460 - val_loss: 0.0708 - val_MAE: 0.0708\n",
      "Epoch 213/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0469 - MAE: 0.0469 - val_loss: 0.0693 - val_MAE: 0.0693\n",
      "Epoch 214/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0456 - MAE: 0.0456 - val_loss: 0.0678 - val_MAE: 0.0678\n",
      "Epoch 215/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0453 - MAE: 0.0453 - val_loss: 0.0689 - val_MAE: 0.0689\n",
      "Epoch 216/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0456 - MAE: 0.0456 - val_loss: 0.0688 - val_MAE: 0.0688\n",
      "Epoch 217/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0444 - MAE: 0.0444 - val_loss: 0.0680 - val_MAE: 0.0680\n",
      "Epoch 218/1000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0454 - MAE: 0.0454 - val_loss: 0.0668 - val_MAE: 0.0668\n",
      "Epoch 219/1000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0473 - MAE: 0.0473 - val_loss: 0.0679 - val_MAE: 0.0679\n",
      "Epoch 220/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0488 - MAE: 0.0488 - val_loss: 0.0702 - val_MAE: 0.0702\n",
      "Epoch 221/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0459 - MAE: 0.0459 - val_loss: 0.0710 - val_MAE: 0.0710\n",
      "Epoch 222/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0453 - MAE: 0.0453 - val_loss: 0.0712 - val_MAE: 0.0712\n",
      "Epoch 223/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0454 - MAE: 0.0454 - val_loss: 0.0724 - val_MAE: 0.0724\n",
      "Epoch 224/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0478 - MAE: 0.0478 - val_loss: 0.0726 - val_MAE: 0.0726\n",
      "Epoch 225/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0510 - MAE: 0.0510 - val_loss: 0.0704 - val_MAE: 0.0704\n",
      "Epoch 226/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0495 - MAE: 0.0495 - val_loss: 0.0697 - val_MAE: 0.0697\n",
      "Epoch 227/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0455 - MAE: 0.0455 - val_loss: 0.0721 - val_MAE: 0.0721\n",
      "Epoch 228/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0498 - MAE: 0.0498 - val_loss: 0.0723 - val_MAE: 0.0723\n",
      "Epoch 229/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0484 - MAE: 0.0484 - val_loss: 0.0719 - val_MAE: 0.0719\n",
      "Epoch 230/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0459 - MAE: 0.0459 - val_loss: 0.0714 - val_MAE: 0.0714\n",
      "Epoch 231/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0457 - MAE: 0.0457 - val_loss: 0.0703 - val_MAE: 0.0703\n",
      "Epoch 232/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0462 - MAE: 0.0462 - val_loss: 0.0672 - val_MAE: 0.0672\n",
      "Epoch 233/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0460 - MAE: 0.0460 - val_loss: 0.0681 - val_MAE: 0.0681\n",
      "Epoch 234/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0444 - MAE: 0.0444 - val_loss: 0.0689 - val_MAE: 0.0689\n",
      "Epoch 235/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0426 - MAE: 0.0426 - val_loss: 0.0692 - val_MAE: 0.0692\n",
      "Epoch 236/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0422 - MAE: 0.0422 - val_loss: 0.0685 - val_MAE: 0.0685\n",
      "Epoch 237/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0434 - MAE: 0.0434 - val_loss: 0.0683 - val_MAE: 0.0683\n",
      "Epoch 238/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0426 - MAE: 0.0426 - val_loss: 0.0703 - val_MAE: 0.0703\n",
      "Epoch 239/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0460 - MAE: 0.0460 - val_loss: 0.0688 - val_MAE: 0.0688\n",
      "Epoch 240/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0429 - MAE: 0.0429 - val_loss: 0.0672 - val_MAE: 0.0672\n",
      "Epoch 241/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0423 - MAE: 0.0423 - val_loss: 0.0676 - val_MAE: 0.0676\n",
      "Epoch 242/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0417 - MAE: 0.0417 - val_loss: 0.0683 - val_MAE: 0.0683\n",
      "Epoch 243/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0448 - MAE: 0.0448 - val_loss: 0.0707 - val_MAE: 0.0707\n",
      "Epoch 244/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0473 - MAE: 0.0473 - val_loss: 0.0698 - val_MAE: 0.0698\n",
      "Epoch 245/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0439 - MAE: 0.0439 - val_loss: 0.0696 - val_MAE: 0.0696\n",
      "Epoch 246/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0433 - MAE: 0.0433 - val_loss: 0.0681 - val_MAE: 0.0681\n",
      "Epoch 247/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0420 - MAE: 0.0420 - val_loss: 0.0653 - val_MAE: 0.0653\n",
      "Epoch 248/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0448 - MAE: 0.0448 - val_loss: 0.0661 - val_MAE: 0.0661\n",
      "Epoch 249/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0421 - MAE: 0.0421 - val_loss: 0.0682 - val_MAE: 0.0682\n",
      "Epoch 250/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0418 - MAE: 0.0418 - val_loss: 0.0717 - val_MAE: 0.0717\n",
      "Epoch 251/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0453 - MAE: 0.0453 - val_loss: 0.0715 - val_MAE: 0.0715\n",
      "Epoch 252/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0427 - MAE: 0.0427 - val_loss: 0.0681 - val_MAE: 0.0681\n",
      "Epoch 253/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0434 - MAE: 0.0434 - val_loss: 0.0680 - val_MAE: 0.0680\n",
      "Epoch 254/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0418 - MAE: 0.0418 - val_loss: 0.0678 - val_MAE: 0.0678\n",
      "Epoch 255/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0414 - MAE: 0.0414 - val_loss: 0.0672 - val_MAE: 0.0672\n",
      "Epoch 256/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0443 - MAE: 0.0443 - val_loss: 0.0692 - val_MAE: 0.0692\n",
      "Epoch 257/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0426 - MAE: 0.0426 - val_loss: 0.0672 - val_MAE: 0.0672\n",
      "Epoch 258/1000\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0407 - MAE: 0.0407 - val_loss: 0.0681 - val_MAE: 0.0681\n",
      "Epoch 259/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0435 - MAE: 0.0435 - val_loss: 0.0727 - val_MAE: 0.0727\n",
      "Epoch 260/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0525 - MAE: 0.0525 - val_loss: 0.0731 - val_MAE: 0.0731\n",
      "Epoch 261/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0542 - MAE: 0.0542 - val_loss: 0.0727 - val_MAE: 0.0727\n",
      "Epoch 262/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0668 - MAE: 0.0668 - val_loss: 0.0687 - val_MAE: 0.0687\n",
      "Epoch 263/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0534 - MAE: 0.0534 - val_loss: 0.0673 - val_MAE: 0.0673\n",
      "Epoch 264/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0486 - MAE: 0.0486 - val_loss: 0.0683 - val_MAE: 0.0683\n",
      "Epoch 265/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0506 - MAE: 0.0506 - val_loss: 0.0670 - val_MAE: 0.0670\n",
      "Epoch 266/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0491 - MAE: 0.0491 - val_loss: 0.0691 - val_MAE: 0.0691\n",
      "Epoch 267/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0440 - MAE: 0.0440 - val_loss: 0.0673 - val_MAE: 0.0673\n",
      "Epoch 268/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0462 - MAE: 0.0462 - val_loss: 0.0690 - val_MAE: 0.0690\n",
      "Epoch 269/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0450 - MAE: 0.0450 - val_loss: 0.0681 - val_MAE: 0.0681\n",
      "Epoch 270/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0474 - MAE: 0.0474 - val_loss: 0.0682 - val_MAE: 0.0682\n",
      "Epoch 271/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0447 - MAE: 0.0447 - val_loss: 0.0691 - val_MAE: 0.0691\n",
      "Epoch 272/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0526 - MAE: 0.0526 - val_loss: 0.0681 - val_MAE: 0.0681\n",
      "Epoch 273/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0458 - MAE: 0.0458 - val_loss: 0.0679 - val_MAE: 0.0679\n",
      "Epoch 274/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0436 - MAE: 0.0436 - val_loss: 0.0673 - val_MAE: 0.0673\n",
      "Epoch 275/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0410 - MAE: 0.0410 - val_loss: 0.0677 - val_MAE: 0.0677\n",
      "Epoch 276/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0398 - MAE: 0.0398 - val_loss: 0.0696 - val_MAE: 0.0696\n",
      "Epoch 277/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0419 - MAE: 0.0419 - val_loss: 0.0686 - val_MAE: 0.0686\n",
      "Epoch 278/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0421 - MAE: 0.0421 - val_loss: 0.0673 - val_MAE: 0.0673\n",
      "Epoch 279/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0433 - MAE: 0.0433 - val_loss: 0.0677 - val_MAE: 0.0677\n",
      "Epoch 280/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0435 - MAE: 0.0435 - val_loss: 0.0675 - val_MAE: 0.0675\n",
      "Epoch 281/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0400 - MAE: 0.0400 - val_loss: 0.0679 - val_MAE: 0.0679\n",
      "Epoch 282/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0393 - MAE: 0.0393 - val_loss: 0.0684 - val_MAE: 0.0684\n",
      "Epoch 283/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0400 - MAE: 0.0400 - val_loss: 0.0697 - val_MAE: 0.0697\n",
      "Epoch 284/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0434 - MAE: 0.0434 - val_loss: 0.0692 - val_MAE: 0.0692\n",
      "Epoch 285/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0448 - MAE: 0.0448 - val_loss: 0.0683 - val_MAE: 0.0683\n",
      "Epoch 286/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0405 - MAE: 0.0405 - val_loss: 0.0738 - val_MAE: 0.0738\n",
      "Epoch 287/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0517 - MAE: 0.0517 - val_loss: 0.0712 - val_MAE: 0.0712\n",
      "Epoch 288/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0486 - MAE: 0.0486 - val_loss: 0.0738 - val_MAE: 0.0738\n",
      "Epoch 289/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0531 - MAE: 0.0531 - val_loss: 0.0718 - val_MAE: 0.0718\n",
      "Epoch 290/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0427 - MAE: 0.0427 - val_loss: 0.0702 - val_MAE: 0.0702\n",
      "Epoch 291/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0402 - MAE: 0.0402 - val_loss: 0.0660 - val_MAE: 0.0660\n",
      "Epoch 292/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0403 - MAE: 0.0403 - val_loss: 0.0665 - val_MAE: 0.0665\n",
      "Epoch 293/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0400 - MAE: 0.0400 - val_loss: 0.0670 - val_MAE: 0.0670\n",
      "Epoch 294/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0406 - MAE: 0.0406 - val_loss: 0.0695 - val_MAE: 0.0695\n",
      "Epoch 295/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0423 - MAE: 0.0423 - val_loss: 0.0675 - val_MAE: 0.0675\n",
      "Epoch 296/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0400 - MAE: 0.0400 - val_loss: 0.0681 - val_MAE: 0.0681\n",
      "Epoch 297/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0403 - MAE: 0.0403 - val_loss: 0.0660 - val_MAE: 0.0660\n",
      "Epoch 298/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0389 - MAE: 0.0389 - val_loss: 0.0672 - val_MAE: 0.0672\n",
      "Epoch 299/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0411 - MAE: 0.0411 - val_loss: 0.0649 - val_MAE: 0.0649\n",
      "Epoch 300/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0389 - MAE: 0.0389 - val_loss: 0.0649 - val_MAE: 0.0649\n",
      "Epoch 301/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0398 - MAE: 0.0398 - val_loss: 0.0642 - val_MAE: 0.0642\n",
      "Epoch 302/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0383 - MAE: 0.0383 - val_loss: 0.0662 - val_MAE: 0.0662\n",
      "Epoch 303/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0379 - MAE: 0.0379 - val_loss: 0.0666 - val_MAE: 0.0666\n",
      "Epoch 304/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0396 - MAE: 0.0396 - val_loss: 0.0684 - val_MAE: 0.0684\n",
      "Epoch 305/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0384 - MAE: 0.0384 - val_loss: 0.0657 - val_MAE: 0.0657\n",
      "Epoch 306/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0371 - MAE: 0.0371 - val_loss: 0.0637 - val_MAE: 0.0637\n",
      "Epoch 307/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0393 - MAE: 0.0393 - val_loss: 0.0634 - val_MAE: 0.0634\n",
      "Epoch 308/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0393 - MAE: 0.0393 - val_loss: 0.0694 - val_MAE: 0.0694\n",
      "Epoch 309/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0442 - MAE: 0.0442 - val_loss: 0.0650 - val_MAE: 0.0650\n",
      "Epoch 310/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0374 - MAE: 0.0374 - val_loss: 0.0667 - val_MAE: 0.0667\n",
      "Epoch 311/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0384 - MAE: 0.0384 - val_loss: 0.0635 - val_MAE: 0.0635\n",
      "Epoch 312/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0380 - MAE: 0.0380 - val_loss: 0.0666 - val_MAE: 0.0666\n",
      "Epoch 313/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0387 - MAE: 0.0387 - val_loss: 0.0639 - val_MAE: 0.0639\n",
      "Epoch 314/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0370 - MAE: 0.0370 - val_loss: 0.0647 - val_MAE: 0.0647\n",
      "Epoch 315/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0379 - MAE: 0.0379 - val_loss: 0.0678 - val_MAE: 0.0678\n",
      "Epoch 316/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0386 - MAE: 0.0386 - val_loss: 0.0661 - val_MAE: 0.0661\n",
      "Epoch 317/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0408 - MAE: 0.0408 - val_loss: 0.0711 - val_MAE: 0.0711\n",
      "Epoch 318/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0416 - MAE: 0.0416 - val_loss: 0.0646 - val_MAE: 0.0646\n",
      "Epoch 319/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0383 - MAE: 0.0383 - val_loss: 0.0685 - val_MAE: 0.0685\n",
      "Epoch 320/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0408 - MAE: 0.0408 - val_loss: 0.0684 - val_MAE: 0.0684\n",
      "Epoch 321/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0422 - MAE: 0.0422 - val_loss: 0.0654 - val_MAE: 0.0654\n",
      "Epoch 322/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0384 - MAE: 0.0384 - val_loss: 0.0645 - val_MAE: 0.0645\n",
      "Epoch 323/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0382 - MAE: 0.0382 - val_loss: 0.0644 - val_MAE: 0.0644\n",
      "Epoch 324/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0484 - MAE: 0.0484 - val_loss: 0.0720 - val_MAE: 0.0720\n",
      "Epoch 325/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0613 - MAE: 0.0613 - val_loss: 0.0650 - val_MAE: 0.0650\n",
      "Epoch 326/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0436 - MAE: 0.0436 - val_loss: 0.0651 - val_MAE: 0.0651\n",
      "Epoch 327/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0383 - MAE: 0.0383 - val_loss: 0.0650 - val_MAE: 0.0650\n",
      "Epoch 328/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0371 - MAE: 0.0371 - val_loss: 0.0647 - val_MAE: 0.0647\n",
      "Epoch 329/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0395 - MAE: 0.0395 - val_loss: 0.0657 - val_MAE: 0.0657\n",
      "Epoch 330/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0383 - MAE: 0.0383 - val_loss: 0.0655 - val_MAE: 0.0655\n",
      "Epoch 331/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0368 - MAE: 0.0368 - val_loss: 0.0682 - val_MAE: 0.0682\n",
      "Epoch 332/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0408 - MAE: 0.0408 - val_loss: 0.0684 - val_MAE: 0.0684\n",
      "Epoch 333/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0383 - MAE: 0.0383 - val_loss: 0.0647 - val_MAE: 0.0647\n",
      "Epoch 334/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0372 - MAE: 0.0372 - val_loss: 0.0659 - val_MAE: 0.0659\n",
      "Epoch 335/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0406 - MAE: 0.0406 - val_loss: 0.0629 - val_MAE: 0.0629\n",
      "Epoch 336/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0372 - MAE: 0.0372 - val_loss: 0.0643 - val_MAE: 0.0643\n",
      "Epoch 337/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0351 - MAE: 0.0351 - val_loss: 0.0658 - val_MAE: 0.0658\n",
      "Epoch 338/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0363 - MAE: 0.0363 - val_loss: 0.0682 - val_MAE: 0.0682\n",
      "Epoch 339/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0357 - MAE: 0.0357 - val_loss: 0.0659 - val_MAE: 0.0659\n",
      "Epoch 340/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0352 - MAE: 0.0352 - val_loss: 0.0653 - val_MAE: 0.0653\n",
      "Epoch 341/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0354 - MAE: 0.0354 - val_loss: 0.0652 - val_MAE: 0.0652\n",
      "Epoch 342/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0348 - MAE: 0.0348 - val_loss: 0.0653 - val_MAE: 0.0653\n",
      "Epoch 343/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0364 - MAE: 0.0364 - val_loss: 0.0667 - val_MAE: 0.0667\n",
      "Epoch 344/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0367 - MAE: 0.0367 - val_loss: 0.0678 - val_MAE: 0.0678\n",
      "Epoch 345/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0420 - MAE: 0.0420 - val_loss: 0.0647 - val_MAE: 0.0647\n",
      "Epoch 346/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0357 - MAE: 0.0357 - val_loss: 0.0672 - val_MAE: 0.0672\n",
      "Epoch 347/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0376 - MAE: 0.0376 - val_loss: 0.0687 - val_MAE: 0.0687\n",
      "Epoch 348/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0369 - MAE: 0.0369 - val_loss: 0.0656 - val_MAE: 0.0656\n",
      "Epoch 349/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0374 - MAE: 0.0374 - val_loss: 0.0701 - val_MAE: 0.0701\n",
      "Epoch 350/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0370 - MAE: 0.0370 - val_loss: 0.0659 - val_MAE: 0.0659\n",
      "Epoch 351/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0361 - MAE: 0.0361 - val_loss: 0.0659 - val_MAE: 0.0659\n",
      "Epoch 352/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0353 - MAE: 0.0353 - val_loss: 0.0660 - val_MAE: 0.0660\n",
      "Epoch 353/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0355 - MAE: 0.0355 - val_loss: 0.0636 - val_MAE: 0.0636\n",
      "Epoch 354/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0364 - MAE: 0.0364 - val_loss: 0.0696 - val_MAE: 0.0696\n",
      "Epoch 355/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0379 - MAE: 0.0379 - val_loss: 0.0717 - val_MAE: 0.0717\n",
      "Epoch 356/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0397 - MAE: 0.0397 - val_loss: 0.0716 - val_MAE: 0.0716\n",
      "Epoch 357/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0399 - MAE: 0.0399 - val_loss: 0.0698 - val_MAE: 0.0698\n",
      "Epoch 358/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0383 - MAE: 0.0383 - val_loss: 0.0672 - val_MAE: 0.0672\n",
      "Epoch 359/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0425 - MAE: 0.0425 - val_loss: 0.0698 - val_MAE: 0.0698\n",
      "Epoch 360/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0411 - MAE: 0.0411 - val_loss: 0.0677 - val_MAE: 0.0677\n",
      "Epoch 361/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0363 - MAE: 0.0363 - val_loss: 0.0685 - val_MAE: 0.0685\n",
      "Epoch 362/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0402 - MAE: 0.0402 - val_loss: 0.0660 - val_MAE: 0.0660\n",
      "Epoch 363/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0338 - MAE: 0.0338 - val_loss: 0.0669 - val_MAE: 0.0669\n",
      "Epoch 364/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0380 - MAE: 0.0380 - val_loss: 0.0660 - val_MAE: 0.0660\n",
      "Epoch 365/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0343 - MAE: 0.0343 - val_loss: 0.0672 - val_MAE: 0.0672\n",
      "Epoch 366/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0342 - MAE: 0.0342 - val_loss: 0.0658 - val_MAE: 0.0658\n",
      "Epoch 367/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0339 - MAE: 0.0339 - val_loss: 0.0661 - val_MAE: 0.0661\n",
      "Epoch 368/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0340 - MAE: 0.0340 - val_loss: 0.0650 - val_MAE: 0.0650\n",
      "Epoch 369/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0351 - MAE: 0.0351 - val_loss: 0.0666 - val_MAE: 0.0666\n",
      "Epoch 370/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0336 - MAE: 0.0336 - val_loss: 0.0648 - val_MAE: 0.0648\n",
      "Epoch 371/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0351 - MAE: 0.0351 - val_loss: 0.0636 - val_MAE: 0.0636\n",
      "Epoch 372/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0337 - MAE: 0.0337 - val_loss: 0.0655 - val_MAE: 0.0655\n",
      "Epoch 373/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0335 - MAE: 0.0335 - val_loss: 0.0662 - val_MAE: 0.0662\n",
      "Epoch 374/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0338 - MAE: 0.0338 - val_loss: 0.0666 - val_MAE: 0.0666\n",
      "Epoch 375/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0333 - MAE: 0.0333 - val_loss: 0.0654 - val_MAE: 0.0654\n",
      "Epoch 376/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0343 - MAE: 0.0343 - val_loss: 0.0659 - val_MAE: 0.0659\n",
      "Epoch 377/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0350 - MAE: 0.0350 - val_loss: 0.0641 - val_MAE: 0.0641\n",
      "Epoch 378/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0358 - MAE: 0.0358 - val_loss: 0.0719 - val_MAE: 0.0719\n",
      "Epoch 379/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0405 - MAE: 0.0405 - val_loss: 0.0671 - val_MAE: 0.0671\n",
      "Epoch 380/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0388 - MAE: 0.0388 - val_loss: 0.0678 - val_MAE: 0.0678\n",
      "Epoch 381/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0337 - MAE: 0.0337 - val_loss: 0.0654 - val_MAE: 0.0654\n",
      "Epoch 382/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0351 - MAE: 0.0351 - val_loss: 0.0653 - val_MAE: 0.0653\n",
      "Epoch 383/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0345 - MAE: 0.0345 - val_loss: 0.0672 - val_MAE: 0.0672\n",
      "Epoch 384/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0344 - MAE: 0.0344 - val_loss: 0.0674 - val_MAE: 0.0674\n",
      "Epoch 385/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0361 - MAE: 0.0361 - val_loss: 0.0643 - val_MAE: 0.0643\n",
      "Epoch 386/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0361 - MAE: 0.0361 - val_loss: 0.0670 - val_MAE: 0.0670\n",
      "Epoch 387/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0348 - MAE: 0.0348 - val_loss: 0.0641 - val_MAE: 0.0641\n",
      "Epoch 388/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0326 - MAE: 0.0326 - val_loss: 0.0645 - val_MAE: 0.0645\n",
      "Epoch 389/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0336 - MAE: 0.0336 - val_loss: 0.0694 - val_MAE: 0.0694\n",
      "Epoch 390/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0399 - MAE: 0.0399 - val_loss: 0.0645 - val_MAE: 0.0645\n",
      "Epoch 391/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0366 - MAE: 0.0366 - val_loss: 0.0665 - val_MAE: 0.0665\n",
      "Epoch 392/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0345 - MAE: 0.0345 - val_loss: 0.0681 - val_MAE: 0.0681\n",
      "Epoch 393/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0402 - MAE: 0.0402 - val_loss: 0.0657 - val_MAE: 0.0657\n",
      "Epoch 394/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0340 - MAE: 0.0340 - val_loss: 0.0655 - val_MAE: 0.0655\n",
      "Epoch 395/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0322 - MAE: 0.0322 - val_loss: 0.0659 - val_MAE: 0.0659\n",
      "Epoch 396/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0319 - MAE: 0.0319 - val_loss: 0.0685 - val_MAE: 0.0685\n",
      "Epoch 397/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0343 - MAE: 0.0343 - val_loss: 0.0636 - val_MAE: 0.0636\n",
      "Epoch 398/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0329 - MAE: 0.0329 - val_loss: 0.0675 - val_MAE: 0.0675\n",
      "Epoch 399/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0345 - MAE: 0.0345 - val_loss: 0.0633 - val_MAE: 0.0633\n",
      "Epoch 400/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0330 - MAE: 0.0330 - val_loss: 0.0672 - val_MAE: 0.0672\n",
      "Epoch 401/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0316 - MAE: 0.0316 - val_loss: 0.0666 - val_MAE: 0.0666\n",
      "Epoch 402/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0346 - MAE: 0.0346 - val_loss: 0.0681 - val_MAE: 0.0681\n",
      "Epoch 403/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0318 - MAE: 0.0318 - val_loss: 0.0665 - val_MAE: 0.0665\n",
      "Epoch 404/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0319 - MAE: 0.0319 - val_loss: 0.0632 - val_MAE: 0.0632\n",
      "Epoch 405/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0314 - MAE: 0.0314 - val_loss: 0.0661 - val_MAE: 0.0661\n",
      "Epoch 406/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0313 - MAE: 0.0313 - val_loss: 0.0641 - val_MAE: 0.0641\n",
      "Epoch 407/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0323 - MAE: 0.0323 - val_loss: 0.0651 - val_MAE: 0.0651\n",
      "Epoch 408/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0329 - MAE: 0.0329 - val_loss: 0.0673 - val_MAE: 0.0673\n",
      "Epoch 409/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0351 - MAE: 0.0351 - val_loss: 0.0671 - val_MAE: 0.0671\n",
      "Epoch 410/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0347 - MAE: 0.0347 - val_loss: 0.0644 - val_MAE: 0.0644\n",
      "Epoch 411/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0325 - MAE: 0.0325 - val_loss: 0.0665 - val_MAE: 0.0665\n",
      "Epoch 412/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0373 - MAE: 0.0373 - val_loss: 0.0707 - val_MAE: 0.0707\n",
      "Epoch 413/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0369 - MAE: 0.0369 - val_loss: 0.0667 - val_MAE: 0.0667\n",
      "Epoch 414/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0312 - MAE: 0.0312 - val_loss: 0.0652 - val_MAE: 0.0652\n",
      "Epoch 415/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0314 - MAE: 0.0314 - val_loss: 0.0643 - val_MAE: 0.0643\n",
      "Epoch 416/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0314 - MAE: 0.0314 - val_loss: 0.0655 - val_MAE: 0.0655\n",
      "Epoch 417/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0307 - MAE: 0.0307 - val_loss: 0.0642 - val_MAE: 0.0642\n",
      "Epoch 418/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0340 - MAE: 0.0340 - val_loss: 0.0723 - val_MAE: 0.0723\n",
      "Epoch 419/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0380 - MAE: 0.0380 - val_loss: 0.0622 - val_MAE: 0.0622\n",
      "Epoch 420/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0357 - MAE: 0.0357 - val_loss: 0.0641 - val_MAE: 0.0641\n",
      "Epoch 421/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0310 - MAE: 0.0310 - val_loss: 0.0640 - val_MAE: 0.0640\n",
      "Epoch 422/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0310 - MAE: 0.0310 - val_loss: 0.0647 - val_MAE: 0.0647\n",
      "Epoch 423/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0313 - MAE: 0.0313 - val_loss: 0.0644 - val_MAE: 0.0644\n",
      "Epoch 424/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0302 - MAE: 0.0302 - val_loss: 0.0629 - val_MAE: 0.0629\n",
      "Epoch 425/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0310 - MAE: 0.0310 - val_loss: 0.0673 - val_MAE: 0.0673\n",
      "Epoch 426/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0309 - MAE: 0.0309 - val_loss: 0.0637 - val_MAE: 0.0637\n",
      "Epoch 427/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0305 - MAE: 0.0305 - val_loss: 0.0667 - val_MAE: 0.0667\n",
      "Epoch 428/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0343 - MAE: 0.0343 - val_loss: 0.0723 - val_MAE: 0.0723\n",
      "Epoch 429/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0361 - MAE: 0.0361 - val_loss: 0.0672 - val_MAE: 0.0672\n",
      "Epoch 430/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0317 - MAE: 0.0317 - val_loss: 0.0654 - val_MAE: 0.0654\n",
      "Epoch 431/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0340 - MAE: 0.0340 - val_loss: 0.0678 - val_MAE: 0.0678\n",
      "Epoch 432/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0318 - MAE: 0.0318 - val_loss: 0.0669 - val_MAE: 0.0669\n",
      "Epoch 433/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0311 - MAE: 0.0311 - val_loss: 0.0659 - val_MAE: 0.0659\n",
      "Epoch 434/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0309 - MAE: 0.0309 - val_loss: 0.0692 - val_MAE: 0.0692\n",
      "Epoch 435/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0323 - MAE: 0.0323 - val_loss: 0.0674 - val_MAE: 0.0674\n",
      "Epoch 436/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0348 - MAE: 0.0348 - val_loss: 0.0716 - val_MAE: 0.0716\n",
      "Epoch 437/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0333 - MAE: 0.0333 - val_loss: 0.0631 - val_MAE: 0.0631\n",
      "Epoch 438/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0315 - MAE: 0.0315 - val_loss: 0.0629 - val_MAE: 0.0629\n",
      "Epoch 439/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0350 - MAE: 0.0350 - val_loss: 0.0683 - val_MAE: 0.0683\n",
      "Epoch 440/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0308 - MAE: 0.0308 - val_loss: 0.0651 - val_MAE: 0.0651\n",
      "Epoch 441/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0311 - MAE: 0.0311 - val_loss: 0.0657 - val_MAE: 0.0657\n",
      "Epoch 442/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0341 - MAE: 0.0341 - val_loss: 0.0707 - val_MAE: 0.0707\n",
      "Epoch 443/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0330 - MAE: 0.0330 - val_loss: 0.0643 - val_MAE: 0.0643\n",
      "Epoch 444/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0311 - MAE: 0.0311 - val_loss: 0.0629 - val_MAE: 0.0629\n",
      "Epoch 445/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0299 - MAE: 0.0299 - val_loss: 0.0641 - val_MAE: 0.0641\n",
      "Epoch 446/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0300 - MAE: 0.0300 - val_loss: 0.0663 - val_MAE: 0.0663\n",
      "Epoch 447/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0302 - MAE: 0.0302 - val_loss: 0.0648 - val_MAE: 0.0648\n",
      "Epoch 448/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0347 - MAE: 0.0347 - val_loss: 0.0781 - val_MAE: 0.0781\n",
      "Epoch 449/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0434 - MAE: 0.0434 - val_loss: 0.0673 - val_MAE: 0.0673\n",
      "Epoch 450/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0356 - MAE: 0.0356 - val_loss: 0.0673 - val_MAE: 0.0673\n",
      "Epoch 451/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0319 - MAE: 0.0319 - val_loss: 0.0666 - val_MAE: 0.0666\n",
      "Epoch 452/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0310 - MAE: 0.0310 - val_loss: 0.0631 - val_MAE: 0.0631\n",
      "Epoch 453/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0322 - MAE: 0.0322 - val_loss: 0.0638 - val_MAE: 0.0638\n",
      "Epoch 454/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0303 - MAE: 0.0303 - val_loss: 0.0652 - val_MAE: 0.0652\n",
      "Epoch 455/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0305 - MAE: 0.0305 - val_loss: 0.0645 - val_MAE: 0.0645\n",
      "Epoch 456/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0298 - MAE: 0.0298 - val_loss: 0.0647 - val_MAE: 0.0647\n",
      "Epoch 457/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0310 - MAE: 0.0310 - val_loss: 0.0642 - val_MAE: 0.0642\n",
      "Epoch 458/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0302 - MAE: 0.0302 - val_loss: 0.0628 - val_MAE: 0.0628\n",
      "Epoch 459/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0340 - MAE: 0.0340 - val_loss: 0.0718 - val_MAE: 0.0718\n",
      "Epoch 460/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0373 - MAE: 0.0373 - val_loss: 0.0641 - val_MAE: 0.0641\n",
      "Epoch 461/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0314 - MAE: 0.0314 - val_loss: 0.0640 - val_MAE: 0.0640\n",
      "Epoch 462/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0294 - MAE: 0.0294 - val_loss: 0.0661 - val_MAE: 0.0661\n",
      "Epoch 463/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0306 - MAE: 0.0306 - val_loss: 0.0659 - val_MAE: 0.0659\n",
      "Epoch 464/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0318 - MAE: 0.0318 - val_loss: 0.0641 - val_MAE: 0.0641\n",
      "Epoch 465/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0346 - MAE: 0.0346 - val_loss: 0.0706 - val_MAE: 0.0706\n",
      "Epoch 466/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0321 - MAE: 0.0321 - val_loss: 0.0644 - val_MAE: 0.0644\n",
      "Epoch 467/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0296 - MAE: 0.0296 - val_loss: 0.0702 - val_MAE: 0.0702\n",
      "Epoch 468/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0305 - MAE: 0.0305 - val_loss: 0.0650 - val_MAE: 0.0650\n",
      "Epoch 469/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0302 - MAE: 0.0302 - val_loss: 0.0667 - val_MAE: 0.0667\n",
      "Epoch 470/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0298 - MAE: 0.0298 - val_loss: 0.0658 - val_MAE: 0.0658\n",
      "Epoch 471/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0285 - MAE: 0.0285 - val_loss: 0.0647 - val_MAE: 0.0647\n",
      "Epoch 472/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0307 - MAE: 0.0307 - val_loss: 0.0717 - val_MAE: 0.0717\n",
      "Epoch 473/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0345 - MAE: 0.0345 - val_loss: 0.0623 - val_MAE: 0.0623\n",
      "Epoch 474/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0331 - MAE: 0.0331 - val_loss: 0.0649 - val_MAE: 0.0649\n",
      "Epoch 475/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0352 - MAE: 0.0352 - val_loss: 0.0676 - val_MAE: 0.0676\n",
      "Epoch 476/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0340 - MAE: 0.0340 - val_loss: 0.0656 - val_MAE: 0.0656\n",
      "Epoch 477/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0346 - MAE: 0.0346 - val_loss: 0.0684 - val_MAE: 0.0684\n",
      "Epoch 478/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0323 - MAE: 0.0323 - val_loss: 0.0650 - val_MAE: 0.0650\n",
      "Epoch 479/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0320 - MAE: 0.0320 - val_loss: 0.0645 - val_MAE: 0.0645\n",
      "Epoch 480/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0361 - MAE: 0.0361 - val_loss: 0.0720 - val_MAE: 0.0720\n",
      "Epoch 481/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0345 - MAE: 0.0345 - val_loss: 0.0643 - val_MAE: 0.0643\n",
      "Epoch 482/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0317 - MAE: 0.0317 - val_loss: 0.0684 - val_MAE: 0.0684\n",
      "Epoch 483/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0319 - MAE: 0.0319 - val_loss: 0.0679 - val_MAE: 0.0679\n",
      "Epoch 484/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0351 - MAE: 0.0351 - val_loss: 0.0635 - val_MAE: 0.0635\n",
      "Epoch 485/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0320 - MAE: 0.0320 - val_loss: 0.0712 - val_MAE: 0.0712\n",
      "Epoch 486/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0309 - MAE: 0.0309 - val_loss: 0.0655 - val_MAE: 0.0655\n",
      "Epoch 487/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0294 - MAE: 0.0294 - val_loss: 0.0717 - val_MAE: 0.0717\n",
      "Epoch 488/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0310 - MAE: 0.0310 - val_loss: 0.0649 - val_MAE: 0.0649\n",
      "Epoch 489/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0293 - MAE: 0.0293 - val_loss: 0.0631 - val_MAE: 0.0631\n",
      "Epoch 490/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0325 - MAE: 0.0325 - val_loss: 0.0651 - val_MAE: 0.0651\n",
      "Epoch 491/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0282 - MAE: 0.0282 - val_loss: 0.0632 - val_MAE: 0.0632\n",
      "Epoch 492/1000\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0289 - MAE: 0.0289 - val_loss: 0.0698 - val_MAE: 0.0698\n",
      "Epoch 493/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0317 - MAE: 0.0317 - val_loss: 0.0637 - val_MAE: 0.0637\n",
      "Epoch 494/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0294 - MAE: 0.0294 - val_loss: 0.0649 - val_MAE: 0.0649\n",
      "Epoch 495/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0283 - MAE: 0.0283 - val_loss: 0.0646 - val_MAE: 0.0646\n",
      "Epoch 496/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0280 - MAE: 0.0280 - val_loss: 0.0655 - val_MAE: 0.0655\n",
      "Epoch 497/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0281 - MAE: 0.0281 - val_loss: 0.0657 - val_MAE: 0.0657\n",
      "Epoch 498/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0281 - MAE: 0.0281 - val_loss: 0.0699 - val_MAE: 0.0699\n",
      "Epoch 499/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0350 - MAE: 0.0350 - val_loss: 0.0633 - val_MAE: 0.0633\n",
      "Epoch 500/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0357 - MAE: 0.0357 - val_loss: 0.0723 - val_MAE: 0.0723\n",
      "Epoch 501/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0345 - MAE: 0.0345 - val_loss: 0.0632 - val_MAE: 0.0632\n",
      "Epoch 502/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0352 - MAE: 0.0352 - val_loss: 0.0757 - val_MAE: 0.0757\n",
      "Epoch 503/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0400 - MAE: 0.0400 - val_loss: 0.0641 - val_MAE: 0.0641\n",
      "Epoch 504/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0345 - MAE: 0.0345 - val_loss: 0.0683 - val_MAE: 0.0683\n",
      "Epoch 505/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0307 - MAE: 0.0307 - val_loss: 0.0617 - val_MAE: 0.0617\n",
      "Epoch 506/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0300 - MAE: 0.0300 - val_loss: 0.0665 - val_MAE: 0.0665\n",
      "Epoch 507/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0291 - MAE: 0.0291 - val_loss: 0.0697 - val_MAE: 0.0697\n",
      "Epoch 508/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0304 - MAE: 0.0304 - val_loss: 0.0666 - val_MAE: 0.0666\n",
      "Epoch 509/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0310 - MAE: 0.0310 - val_loss: 0.0628 - val_MAE: 0.0628\n",
      "Epoch 510/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0312 - MAE: 0.0312 - val_loss: 0.0647 - val_MAE: 0.0647\n",
      "Epoch 511/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0288 - MAE: 0.0288 - val_loss: 0.0637 - val_MAE: 0.0637\n",
      "Epoch 512/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0281 - MAE: 0.0281 - val_loss: 0.0634 - val_MAE: 0.0634\n",
      "Epoch 513/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0280 - MAE: 0.0280 - val_loss: 0.0679 - val_MAE: 0.0679\n",
      "Epoch 514/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0279 - MAE: 0.0279 - val_loss: 0.0654 - val_MAE: 0.0654\n",
      "Epoch 515/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0276 - MAE: 0.0276 - val_loss: 0.0628 - val_MAE: 0.0628\n",
      "Epoch 516/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0283 - MAE: 0.0283 - val_loss: 0.0698 - val_MAE: 0.0698\n",
      "Epoch 517/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0293 - MAE: 0.0293 - val_loss: 0.0639 - val_MAE: 0.0639\n",
      "Epoch 518/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0275 - MAE: 0.0275 - val_loss: 0.0652 - val_MAE: 0.0652\n",
      "Epoch 519/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0276 - MAE: 0.0276 - val_loss: 0.0657 - val_MAE: 0.0657\n",
      "Epoch 520/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0270 - MAE: 0.0270 - val_loss: 0.0653 - val_MAE: 0.0653\n",
      "Epoch 521/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0292 - MAE: 0.0292 - val_loss: 0.0636 - val_MAE: 0.0636\n",
      "Epoch 522/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0291 - MAE: 0.0291 - val_loss: 0.0643 - val_MAE: 0.0643\n",
      "Epoch 523/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0288 - MAE: 0.0288 - val_loss: 0.0623 - val_MAE: 0.0623\n",
      "Epoch 524/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0288 - MAE: 0.0288 - val_loss: 0.0661 - val_MAE: 0.0661\n",
      "Epoch 525/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0288 - MAE: 0.0288 - val_loss: 0.0660 - val_MAE: 0.0660\n",
      "Epoch 526/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0278 - MAE: 0.0278 - val_loss: 0.0646 - val_MAE: 0.0646\n",
      "Epoch 527/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0270 - MAE: 0.0270 - val_loss: 0.0653 - val_MAE: 0.0653\n",
      "Epoch 528/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0284 - MAE: 0.0284 - val_loss: 0.0623 - val_MAE: 0.0623\n",
      "Epoch 529/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0275 - MAE: 0.0275 - val_loss: 0.0695 - val_MAE: 0.0695\n",
      "Epoch 530/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0299 - MAE: 0.0299 - val_loss: 0.0634 - val_MAE: 0.0634\n",
      "Epoch 531/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0268 - MAE: 0.0268 - val_loss: 0.0646 - val_MAE: 0.0646\n",
      "Epoch 532/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0266 - MAE: 0.0266 - val_loss: 0.0619 - val_MAE: 0.0619\n",
      "Epoch 533/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0313 - MAE: 0.0313 - val_loss: 0.0702 - val_MAE: 0.0702\n",
      "Epoch 534/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0302 - MAE: 0.0302 - val_loss: 0.0624 - val_MAE: 0.0624\n",
      "Epoch 535/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0281 - MAE: 0.0281 - val_loss: 0.0623 - val_MAE: 0.0623\n",
      "Epoch 536/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0343 - MAE: 0.0343 - val_loss: 0.0770 - val_MAE: 0.0770\n",
      "Epoch 537/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0349 - MAE: 0.0349 - val_loss: 0.0645 - val_MAE: 0.0645\n",
      "Epoch 538/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0332 - MAE: 0.0332 - val_loss: 0.0754 - val_MAE: 0.0754\n",
      "Epoch 539/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0317 - MAE: 0.0317 - val_loss: 0.0647 - val_MAE: 0.0647\n",
      "Epoch 540/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0342 - MAE: 0.0342 - val_loss: 0.0675 - val_MAE: 0.0675\n",
      "Epoch 541/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0287 - MAE: 0.0287 - val_loss: 0.0673 - val_MAE: 0.0673\n",
      "Epoch 542/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0319 - MAE: 0.0319 - val_loss: 0.0635 - val_MAE: 0.0635\n",
      "Epoch 543/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0293 - MAE: 0.0293 - val_loss: 0.0699 - val_MAE: 0.0699\n",
      "Epoch 544/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0291 - MAE: 0.0291 - val_loss: 0.0625 - val_MAE: 0.0625\n",
      "Epoch 545/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0282 - MAE: 0.0282 - val_loss: 0.0609 - val_MAE: 0.0609\n",
      "Epoch 546/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0271 - MAE: 0.0271 - val_loss: 0.0613 - val_MAE: 0.0613\n",
      "Epoch 547/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0290 - MAE: 0.0290 - val_loss: 0.0694 - val_MAE: 0.0694\n",
      "Epoch 548/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0296 - MAE: 0.0296 - val_loss: 0.0622 - val_MAE: 0.0622\n",
      "Epoch 549/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0296 - MAE: 0.0296 - val_loss: 0.0614 - val_MAE: 0.0614\n",
      "Epoch 550/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0278 - MAE: 0.0278 - val_loss: 0.0631 - val_MAE: 0.0631\n",
      "Epoch 551/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0270 - MAE: 0.0270 - val_loss: 0.0653 - val_MAE: 0.0653\n",
      "Epoch 552/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0263 - MAE: 0.0263 - val_loss: 0.0618 - val_MAE: 0.0618\n",
      "Epoch 553/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0324 - MAE: 0.0324 - val_loss: 0.0664 - val_MAE: 0.0664\n",
      "Epoch 554/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0268 - MAE: 0.0268 - val_loss: 0.0682 - val_MAE: 0.0682\n",
      "Epoch 555/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0312 - MAE: 0.0312 - val_loss: 0.0641 - val_MAE: 0.0641\n",
      "Epoch 556/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0291 - MAE: 0.0291 - val_loss: 0.0646 - val_MAE: 0.0646\n",
      "Epoch 557/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0275 - MAE: 0.0275 - val_loss: 0.0666 - val_MAE: 0.0666\n",
      "Epoch 558/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0273 - MAE: 0.0273 - val_loss: 0.0613 - val_MAE: 0.0613\n",
      "Epoch 559/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0293 - MAE: 0.0293 - val_loss: 0.0668 - val_MAE: 0.0668\n",
      "Epoch 560/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0285 - MAE: 0.0285 - val_loss: 0.0672 - val_MAE: 0.0672\n",
      "Epoch 561/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0294 - MAE: 0.0294 - val_loss: 0.0657 - val_MAE: 0.0657\n",
      "Epoch 562/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0264 - MAE: 0.0264 - val_loss: 0.0617 - val_MAE: 0.0617\n",
      "Epoch 563/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0301 - MAE: 0.0301 - val_loss: 0.0763 - val_MAE: 0.0763\n",
      "Epoch 564/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0432 - MAE: 0.0432 - val_loss: 0.0656 - val_MAE: 0.0656\n",
      "Epoch 565/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0369 - MAE: 0.0369 - val_loss: 0.0711 - val_MAE: 0.0711\n",
      "Epoch 566/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0289 - MAE: 0.0289 - val_loss: 0.0626 - val_MAE: 0.0626\n",
      "Epoch 567/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0270 - MAE: 0.0270 - val_loss: 0.0652 - val_MAE: 0.0652\n",
      "Epoch 568/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0272 - MAE: 0.0272 - val_loss: 0.0687 - val_MAE: 0.0687\n",
      "Epoch 569/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0275 - MAE: 0.0275 - val_loss: 0.0684 - val_MAE: 0.0684\n",
      "Epoch 570/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0329 - MAE: 0.0329 - val_loss: 0.0589 - val_MAE: 0.0589\n",
      "Epoch 571/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0337 - MAE: 0.0337 - val_loss: 0.0702 - val_MAE: 0.0702\n",
      "Epoch 572/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0298 - MAE: 0.0298 - val_loss: 0.0622 - val_MAE: 0.0622\n",
      "Epoch 573/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0296 - MAE: 0.0296 - val_loss: 0.0634 - val_MAE: 0.0634\n",
      "Epoch 574/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0289 - MAE: 0.0289 - val_loss: 0.0710 - val_MAE: 0.0710\n",
      "Epoch 575/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0355 - MAE: 0.0355 - val_loss: 0.0618 - val_MAE: 0.0618\n",
      "Epoch 576/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0273 - MAE: 0.0273 - val_loss: 0.0651 - val_MAE: 0.0651\n",
      "Epoch 577/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0265 - MAE: 0.0265 - val_loss: 0.0619 - val_MAE: 0.0619\n",
      "Epoch 578/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0269 - MAE: 0.0269 - val_loss: 0.0664 - val_MAE: 0.0664\n",
      "Epoch 579/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0268 - MAE: 0.0268 - val_loss: 0.0674 - val_MAE: 0.0674\n",
      "Epoch 580/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0279 - MAE: 0.0279 - val_loss: 0.0642 - val_MAE: 0.0642\n",
      "Epoch 581/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0277 - MAE: 0.0277 - val_loss: 0.0638 - val_MAE: 0.0638\n",
      "Epoch 582/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0300 - MAE: 0.0300 - val_loss: 0.0690 - val_MAE: 0.0690\n",
      "Epoch 583/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0278 - MAE: 0.0278 - val_loss: 0.0622 - val_MAE: 0.0622\n",
      "Epoch 584/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0271 - MAE: 0.0271 - val_loss: 0.0629 - val_MAE: 0.0629\n",
      "Epoch 585/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0301 - MAE: 0.0301 - val_loss: 0.0706 - val_MAE: 0.0706\n",
      "Epoch 586/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0275 - MAE: 0.0275 - val_loss: 0.0640 - val_MAE: 0.0640\n",
      "Epoch 587/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0281 - MAE: 0.0281 - val_loss: 0.0648 - val_MAE: 0.0648\n",
      "Epoch 588/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0283 - MAE: 0.0283 - val_loss: 0.0620 - val_MAE: 0.0620\n",
      "Epoch 589/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0258 - MAE: 0.0258 - val_loss: 0.0623 - val_MAE: 0.0623\n",
      "Epoch 590/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0256 - MAE: 0.0256 - val_loss: 0.0656 - val_MAE: 0.0656\n",
      "Epoch 591/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0271 - MAE: 0.0271 - val_loss: 0.0662 - val_MAE: 0.0662\n",
      "Epoch 592/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0258 - MAE: 0.0258 - val_loss: 0.0679 - val_MAE: 0.0679\n",
      "Epoch 593/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0272 - MAE: 0.0272 - val_loss: 0.0613 - val_MAE: 0.0613\n",
      "Epoch 594/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0271 - MAE: 0.0271 - val_loss: 0.0703 - val_MAE: 0.0703\n",
      "Epoch 595/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0294 - MAE: 0.0294 - val_loss: 0.0616 - val_MAE: 0.0616\n",
      "Epoch 596/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0255 - MAE: 0.0255 - val_loss: 0.0662 - val_MAE: 0.0662\n",
      "Epoch 597/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0264 - MAE: 0.0264 - val_loss: 0.0655 - val_MAE: 0.0655\n",
      "Epoch 598/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0264 - MAE: 0.0264 - val_loss: 0.0647 - val_MAE: 0.0647\n",
      "Epoch 599/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0248 - MAE: 0.0248 - val_loss: 0.0681 - val_MAE: 0.0681\n",
      "Epoch 600/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0273 - MAE: 0.0273 - val_loss: 0.0629 - val_MAE: 0.0629\n",
      "Epoch 601/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0266 - MAE: 0.0266 - val_loss: 0.0658 - val_MAE: 0.0658\n",
      "Epoch 602/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0257 - MAE: 0.0257 - val_loss: 0.0691 - val_MAE: 0.0691\n",
      "Epoch 603/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0274 - MAE: 0.0274 - val_loss: 0.0665 - val_MAE: 0.0665\n",
      "Epoch 604/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0261 - MAE: 0.0261 - val_loss: 0.0623 - val_MAE: 0.0623\n",
      "Epoch 605/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0373 - MAE: 0.0373 - val_loss: 0.0701 - val_MAE: 0.0701\n",
      "Epoch 606/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0288 - MAE: 0.0288 - val_loss: 0.0624 - val_MAE: 0.0624\n",
      "Epoch 607/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0292 - MAE: 0.0292 - val_loss: 0.0666 - val_MAE: 0.0666\n",
      "Epoch 608/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0263 - MAE: 0.0263 - val_loss: 0.0677 - val_MAE: 0.0677\n",
      "Epoch 609/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0247 - MAE: 0.0247 - val_loss: 0.0632 - val_MAE: 0.0632\n",
      "Epoch 610/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0247 - MAE: 0.0247 - val_loss: 0.0672 - val_MAE: 0.0672\n",
      "Epoch 611/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0268 - MAE: 0.0268 - val_loss: 0.0633 - val_MAE: 0.0633\n",
      "Epoch 612/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0281 - MAE: 0.0281 - val_loss: 0.0726 - val_MAE: 0.0726\n",
      "Epoch 613/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0266 - MAE: 0.0266 - val_loss: 0.0672 - val_MAE: 0.0672\n",
      "Epoch 614/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0273 - MAE: 0.0273 - val_loss: 0.0615 - val_MAE: 0.0615\n",
      "Epoch 615/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0268 - MAE: 0.0268 - val_loss: 0.0619 - val_MAE: 0.0619\n",
      "Epoch 616/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0263 - MAE: 0.0263 - val_loss: 0.0662 - val_MAE: 0.0662\n",
      "Epoch 617/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0258 - MAE: 0.0258 - val_loss: 0.0633 - val_MAE: 0.0633\n",
      "Epoch 618/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0278 - MAE: 0.0278 - val_loss: 0.0650 - val_MAE: 0.0650\n",
      "Epoch 619/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0284 - MAE: 0.0284 - val_loss: 0.0679 - val_MAE: 0.0679\n",
      "Epoch 620/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0276 - MAE: 0.0276 - val_loss: 0.0695 - val_MAE: 0.0695\n",
      "Epoch 621/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0290 - MAE: 0.0290 - val_loss: 0.0619 - val_MAE: 0.0619\n",
      "Epoch 622/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0252 - MAE: 0.0252 - val_loss: 0.0613 - val_MAE: 0.0613\n",
      "Epoch 623/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0277 - MAE: 0.0277 - val_loss: 0.0626 - val_MAE: 0.0626\n",
      "Epoch 624/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0262 - MAE: 0.0262 - val_loss: 0.0652 - val_MAE: 0.0652\n",
      "Epoch 625/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0258 - MAE: 0.0258 - val_loss: 0.0667 - val_MAE: 0.0667\n",
      "Epoch 626/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0249 - MAE: 0.0249 - val_loss: 0.0610 - val_MAE: 0.0610\n",
      "Epoch 627/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0258 - MAE: 0.0258 - val_loss: 0.0685 - val_MAE: 0.0685\n",
      "Epoch 628/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0272 - MAE: 0.0272 - val_loss: 0.0657 - val_MAE: 0.0657\n",
      "Epoch 629/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0247 - MAE: 0.0247 - val_loss: 0.0660 - val_MAE: 0.0660\n",
      "Epoch 630/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0245 - MAE: 0.0245 - val_loss: 0.0653 - val_MAE: 0.0653\n",
      "Epoch 631/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0242 - MAE: 0.0242 - val_loss: 0.0638 - val_MAE: 0.0638\n",
      "Epoch 632/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0242 - MAE: 0.0242 - val_loss: 0.0630 - val_MAE: 0.0630\n",
      "Epoch 633/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0328 - MAE: 0.0328 - val_loss: 0.0800 - val_MAE: 0.0800\n",
      "Epoch 634/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0373 - MAE: 0.0373 - val_loss: 0.0687 - val_MAE: 0.0687\n",
      "Epoch 635/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0404 - MAE: 0.0404 - val_loss: 0.0765 - val_MAE: 0.0765\n",
      "Epoch 636/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0339 - MAE: 0.0339 - val_loss: 0.0617 - val_MAE: 0.0617\n",
      "Epoch 637/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0280 - MAE: 0.0280 - val_loss: 0.0682 - val_MAE: 0.0682\n",
      "Epoch 638/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0302 - MAE: 0.0302 - val_loss: 0.0702 - val_MAE: 0.0702\n",
      "Epoch 639/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0357 - MAE: 0.0357 - val_loss: 0.0601 - val_MAE: 0.0601\n",
      "Epoch 640/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0458 - MAE: 0.0458 - val_loss: 0.0651 - val_MAE: 0.0651\n",
      "Epoch 641/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0268 - MAE: 0.0268 - val_loss: 0.0630 - val_MAE: 0.0630\n",
      "Epoch 642/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0330 - MAE: 0.0330 - val_loss: 0.0679 - val_MAE: 0.0679\n",
      "Epoch 643/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0265 - MAE: 0.0265 - val_loss: 0.0642 - val_MAE: 0.0642\n",
      "Epoch 644/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0313 - MAE: 0.0313 - val_loss: 0.0609 - val_MAE: 0.0609\n",
      "Epoch 645/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0306 - MAE: 0.0306 - val_loss: 0.0677 - val_MAE: 0.0677\n",
      "Epoch 646/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0269 - MAE: 0.0269 - val_loss: 0.0638 - val_MAE: 0.0638\n",
      "Epoch 647/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0278 - MAE: 0.0278 - val_loss: 0.0625 - val_MAE: 0.0625\n",
      "Epoch 648/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0307 - MAE: 0.0307 - val_loss: 0.0705 - val_MAE: 0.0705\n",
      "Epoch 649/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0280 - MAE: 0.0280 - val_loss: 0.0619 - val_MAE: 0.0619\n",
      "Epoch 650/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0239 - MAE: 0.0239 - val_loss: 0.0662 - val_MAE: 0.0662\n",
      "Epoch 651/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0249 - MAE: 0.0249 - val_loss: 0.0629 - val_MAE: 0.0629\n",
      "Epoch 652/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0266 - MAE: 0.0266 - val_loss: 0.0655 - val_MAE: 0.0655\n",
      "Epoch 653/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0252 - MAE: 0.0252 - val_loss: 0.0666 - val_MAE: 0.0666\n",
      "Epoch 654/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0265 - MAE: 0.0265 - val_loss: 0.0629 - val_MAE: 0.0629\n",
      "Epoch 655/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0266 - MAE: 0.0266 - val_loss: 0.0733 - val_MAE: 0.0733\n",
      "Epoch 656/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0271 - MAE: 0.0271 - val_loss: 0.0646 - val_MAE: 0.0646\n",
      "Epoch 657/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0268 - MAE: 0.0268 - val_loss: 0.0616 - val_MAE: 0.0616\n",
      "Epoch 658/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0254 - MAE: 0.0254 - val_loss: 0.0640 - val_MAE: 0.0640\n",
      "Epoch 659/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0266 - MAE: 0.0266 - val_loss: 0.0697 - val_MAE: 0.0697\n",
      "Epoch 660/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0320 - MAE: 0.0320 - val_loss: 0.0648 - val_MAE: 0.0648\n",
      "Epoch 661/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0345 - MAE: 0.0345 - val_loss: 0.0707 - val_MAE: 0.0707\n",
      "Epoch 662/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0304 - MAE: 0.0304 - val_loss: 0.0593 - val_MAE: 0.0593\n",
      "Epoch 663/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0277 - MAE: 0.0277 - val_loss: 0.0672 - val_MAE: 0.0672\n",
      "Epoch 664/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0264 - MAE: 0.0264 - val_loss: 0.0637 - val_MAE: 0.0637\n",
      "Epoch 665/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0244 - MAE: 0.0244 - val_loss: 0.0649 - val_MAE: 0.0649\n",
      "Epoch 666/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0238 - MAE: 0.0238 - val_loss: 0.0634 - val_MAE: 0.0634\n",
      "Epoch 667/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0243 - MAE: 0.0243 - val_loss: 0.0630 - val_MAE: 0.0630\n",
      "Epoch 668/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0251 - MAE: 0.0251 - val_loss: 0.0614 - val_MAE: 0.0614\n",
      "Epoch 669/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0287 - MAE: 0.0287 - val_loss: 0.0705 - val_MAE: 0.0705\n",
      "Epoch 670/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0268 - MAE: 0.0268 - val_loss: 0.0622 - val_MAE: 0.0622\n",
      "Epoch 671/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0244 - MAE: 0.0244 - val_loss: 0.0619 - val_MAE: 0.0619\n",
      "Epoch 672/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0241 - MAE: 0.0241 - val_loss: 0.0611 - val_MAE: 0.0611\n",
      "Epoch 673/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0238 - MAE: 0.0238 - val_loss: 0.0607 - val_MAE: 0.0607\n",
      "Epoch 674/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0289 - MAE: 0.0289 - val_loss: 0.0697 - val_MAE: 0.0697\n",
      "Epoch 675/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0274 - MAE: 0.0274 - val_loss: 0.0635 - val_MAE: 0.0635\n",
      "Epoch 676/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0286 - MAE: 0.0286 - val_loss: 0.0684 - val_MAE: 0.0684\n",
      "Epoch 677/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0256 - MAE: 0.0256 - val_loss: 0.0622 - val_MAE: 0.0622\n",
      "Epoch 678/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0263 - MAE: 0.0263 - val_loss: 0.0647 - val_MAE: 0.0647\n",
      "Epoch 679/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0231 - MAE: 0.0231 - val_loss: 0.0667 - val_MAE: 0.0667\n",
      "Epoch 680/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0267 - MAE: 0.0267 - val_loss: 0.0633 - val_MAE: 0.0633\n",
      "Epoch 681/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0279 - MAE: 0.0279 - val_loss: 0.0721 - val_MAE: 0.0721\n",
      "Epoch 682/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0259 - MAE: 0.0259 - val_loss: 0.0646 - val_MAE: 0.0646\n",
      "Epoch 683/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0282 - MAE: 0.0282 - val_loss: 0.0599 - val_MAE: 0.0599\n",
      "Epoch 684/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0245 - MAE: 0.0245 - val_loss: 0.0592 - val_MAE: 0.0592\n",
      "Epoch 685/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0300 - MAE: 0.0300 - val_loss: 0.0660 - val_MAE: 0.0660\n",
      "Epoch 686/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0241 - MAE: 0.0241 - val_loss: 0.0654 - val_MAE: 0.0654\n",
      "Epoch 687/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0269 - MAE: 0.0269 - val_loss: 0.0625 - val_MAE: 0.0625\n",
      "Epoch 688/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0261 - MAE: 0.0261 - val_loss: 0.0700 - val_MAE: 0.0700\n",
      "Epoch 689/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0266 - MAE: 0.0266 - val_loss: 0.0643 - val_MAE: 0.0643\n",
      "Epoch 690/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0239 - MAE: 0.0239 - val_loss: 0.0654 - val_MAE: 0.0654\n",
      "Epoch 691/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0235 - MAE: 0.0235 - val_loss: 0.0641 - val_MAE: 0.0641\n",
      "Epoch 692/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0225 - MAE: 0.0225 - val_loss: 0.0617 - val_MAE: 0.0617\n",
      "Epoch 693/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0242 - MAE: 0.0242 - val_loss: 0.0638 - val_MAE: 0.0638\n",
      "Epoch 694/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0233 - MAE: 0.0233 - val_loss: 0.0726 - val_MAE: 0.0726\n",
      "Epoch 695/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0289 - MAE: 0.0289 - val_loss: 0.0655 - val_MAE: 0.0655\n",
      "Epoch 696/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0275 - MAE: 0.0275 - val_loss: 0.0679 - val_MAE: 0.0679\n",
      "Epoch 697/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0265 - MAE: 0.0265 - val_loss: 0.0599 - val_MAE: 0.0599\n",
      "Epoch 698/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0243 - MAE: 0.0243 - val_loss: 0.0670 - val_MAE: 0.0670\n",
      "Epoch 699/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0252 - MAE: 0.0252 - val_loss: 0.0665 - val_MAE: 0.0665\n",
      "Epoch 700/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0288 - MAE: 0.0288 - val_loss: 0.0664 - val_MAE: 0.0664\n",
      "Epoch 701/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0277 - MAE: 0.0277 - val_loss: 0.0656 - val_MAE: 0.0656\n",
      "Epoch 702/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0235 - MAE: 0.0235 - val_loss: 0.0643 - val_MAE: 0.0643\n",
      "Epoch 703/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0221 - MAE: 0.0221 - val_loss: 0.0640 - val_MAE: 0.0640\n",
      "Epoch 704/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0239 - MAE: 0.0239 - val_loss: 0.0668 - val_MAE: 0.0668\n",
      "Epoch 705/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0232 - MAE: 0.0232 - val_loss: 0.0703 - val_MAE: 0.0703\n",
      "Epoch 706/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0301 - MAE: 0.0301 - val_loss: 0.0620 - val_MAE: 0.0620\n",
      "Epoch 707/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0318 - MAE: 0.0318 - val_loss: 0.0716 - val_MAE: 0.0716\n",
      "Epoch 708/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0265 - MAE: 0.0265 - val_loss: 0.0635 - val_MAE: 0.0635\n",
      "Epoch 709/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0239 - MAE: 0.0239 - val_loss: 0.0689 - val_MAE: 0.0689\n",
      "Epoch 710/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0243 - MAE: 0.0243 - val_loss: 0.0636 - val_MAE: 0.0636\n",
      "Epoch 711/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0256 - MAE: 0.0256 - val_loss: 0.0661 - val_MAE: 0.0661\n",
      "Epoch 712/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0227 - MAE: 0.0227 - val_loss: 0.0612 - val_MAE: 0.0612\n",
      "Epoch 713/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0222 - MAE: 0.0222 - val_loss: 0.0667 - val_MAE: 0.0667\n",
      "Epoch 714/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0230 - MAE: 0.0230 - val_loss: 0.0639 - val_MAE: 0.0639\n",
      "Epoch 715/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0223 - MAE: 0.0223 - val_loss: 0.0638 - val_MAE: 0.0638\n",
      "Epoch 716/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0220 - MAE: 0.0220 - val_loss: 0.0670 - val_MAE: 0.0670\n",
      "Epoch 717/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0243 - MAE: 0.0243 - val_loss: 0.0632 - val_MAE: 0.0632\n",
      "Epoch 718/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0252 - MAE: 0.0252 - val_loss: 0.0654 - val_MAE: 0.0654\n",
      "Epoch 719/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0245 - MAE: 0.0245 - val_loss: 0.0651 - val_MAE: 0.0651\n",
      "Epoch 720/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0232 - MAE: 0.0232 - val_loss: 0.0629 - val_MAE: 0.0629\n",
      "Epoch 721/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0229 - MAE: 0.0229 - val_loss: 0.0653 - val_MAE: 0.0653\n",
      "Epoch 722/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0229 - MAE: 0.0229 - val_loss: 0.0632 - val_MAE: 0.0632\n",
      "Epoch 723/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0220 - MAE: 0.0220 - val_loss: 0.0635 - val_MAE: 0.0635\n",
      "Epoch 724/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0249 - MAE: 0.0249 - val_loss: 0.0620 - val_MAE: 0.0620\n",
      "Epoch 725/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0234 - MAE: 0.0234 - val_loss: 0.0605 - val_MAE: 0.0605\n",
      "Epoch 726/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0231 - MAE: 0.0231 - val_loss: 0.0638 - val_MAE: 0.0638\n",
      "Epoch 727/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0217 - MAE: 0.0217 - val_loss: 0.0626 - val_MAE: 0.0626\n",
      "Epoch 728/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0237 - MAE: 0.0237 - val_loss: 0.0700 - val_MAE: 0.0700\n",
      "Epoch 729/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0233 - MAE: 0.0233 - val_loss: 0.0642 - val_MAE: 0.0642\n",
      "Epoch 730/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0212 - MAE: 0.0212 - val_loss: 0.0650 - val_MAE: 0.0650\n",
      "Epoch 731/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0222 - MAE: 0.0222 - val_loss: 0.0620 - val_MAE: 0.0620\n",
      "Epoch 732/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0218 - MAE: 0.0218 - val_loss: 0.0644 - val_MAE: 0.0644\n",
      "Epoch 733/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0227 - MAE: 0.0227 - val_loss: 0.0636 - val_MAE: 0.0636\n",
      "Epoch 734/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0222 - MAE: 0.0222 - val_loss: 0.0710 - val_MAE: 0.0710\n",
      "Epoch 735/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0267 - MAE: 0.0267 - val_loss: 0.0628 - val_MAE: 0.0628\n",
      "Epoch 736/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0276 - MAE: 0.0276 - val_loss: 0.0694 - val_MAE: 0.0694\n",
      "Epoch 737/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0260 - MAE: 0.0260 - val_loss: 0.0637 - val_MAE: 0.0637\n",
      "Epoch 738/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0263 - MAE: 0.0263 - val_loss: 0.0603 - val_MAE: 0.0603\n",
      "Epoch 739/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0278 - MAE: 0.0278 - val_loss: 0.0676 - val_MAE: 0.0676\n",
      "Epoch 740/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0246 - MAE: 0.0246 - val_loss: 0.0590 - val_MAE: 0.0590\n",
      "Epoch 741/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0241 - MAE: 0.0241 - val_loss: 0.0644 - val_MAE: 0.0644\n",
      "Epoch 742/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0244 - MAE: 0.0244 - val_loss: 0.0618 - val_MAE: 0.0618\n",
      "Epoch 743/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0245 - MAE: 0.0245 - val_loss: 0.0641 - val_MAE: 0.0641\n",
      "Epoch 744/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0243 - MAE: 0.0243 - val_loss: 0.0724 - val_MAE: 0.0724\n",
      "Epoch 745/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0285 - MAE: 0.0285 - val_loss: 0.0611 - val_MAE: 0.0611\n",
      "Epoch 746/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0241 - MAE: 0.0241 - val_loss: 0.0670 - val_MAE: 0.0670\n",
      "Epoch 747/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0232 - MAE: 0.0232 - val_loss: 0.0639 - val_MAE: 0.0639\n",
      "Epoch 748/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0229 - MAE: 0.0229 - val_loss: 0.0607 - val_MAE: 0.0607\n",
      "Epoch 749/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0226 - MAE: 0.0226 - val_loss: 0.0636 - val_MAE: 0.0636\n",
      "Epoch 750/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0239 - MAE: 0.0239 - val_loss: 0.0686 - val_MAE: 0.0686\n",
      "Epoch 751/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0223 - MAE: 0.0223 - val_loss: 0.0633 - val_MAE: 0.0633\n",
      "Epoch 752/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0231 - MAE: 0.0231 - val_loss: 0.0618 - val_MAE: 0.0618\n",
      "Epoch 753/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0230 - MAE: 0.0230 - val_loss: 0.0633 - val_MAE: 0.0633\n",
      "Epoch 754/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0218 - MAE: 0.0218 - val_loss: 0.0643 - val_MAE: 0.0643\n",
      "Epoch 755/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0260 - MAE: 0.0260 - val_loss: 0.0612 - val_MAE: 0.0612\n",
      "Epoch 756/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0248 - MAE: 0.0248 - val_loss: 0.0674 - val_MAE: 0.0674\n",
      "Epoch 757/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0239 - MAE: 0.0239 - val_loss: 0.0606 - val_MAE: 0.0606\n",
      "Epoch 758/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0343 - MAE: 0.0343 - val_loss: 0.0697 - val_MAE: 0.0697\n",
      "Epoch 759/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0252 - MAE: 0.0252 - val_loss: 0.0597 - val_MAE: 0.0597\n",
      "Epoch 760/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0233 - MAE: 0.0233 - val_loss: 0.0625 - val_MAE: 0.0625\n",
      "Epoch 761/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0218 - MAE: 0.0218 - val_loss: 0.0648 - val_MAE: 0.0648\n",
      "Epoch 762/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0216 - MAE: 0.0216 - val_loss: 0.0661 - val_MAE: 0.0661\n",
      "Epoch 763/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0211 - MAE: 0.0211 - val_loss: 0.0680 - val_MAE: 0.0680\n",
      "Epoch 764/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0220 - MAE: 0.0220 - val_loss: 0.0644 - val_MAE: 0.0644\n",
      "Epoch 765/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0219 - MAE: 0.0219 - val_loss: 0.0604 - val_MAE: 0.0604\n",
      "Epoch 766/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0269 - MAE: 0.0269 - val_loss: 0.0699 - val_MAE: 0.0699\n",
      "Epoch 767/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0251 - MAE: 0.0251 - val_loss: 0.0674 - val_MAE: 0.0674\n",
      "Epoch 768/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0262 - MAE: 0.0262 - val_loss: 0.0620 - val_MAE: 0.0620\n",
      "Epoch 769/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0277 - MAE: 0.0277 - val_loss: 0.0687 - val_MAE: 0.0687\n",
      "Epoch 770/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0252 - MAE: 0.0252 - val_loss: 0.0614 - val_MAE: 0.0614\n",
      "Epoch 771/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0229 - MAE: 0.0229 - val_loss: 0.0619 - val_MAE: 0.0619\n",
      "Epoch 772/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0226 - MAE: 0.0226 - val_loss: 0.0635 - val_MAE: 0.0635\n",
      "Epoch 773/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0219 - MAE: 0.0219 - val_loss: 0.0671 - val_MAE: 0.0671\n",
      "Epoch 774/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0245 - MAE: 0.0245 - val_loss: 0.0591 - val_MAE: 0.0591\n",
      "Epoch 775/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0223 - MAE: 0.0223 - val_loss: 0.0596 - val_MAE: 0.0596\n",
      "Epoch 776/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0234 - MAE: 0.0234 - val_loss: 0.0704 - val_MAE: 0.0704\n",
      "Epoch 777/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0256 - MAE: 0.0256 - val_loss: 0.0632 - val_MAE: 0.0632\n",
      "Epoch 778/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0253 - MAE: 0.0253 - val_loss: 0.0637 - val_MAE: 0.0637\n",
      "Epoch 779/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0227 - MAE: 0.0227 - val_loss: 0.0624 - val_MAE: 0.0624\n",
      "Epoch 780/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0250 - MAE: 0.0250 - val_loss: 0.0647 - val_MAE: 0.0647\n",
      "Epoch 781/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0224 - MAE: 0.0224 - val_loss: 0.0635 - val_MAE: 0.0635\n",
      "Epoch 782/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0217 - MAE: 0.0217 - val_loss: 0.0617 - val_MAE: 0.0617\n",
      "Epoch 783/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0202 - MAE: 0.0202 - val_loss: 0.0621 - val_MAE: 0.0621\n",
      "Epoch 784/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0244 - MAE: 0.0244 - val_loss: 0.0647 - val_MAE: 0.0647\n",
      "Epoch 785/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0217 - MAE: 0.0217 - val_loss: 0.0679 - val_MAE: 0.0679\n",
      "Epoch 786/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0282 - MAE: 0.0282 - val_loss: 0.0612 - val_MAE: 0.0612\n",
      "Epoch 787/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0276 - MAE: 0.0276 - val_loss: 0.0673 - val_MAE: 0.0673\n",
      "Epoch 788/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0284 - MAE: 0.0284 - val_loss: 0.0676 - val_MAE: 0.0676\n",
      "Epoch 789/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0217 - MAE: 0.0217 - val_loss: 0.0620 - val_MAE: 0.0620\n",
      "Epoch 790/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0258 - MAE: 0.0258 - val_loss: 0.0647 - val_MAE: 0.0647\n",
      "Epoch 791/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0243 - MAE: 0.0243 - val_loss: 0.0727 - val_MAE: 0.0727\n",
      "Epoch 792/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0327 - MAE: 0.0327 - val_loss: 0.0636 - val_MAE: 0.0636\n",
      "Epoch 793/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0274 - MAE: 0.0274 - val_loss: 0.0637 - val_MAE: 0.0637\n",
      "Epoch 794/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0233 - MAE: 0.0233 - val_loss: 0.0643 - val_MAE: 0.0643\n",
      "Epoch 795/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0271 - MAE: 0.0271 - val_loss: 0.0639 - val_MAE: 0.0639\n",
      "Epoch 796/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0375 - MAE: 0.0375 - val_loss: 0.0786 - val_MAE: 0.0786\n",
      "Epoch 797/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0484 - MAE: 0.0484 - val_loss: 0.0639 - val_MAE: 0.0639\n",
      "Epoch 798/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0510 - MAE: 0.0510 - val_loss: 0.0656 - val_MAE: 0.0656\n",
      "Epoch 799/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0370 - MAE: 0.0370 - val_loss: 0.0606 - val_MAE: 0.0606\n",
      "Epoch 800/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0331 - MAE: 0.0331 - val_loss: 0.0630 - val_MAE: 0.0630\n",
      "Epoch 801/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0252 - MAE: 0.0252 - val_loss: 0.0598 - val_MAE: 0.0598\n",
      "Epoch 802/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0236 - MAE: 0.0236 - val_loss: 0.0609 - val_MAE: 0.0609\n",
      "Epoch 803/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0231 - MAE: 0.0231 - val_loss: 0.0706 - val_MAE: 0.0706\n",
      "Epoch 804/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0270 - MAE: 0.0270 - val_loss: 0.0619 - val_MAE: 0.0619\n",
      "Epoch 805/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0255 - MAE: 0.0255 - val_loss: 0.0648 - val_MAE: 0.0648\n",
      "Epoch 806/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0247 - MAE: 0.0247 - val_loss: 0.0648 - val_MAE: 0.0648\n",
      "Epoch 807/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0266 - MAE: 0.0266 - val_loss: 0.0595 - val_MAE: 0.0595\n",
      "Epoch 808/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0237 - MAE: 0.0237 - val_loss: 0.0616 - val_MAE: 0.0616\n",
      "Epoch 809/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0232 - MAE: 0.0232 - val_loss: 0.0685 - val_MAE: 0.0685\n",
      "Epoch 810/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0258 - MAE: 0.0258 - val_loss: 0.0609 - val_MAE: 0.0609\n",
      "Epoch 811/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0221 - MAE: 0.0221 - val_loss: 0.0621 - val_MAE: 0.0621\n",
      "Epoch 812/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0233 - MAE: 0.0233 - val_loss: 0.0578 - val_MAE: 0.0578\n",
      "Epoch 813/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0230 - MAE: 0.0230 - val_loss: 0.0594 - val_MAE: 0.0594\n",
      "Epoch 814/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0222 - MAE: 0.0222 - val_loss: 0.0688 - val_MAE: 0.0688\n",
      "Epoch 815/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0247 - MAE: 0.0247 - val_loss: 0.0610 - val_MAE: 0.0610\n",
      "Epoch 816/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0267 - MAE: 0.0267 - val_loss: 0.0664 - val_MAE: 0.0664\n",
      "Epoch 817/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0258 - MAE: 0.0258 - val_loss: 0.0611 - val_MAE: 0.0611\n",
      "Epoch 818/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0212 - MAE: 0.0212 - val_loss: 0.0597 - val_MAE: 0.0597\n",
      "Epoch 819/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0224 - MAE: 0.0224 - val_loss: 0.0621 - val_MAE: 0.0621\n",
      "Epoch 820/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0210 - MAE: 0.0210 - val_loss: 0.0620 - val_MAE: 0.0620\n",
      "Epoch 821/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0217 - MAE: 0.0217 - val_loss: 0.0604 - val_MAE: 0.0604\n",
      "Epoch 822/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0330 - MAE: 0.0330 - val_loss: 0.0697 - val_MAE: 0.0697\n",
      "Epoch 823/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0307 - MAE: 0.0307 - val_loss: 0.0634 - val_MAE: 0.0634\n",
      "Epoch 824/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0313 - MAE: 0.0313 - val_loss: 0.0717 - val_MAE: 0.0717\n",
      "Epoch 825/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0258 - MAE: 0.0258 - val_loss: 0.0635 - val_MAE: 0.0635\n",
      "Epoch 826/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0235 - MAE: 0.0235 - val_loss: 0.0650 - val_MAE: 0.0650\n",
      "Epoch 827/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0239 - MAE: 0.0239 - val_loss: 0.0620 - val_MAE: 0.0620\n",
      "Epoch 828/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0211 - MAE: 0.0211 - val_loss: 0.0622 - val_MAE: 0.0622\n",
      "Epoch 829/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0203 - MAE: 0.0203 - val_loss: 0.0636 - val_MAE: 0.0636\n",
      "Epoch 830/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0198 - MAE: 0.0198 - val_loss: 0.0640 - val_MAE: 0.0640\n",
      "Epoch 831/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0198 - MAE: 0.0198 - val_loss: 0.0639 - val_MAE: 0.0639\n",
      "Epoch 832/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0205 - MAE: 0.0205 - val_loss: 0.0606 - val_MAE: 0.0606\n",
      "Epoch 833/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0193 - MAE: 0.0193 - val_loss: 0.0601 - val_MAE: 0.0601\n",
      "Epoch 834/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0212 - MAE: 0.0212 - val_loss: 0.0630 - val_MAE: 0.0630\n",
      "Epoch 835/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0201 - MAE: 0.0201 - val_loss: 0.0643 - val_MAE: 0.0643\n",
      "Epoch 836/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0201 - MAE: 0.0201 - val_loss: 0.0641 - val_MAE: 0.0641\n",
      "Epoch 837/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0210 - MAE: 0.0210 - val_loss: 0.0609 - val_MAE: 0.0609\n",
      "Epoch 838/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0201 - MAE: 0.0201 - val_loss: 0.0637 - val_MAE: 0.0637\n",
      "Epoch 839/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0218 - MAE: 0.0218 - val_loss: 0.0687 - val_MAE: 0.0687\n",
      "Epoch 840/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0239 - MAE: 0.0239 - val_loss: 0.0592 - val_MAE: 0.0592\n",
      "Epoch 841/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0241 - MAE: 0.0241 - val_loss: 0.0590 - val_MAE: 0.0590\n",
      "Epoch 842/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0239 - MAE: 0.0239 - val_loss: 0.0636 - val_MAE: 0.0636\n",
      "Epoch 843/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0218 - MAE: 0.0218 - val_loss: 0.0637 - val_MAE: 0.0637\n",
      "Epoch 844/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0198 - MAE: 0.0198 - val_loss: 0.0610 - val_MAE: 0.0610\n",
      "Epoch 845/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0196 - MAE: 0.0196 - val_loss: 0.0603 - val_MAE: 0.0603\n",
      "Epoch 846/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0215 - MAE: 0.0215 - val_loss: 0.0632 - val_MAE: 0.0632\n",
      "Epoch 847/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0201 - MAE: 0.0201 - val_loss: 0.0584 - val_MAE: 0.0584\n",
      "Epoch 848/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0211 - MAE: 0.0211 - val_loss: 0.0601 - val_MAE: 0.0601\n",
      "Epoch 849/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0229 - MAE: 0.0229 - val_loss: 0.0625 - val_MAE: 0.0625\n",
      "Epoch 850/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0208 - MAE: 0.0208 - val_loss: 0.0648 - val_MAE: 0.0648\n",
      "Epoch 851/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0219 - MAE: 0.0219 - val_loss: 0.0621 - val_MAE: 0.0621\n",
      "Epoch 852/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0198 - MAE: 0.0198 - val_loss: 0.0615 - val_MAE: 0.0615\n",
      "Epoch 853/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0201 - MAE: 0.0201 - val_loss: 0.0617 - val_MAE: 0.0617\n",
      "Epoch 854/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0213 - MAE: 0.0213 - val_loss: 0.0590 - val_MAE: 0.0590\n",
      "Epoch 855/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0271 - MAE: 0.0271 - val_loss: 0.0658 - val_MAE: 0.0658\n",
      "Epoch 856/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0248 - MAE: 0.0248 - val_loss: 0.0604 - val_MAE: 0.0604\n",
      "Epoch 857/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0218 - MAE: 0.0218 - val_loss: 0.0611 - val_MAE: 0.0611\n",
      "Epoch 858/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0248 - MAE: 0.0248 - val_loss: 0.0675 - val_MAE: 0.0675\n",
      "Epoch 859/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0238 - MAE: 0.0238 - val_loss: 0.0593 - val_MAE: 0.0593\n",
      "Epoch 860/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0232 - MAE: 0.0232 - val_loss: 0.0645 - val_MAE: 0.0645\n",
      "Epoch 861/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0228 - MAE: 0.0228 - val_loss: 0.0647 - val_MAE: 0.0647\n",
      "Epoch 862/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0201 - MAE: 0.0201 - val_loss: 0.0602 - val_MAE: 0.0602\n",
      "Epoch 863/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0196 - MAE: 0.0196 - val_loss: 0.0705 - val_MAE: 0.0705\n",
      "Epoch 864/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0272 - MAE: 0.0272 - val_loss: 0.0592 - val_MAE: 0.0592\n",
      "Epoch 865/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0275 - MAE: 0.0275 - val_loss: 0.0703 - val_MAE: 0.0703\n",
      "Epoch 866/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0244 - MAE: 0.0244 - val_loss: 0.0633 - val_MAE: 0.0633\n",
      "Epoch 867/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0245 - MAE: 0.0245 - val_loss: 0.0614 - val_MAE: 0.0614\n",
      "Epoch 868/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0199 - MAE: 0.0199 - val_loss: 0.0608 - val_MAE: 0.0608\n",
      "Epoch 869/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0239 - MAE: 0.0239 - val_loss: 0.0660 - val_MAE: 0.0660\n",
      "Epoch 870/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0219 - MAE: 0.0219 - val_loss: 0.0675 - val_MAE: 0.0675\n",
      "Epoch 871/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0228 - MAE: 0.0228 - val_loss: 0.0634 - val_MAE: 0.0634\n",
      "Epoch 872/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0224 - MAE: 0.0224 - val_loss: 0.0604 - val_MAE: 0.0604\n",
      "Epoch 873/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0210 - MAE: 0.0210 - val_loss: 0.0622 - val_MAE: 0.0622\n",
      "Epoch 874/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0206 - MAE: 0.0206 - val_loss: 0.0639 - val_MAE: 0.0639\n",
      "Epoch 875/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0228 - MAE: 0.0228 - val_loss: 0.0634 - val_MAE: 0.0634\n",
      "Epoch 876/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0206 - MAE: 0.0206 - val_loss: 0.0592 - val_MAE: 0.0592\n",
      "Epoch 877/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0221 - MAE: 0.0221 - val_loss: 0.0603 - val_MAE: 0.0603\n",
      "Epoch 878/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0244 - MAE: 0.0244 - val_loss: 0.0691 - val_MAE: 0.0691\n",
      "Epoch 879/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0238 - MAE: 0.0238 - val_loss: 0.0640 - val_MAE: 0.0640\n",
      "Epoch 880/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0231 - MAE: 0.0231 - val_loss: 0.0600 - val_MAE: 0.0600\n",
      "Epoch 881/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0255 - MAE: 0.0255 - val_loss: 0.0652 - val_MAE: 0.0652\n",
      "Epoch 882/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0261 - MAE: 0.0261 - val_loss: 0.0619 - val_MAE: 0.0619\n",
      "Epoch 883/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0251 - MAE: 0.0251 - val_loss: 0.0635 - val_MAE: 0.0635\n",
      "Epoch 884/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0271 - MAE: 0.0271 - val_loss: 0.0752 - val_MAE: 0.0752\n",
      "Epoch 885/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0273 - MAE: 0.0273 - val_loss: 0.0615 - val_MAE: 0.0615\n",
      "Epoch 886/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0235 - MAE: 0.0235 - val_loss: 0.0673 - val_MAE: 0.0673\n",
      "Epoch 887/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0248 - MAE: 0.0248 - val_loss: 0.0617 - val_MAE: 0.0617\n",
      "Epoch 888/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0222 - MAE: 0.0222 - val_loss: 0.0707 - val_MAE: 0.0707\n",
      "Epoch 889/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0315 - MAE: 0.0315 - val_loss: 0.0640 - val_MAE: 0.0640\n",
      "Epoch 890/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0253 - MAE: 0.0253 - val_loss: 0.0639 - val_MAE: 0.0639\n",
      "Epoch 891/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0232 - MAE: 0.0232 - val_loss: 0.0680 - val_MAE: 0.0680\n",
      "Epoch 892/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0231 - MAE: 0.0231 - val_loss: 0.0643 - val_MAE: 0.0643\n",
      "Epoch 893/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0254 - MAE: 0.0254 - val_loss: 0.0674 - val_MAE: 0.0674\n",
      "Epoch 894/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0235 - MAE: 0.0235 - val_loss: 0.0625 - val_MAE: 0.0625\n",
      "Epoch 895/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0212 - MAE: 0.0212 - val_loss: 0.0631 - val_MAE: 0.0631\n",
      "Epoch 896/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0200 - MAE: 0.0200 - val_loss: 0.0645 - val_MAE: 0.0645\n",
      "Epoch 897/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0201 - MAE: 0.0201 - val_loss: 0.0661 - val_MAE: 0.0661\n",
      "Epoch 898/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0228 - MAE: 0.0228 - val_loss: 0.0612 - val_MAE: 0.0612\n",
      "Epoch 899/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0228 - MAE: 0.0228 - val_loss: 0.0633 - val_MAE: 0.0633\n",
      "Epoch 900/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0197 - MAE: 0.0197 - val_loss: 0.0623 - val_MAE: 0.0623\n",
      "Epoch 901/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0187 - MAE: 0.0187 - val_loss: 0.0654 - val_MAE: 0.0654\n",
      "Epoch 902/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0213 - MAE: 0.0213 - val_loss: 0.0618 - val_MAE: 0.0618\n",
      "Epoch 903/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0250 - MAE: 0.0250 - val_loss: 0.0668 - val_MAE: 0.0668\n",
      "Epoch 904/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0232 - MAE: 0.0232 - val_loss: 0.0615 - val_MAE: 0.0615\n",
      "Epoch 905/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0235 - MAE: 0.0235 - val_loss: 0.0592 - val_MAE: 0.0592\n",
      "Epoch 906/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0218 - MAE: 0.0218 - val_loss: 0.0636 - val_MAE: 0.0636\n",
      "Epoch 907/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0224 - MAE: 0.0224 - val_loss: 0.0647 - val_MAE: 0.0647\n",
      "Epoch 908/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0200 - MAE: 0.0200 - val_loss: 0.0631 - val_MAE: 0.0631\n",
      "Epoch 909/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0216 - MAE: 0.0216 - val_loss: 0.0615 - val_MAE: 0.0615\n",
      "Epoch 910/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0197 - MAE: 0.0197 - val_loss: 0.0668 - val_MAE: 0.0668\n",
      "Epoch 911/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0213 - MAE: 0.0213 - val_loss: 0.0709 - val_MAE: 0.0709\n",
      "Epoch 912/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0263 - MAE: 0.0263 - val_loss: 0.0630 - val_MAE: 0.0630\n",
      "Epoch 913/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0288 - MAE: 0.0288 - val_loss: 0.0706 - val_MAE: 0.0706\n",
      "Epoch 914/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0221 - MAE: 0.0221 - val_loss: 0.0643 - val_MAE: 0.0643\n",
      "Epoch 915/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0190 - MAE: 0.0190 - val_loss: 0.0682 - val_MAE: 0.0682\n",
      "Epoch 916/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0242 - MAE: 0.0242 - val_loss: 0.0645 - val_MAE: 0.0645\n",
      "Epoch 917/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0273 - MAE: 0.0273 - val_loss: 0.0640 - val_MAE: 0.0640\n",
      "Epoch 918/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0222 - MAE: 0.0222 - val_loss: 0.0654 - val_MAE: 0.0654\n",
      "Epoch 919/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0219 - MAE: 0.0219 - val_loss: 0.0635 - val_MAE: 0.0635\n",
      "Epoch 920/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0205 - MAE: 0.0205 - val_loss: 0.0602 - val_MAE: 0.0602\n",
      "Epoch 921/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0209 - MAE: 0.0209 - val_loss: 0.0633 - val_MAE: 0.0633\n",
      "Epoch 922/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0216 - MAE: 0.0216 - val_loss: 0.0597 - val_MAE: 0.0597\n",
      "Epoch 923/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0218 - MAE: 0.0218 - val_loss: 0.0612 - val_MAE: 0.0612\n",
      "Epoch 924/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0204 - MAE: 0.0204 - val_loss: 0.0640 - val_MAE: 0.0640\n",
      "Epoch 925/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0201 - MAE: 0.0201 - val_loss: 0.0674 - val_MAE: 0.0674\n",
      "Epoch 926/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0217 - MAE: 0.0217 - val_loss: 0.0647 - val_MAE: 0.0647\n",
      "Epoch 927/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0213 - MAE: 0.0213 - val_loss: 0.0626 - val_MAE: 0.0626\n",
      "Epoch 928/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0200 - MAE: 0.0200 - val_loss: 0.0673 - val_MAE: 0.0673\n",
      "Epoch 929/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0236 - MAE: 0.0236 - val_loss: 0.0600 - val_MAE: 0.0600\n",
      "Epoch 930/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0225 - MAE: 0.0225 - val_loss: 0.0591 - val_MAE: 0.0591\n",
      "Epoch 931/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0197 - MAE: 0.0197 - val_loss: 0.0661 - val_MAE: 0.0661\n",
      "Epoch 932/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0199 - MAE: 0.0199 - val_loss: 0.0645 - val_MAE: 0.0645\n",
      "Epoch 933/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0192 - MAE: 0.0192 - val_loss: 0.0684 - val_MAE: 0.0684\n",
      "Epoch 934/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0232 - MAE: 0.0232 - val_loss: 0.0588 - val_MAE: 0.0588\n",
      "Epoch 935/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0226 - MAE: 0.0226 - val_loss: 0.0644 - val_MAE: 0.0644\n",
      "Epoch 936/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0205 - MAE: 0.0205 - val_loss: 0.0611 - val_MAE: 0.0611\n",
      "Epoch 937/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0187 - MAE: 0.0187 - val_loss: 0.0635 - val_MAE: 0.0635\n",
      "Epoch 938/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0204 - MAE: 0.0204 - val_loss: 0.0631 - val_MAE: 0.0631\n",
      "Epoch 939/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0192 - MAE: 0.0192 - val_loss: 0.0584 - val_MAE: 0.0584\n",
      "Epoch 940/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0237 - MAE: 0.0237 - val_loss: 0.0675 - val_MAE: 0.0675\n",
      "Epoch 941/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0229 - MAE: 0.0229 - val_loss: 0.0665 - val_MAE: 0.0665\n",
      "Epoch 942/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0257 - MAE: 0.0257 - val_loss: 0.0600 - val_MAE: 0.0600\n",
      "Epoch 943/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0264 - MAE: 0.0264 - val_loss: 0.0701 - val_MAE: 0.0701\n",
      "Epoch 944/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0241 - MAE: 0.0241 - val_loss: 0.0625 - val_MAE: 0.0625\n",
      "Epoch 945/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0221 - MAE: 0.0221 - val_loss: 0.0629 - val_MAE: 0.0629\n",
      "Epoch 946/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0245 - MAE: 0.0245 - val_loss: 0.0692 - val_MAE: 0.0692\n",
      "Epoch 947/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0234 - MAE: 0.0234 - val_loss: 0.0602 - val_MAE: 0.0602\n",
      "Epoch 948/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0198 - MAE: 0.0198 - val_loss: 0.0637 - val_MAE: 0.0637\n",
      "Epoch 949/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0206 - MAE: 0.0206 - val_loss: 0.0618 - val_MAE: 0.0618\n",
      "Epoch 950/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0248 - MAE: 0.0248 - val_loss: 0.0644 - val_MAE: 0.0644\n",
      "Epoch 951/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0315 - MAE: 0.0315 - val_loss: 0.0697 - val_MAE: 0.0697\n",
      "Epoch 952/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0226 - MAE: 0.0226 - val_loss: 0.0592 - val_MAE: 0.0592\n",
      "Epoch 953/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0250 - MAE: 0.0250 - val_loss: 0.0597 - val_MAE: 0.0597\n",
      "Epoch 954/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0222 - MAE: 0.0222 - val_loss: 0.0636 - val_MAE: 0.0636\n",
      "Epoch 955/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0206 - MAE: 0.0206 - val_loss: 0.0671 - val_MAE: 0.0671\n",
      "Epoch 956/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0214 - MAE: 0.0214 - val_loss: 0.0646 - val_MAE: 0.0646\n",
      "Epoch 957/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0210 - MAE: 0.0210 - val_loss: 0.0627 - val_MAE: 0.0627\n",
      "Epoch 958/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0217 - MAE: 0.0217 - val_loss: 0.0590 - val_MAE: 0.0590\n",
      "Epoch 959/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0239 - MAE: 0.0239 - val_loss: 0.0698 - val_MAE: 0.0698\n",
      "Epoch 960/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0256 - MAE: 0.0256 - val_loss: 0.0582 - val_MAE: 0.0582\n",
      "Epoch 961/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0220 - MAE: 0.0220 - val_loss: 0.0606 - val_MAE: 0.0606\n",
      "Epoch 962/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0237 - MAE: 0.0237 - val_loss: 0.0663 - val_MAE: 0.0663\n",
      "Epoch 963/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0215 - MAE: 0.0215 - val_loss: 0.0650 - val_MAE: 0.0650\n",
      "Epoch 964/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0214 - MAE: 0.0214 - val_loss: 0.0583 - val_MAE: 0.0583\n",
      "Epoch 965/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0211 - MAE: 0.0211 - val_loss: 0.0610 - val_MAE: 0.0610\n",
      "Epoch 966/1000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0189 - MAE: 0.0189 - val_loss: 0.0655 - val_MAE: 0.0655\n",
      "Epoch 967/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0198 - MAE: 0.0198 - val_loss: 0.0622 - val_MAE: 0.0622\n",
      "Epoch 968/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0199 - MAE: 0.0199 - val_loss: 0.0627 - val_MAE: 0.0627\n",
      "Epoch 969/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0191 - MAE: 0.0191 - val_loss: 0.0699 - val_MAE: 0.0699\n",
      "Epoch 970/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0242 - MAE: 0.0242 - val_loss: 0.0625 - val_MAE: 0.0625\n",
      "Epoch 971/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0251 - MAE: 0.0251 - val_loss: 0.0702 - val_MAE: 0.0702\n",
      "Epoch 972/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0235 - MAE: 0.0235 - val_loss: 0.0734 - val_MAE: 0.0734\n",
      "Epoch 973/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0272 - MAE: 0.0272 - val_loss: 0.0639 - val_MAE: 0.0639\n",
      "Epoch 974/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0264 - MAE: 0.0264 - val_loss: 0.0732 - val_MAE: 0.0732\n",
      "Epoch 975/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0261 - MAE: 0.0261 - val_loss: 0.0626 - val_MAE: 0.0626\n",
      "Epoch 976/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0260 - MAE: 0.0260 - val_loss: 0.0629 - val_MAE: 0.0629\n",
      "Epoch 977/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0236 - MAE: 0.0236 - val_loss: 0.0604 - val_MAE: 0.0604\n",
      "Epoch 978/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0239 - MAE: 0.0239 - val_loss: 0.0611 - val_MAE: 0.0611\n",
      "Epoch 979/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0208 - MAE: 0.0208 - val_loss: 0.0633 - val_MAE: 0.0633\n",
      "Epoch 980/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0180 - MAE: 0.0180 - val_loss: 0.0601 - val_MAE: 0.0601\n",
      "Epoch 981/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0209 - MAE: 0.0209 - val_loss: 0.0645 - val_MAE: 0.0645\n",
      "Epoch 982/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0203 - MAE: 0.0203 - val_loss: 0.0639 - val_MAE: 0.0639\n",
      "Epoch 983/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0193 - MAE: 0.0193 - val_loss: 0.0582 - val_MAE: 0.0582\n",
      "Epoch 984/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0234 - MAE: 0.0234 - val_loss: 0.0610 - val_MAE: 0.0610\n",
      "Epoch 985/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0244 - MAE: 0.0244 - val_loss: 0.0706 - val_MAE: 0.0706\n",
      "Epoch 986/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0232 - MAE: 0.0232 - val_loss: 0.0604 - val_MAE: 0.0604\n",
      "Epoch 987/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0196 - MAE: 0.0196 - val_loss: 0.0598 - val_MAE: 0.0598\n",
      "Epoch 988/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0223 - MAE: 0.0223 - val_loss: 0.0651 - val_MAE: 0.0651\n",
      "Epoch 989/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0238 - MAE: 0.0238 - val_loss: 0.0620 - val_MAE: 0.0620\n",
      "Epoch 990/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0215 - MAE: 0.0215 - val_loss: 0.0672 - val_MAE: 0.0672\n",
      "Epoch 991/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0202 - MAE: 0.0202 - val_loss: 0.0643 - val_MAE: 0.0643\n",
      "Epoch 992/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0187 - MAE: 0.0187 - val_loss: 0.0616 - val_MAE: 0.0616\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0176 - MAE: 0.0176 - val_loss: 0.0621 - val_MAE: 0.0621\n",
      "Epoch 994/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0177 - MAE: 0.0177 - val_loss: 0.0656 - val_MAE: 0.0656\n",
      "Epoch 995/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0210 - MAE: 0.0210 - val_loss: 0.0656 - val_MAE: 0.0656\n",
      "Epoch 996/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0195 - MAE: 0.0195 - val_loss: 0.0626 - val_MAE: 0.0626\n",
      "Epoch 997/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0182 - MAE: 0.0182 - val_loss: 0.0587 - val_MAE: 0.0587\n",
      "Epoch 998/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0190 - MAE: 0.0190 - val_loss: 0.0657 - val_MAE: 0.0657\n",
      "Epoch 999/1000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0210 - MAE: 0.0210 - val_loss: 0.0627 - val_MAE: 0.0627\n",
      "Epoch 1000/1000\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0195 - MAE: 0.0195 - val_loss: 0.0638 - val_MAE: 0.0638\n"
     ]
    }
   ],
   "source": [
    "# 3. Fit the model\n",
    "history = model_1.fit(X_train_scaled, \n",
    "                      y_train_scaled, \n",
    "                      epochs=1000,    # Load가 크지 않은 문제이므로, 충분히 학습할 것(즉, Underfitting이 되지 않도록 할 것). \n",
    "                      verbose = 1,     # 단, Overfitting이 발생하면 더이상 학습할 필요가 없음. \n",
    "                      #validation_split = 0.1)\n",
    "                      validation_data=(X_valid_scaled, y_valid_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epochs')"
      ]
     },
     "execution_count": 724,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEGCAYAAABy53LJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABbyElEQVR4nO3dd3hUVfrA8e87k04g9BZaCAihlwABFTsIsmIXFxHLWhe7qFixrV3XVdZecFWKBeVHFRVBlEBCL6EkECChpEB6mczM+f1xJ5OZzKRnCIHzeZ483HtumXOHZN45XZRSaJqmaVp1mRo6A5qmaVrjogOHpmmaViM6cGiapmk1ogOHpmmaViM6cGiapmk14tfQGTgZWrdurbp169bQ2dA0TWtUNmzYkKGUalM+/YwIHN26dSM+Pr6hs6FpmtaoiMgBb+m6qkrTNE2rER04NE3TtBrRgUPTNE2rkTOijUPTtDNHSUkJKSkpFBUVNXRWGo2goCA6deqEv79/tc7XgUPTtNNKSkoKTZs2pVu3bohIQ2fnlKeUIjMzk5SUFCIiIqp1ja6q0jTttFJUVESrVq100KgmEaFVq1Y1KqHpwKFp2mlHB42aqen7pQNHJTb/Ope1s59s6GxomqadUnTgqERxwnKi9n/R0NnQNK2RCQ0Nbegs+JQOHJVQ5gD8lK2hs6FpmnZK0YGjEsoUgD/Whs6GpmmNlFKK6dOn069fP/r378+8efMAOHLkCKNHj2bQoEH069ePP/74A5vNxs033+w89+23327g3FdMd8ethJj98ceKstsRk46xmtbYPPd/O9h5OKde79mnYzOe/Vvfap37ww8/sHnzZrZs2UJGRgbDhg1j9OjRfPPNN4wdO5Ynn3wSm81GQUEBmzdvJjU1le3btwOQlZVVr/muT/rTsBLK7I9JFDabLnVomlZza9as4YYbbsBsNtOuXTvOO+884uLiGDZsGJ9//jkzZ85k27ZtNG3alO7du7Nv3z7uvfdeli1bRrNmzRo6+xXyaYlDRC4F3gHMwCdKqVfKHZ8MPObYzQPuVkptqexaEWkJzAO6AcnAdUqpEz7JvzkAgBJLMX7+Ab54CU3TfKi6JQNfUUp5TR89ejSrV69m8eLFTJkyhenTp3PTTTexZcsWli9fzqxZs5g/fz6fffbZSc5x9fisxCEiZmAWMA7oA9wgIn3KnbYfOE8pNQB4AfioGtc+DvyqlOoJ/OrY9w0/I1hYLMU+ewlN005fo0ePZt68edhsNtLT01m9ejXDhw/nwIEDtG3blttvv53bbruNjRs3kpGRgd1u5+qrr+aFF15g48aNDZ39CvmyxDEcSFRK7QMQkbnARGBn6QlKqb9czo8FOlXj2onA+Y7zZgO/U1ZqqVdiNuZtsVr0nDeaptXclVdeydq1axk4cCAiwmuvvUb79u2ZPXs2r7/+Ov7+/oSGhvLll1+SmprKLbfcgt1uB+Dll19u4NxXzJeBIxw45LKfAoyo5PzbgKXVuLadUuoIgFLqiIi09XYzEbkDuAOgS5cuNc48lFVVWUt0iUPTtOrLy8sDjBHZr7/+Oq+//rrb8alTpzJ16lSP607lUoYrXzaOexvD7rXCT0QuwAgcpSWHal9bEaXUR0qpaKVUdJs2HisfVos4qqqsFkutrtc0TTsd+TJwpACdXfY7AYfLnyQiA4BPgIlKqcxqXHtMRDo4ru0ApNVzvsvy5ggcNqsucWiappXyZeCIA3qKSISIBACTgIWuJ4hIF+AHYIpSak81r10IlJbxpgI/+eoBTKWBQ1dVaZqmOfmsjUMpZRWRacByjC61nymldojIXY7jHwDPAK2A/zpmZ7Q6qpe8Xuu49SvAfBG5DTgIXOurZzD5BQJgLdFVVZqmaaV8Oo5DKbUEWFIu7QOX7X8A/6jutY70TOCi+s2pd7rEoWma5kmPHK+Eyb80cOgSh6ZpWikdOCphdpQ47LpxXNO0GhARpkyZ4ty3Wq20adOGCRMmuJ03ceJERo4c6ZY2c+ZMwsPDGTRokPPnVJu3Sk9yWAmzv9HGoQOHpmk10aRJE7Zv305hYSHBwcGsWLGC8PBwt3OysrLYuHEjoaGh7N+/32297wcffJBHHnnkZGe72nSJoxJmZxtHSQPnRNO0xmbcuHEsXrwYgDlz5nDDDTe4Hf/+++/529/+xqRJk5g7d25DZLHWdImjEn6OEoey6TYOTWuUlj4OR7fV7z3b94dxr1R52qRJk3j++eeZMGECW7du5dZbb+WPP/5wHp8zZw7PPvss7dq145prrmHGjBnOY2+//TZfffUVAC1atGDlypX1+wx1pANHJUqrqpRVBw5N02pmwIABJCcnM2fOHMaPH+927NixYyQmJnLOOecgIvj5+bF9+3b69esHnPpVVTpwVMIvQAcOTWvUqlEy8KXLL7+cRx55hN9//53MzExn+rx58zhx4oSzXSMnJ4e5c+fy4osvNlRWa0S3cVSiNHDYdeDQNK0Wbr31Vp555hn69+/vlj5nzhyWLVtGcnIyycnJbNiwoVG1c+jAUQl/3cahaVoddOrUifvvv98tLTk5mYMHDxITE+NMi4iIoFmzZqxbtw4w2jhcu+MmJyefzGxXSVdVVcJcuuqfDhyaptVA6bTqrs4//3zOP/98AFJTUz2Ol06pPmLECGbOnOnL7NWZLnFUwt9RVYVVd8fVNE0rpQNHJXRVlaZpmicdOCphMpspUWaw6ZHjmqZppXTgqEKhBGEqKWjobGiapp0ydOCoQgEhmCyeDV2apmlnKh04qlBoCsHPqgOHpmlaKR04qlBkboK/DhyapmlOPg0cInKpiOwWkUQRedzL8d4islZEikXkEZf0XiKy2eUnR0QecBybKSKpLsfGl79vfbKYmxBg020cmqb5RmhoaIXHkpOTnfNXnUp8NgBQRMzALOASIAWIE5GFSqmdLqcdB+4DrnC9Vim1Gxjkcp9UYIHLKW8rpd7wVd5dWf1DCS72HKyjaZp2pvLlyPHhQKJSah+AiMwFJgLOwKGUSgPSROSySu5zEZCklDrgw7xWyOYfSrDSJQ5Na4xeXf8qu47vqtd79m7Zm8eGP1bh8ccee4yuXbtyzz33AMaKfiLC6tWrOXHiBCUlJbz44otMnDixRq9bVFTE3XffTXx8PH5+frz11ltccMEF7Nixg1tuuQWLxYLdbuf777+nY8eOXHfddaSkpGCz2Xj66ae5/vrr6/TcrnwZOMKBQy77KcCIWtxnEjCnXNo0EbkJiAceVkqdKH+RiNwB3AHQpUuXWryswe4fSogqrPX1mqadWSZNmsQDDzzgDBzz589n2bJlPPjggzRr1oyMjAxiYmK4/PLLEZFq33fWrFkAbNu2jV27djFmzBj27NnDBx98wP3338/kyZOxWCzYbDaWLFlCx44dnQtJZWdn1+sz+jJweHtHVI1uIBIAXA7McEl+H3jBca8XgDeBWz1eSKmPgI8AoqOja/S6bvcJbEaIFGMtseBXOneVpmmNQmUlA18ZPHgwaWlpHD58mPT0dFq0aEGHDh148MEHWb16NSaTidTUVI4dO0b79u2rfd81a9Zw7733AtC7d2+6du3Knj17GDlyJC+99BIpKSlcddVV9OzZk/79+/PII4/w2GOPMWHCBM4999x6fUZfNo6nAJ1d9jsBh2t4j3HARqXUsdIEpdQxpZRNKWUHPsaoEvMZCWoKQH5u/UZsTdNOX9dccw3fffcd8+bNY9KkSXz99dekp6ezYcMGNm/eTLt27SgqKqrRPZXy/v3373//OwsXLiQ4OJixY8fy22+/cdZZZ7Fhwwb69+/PjBkzeP755+vjsZx8GTjigJ4iEuEoOUwCFtbwHjdQrppKRDq47F4JbK9TLqtgDmoGQH52ZhVnapqmGUrXEf/uu++45ppryM7Opm3btvj7+7Ny5UoOHKh5k+3o0aP5+uuvAdizZw8HDx6kV69e7Nu3j+7du3Pfffdx+eWXs3XrVg4fPkxISAg33ngjjzzyiHPm3fris6oqpZRVRKYBywEz8JlSaoeI3OU4/oGItMdop2gG2B1dbvsopXJEJASjR9ad5W79mogMwqiqSvZyvN4snj6J4NgdcBEcT91Dx4jevnopTdNOI3379iU3N5fw8HA6dOjA5MmT+dvf/kZ0dDSDBg2id++af5bcc8893HXXXfTv3x8/Pz+++OILAgMDmTdvHl999RX+/v60b9+eZ555hri4OKZPn47JZMLf35/333+/Xp9PKir+nE6io6NVfHx8ja9bdN9VdFiVwNArDxPb82FiJj/jg9xpmlafEhISiIqKauhsNDre3jcR2aCUii5/rh45XgkJDCSgBPaaexC19wPycjw6b2mapp1xdOCohAQF4meHwvOeIox89vz1U0NnSdO009C2bdvcloodNGgQI0bUZvTCyaGXjq2EKSgIgI5nDcH6q4nilC0NnCNN005H/fv3Z/PmzQ2djWrTJY5KmIKCjQ27lSOm9gRmJTZshjRN004BOnBUwuwIHMUFuWQHtCWkKL2Bc6RpmtbwdOCoRGngyE5LIaUkhDBrRgPnSNM0reHpNo5K+Ac3ASDzkRl0PW4lbXwBrYqLCAgMauCcaZqmNRxd4qiEf4gROFoftwKQlh1AatK2hsySpmmnmarW4xARnn76aWdaRkYG/v7+TJs2ze3cgQMHcsMNN7il3XzzzURERDh7ao0aNape8qwDRyWCmrdy2y+xmMjct6mBcqNp2pmoe/fuLFq0yLn/7bff0rdvX7dzEhISsNvtrF69mvz8fLdjr7/+Ops3b2bz5s389ddf9ZInXVVViZAWbShx2bcVmSk57NOpsTRNq0dH//UvihPqdz2OwKjetH/iiQqP1/d6HMHBwURFRREfH090dDTz5s3juuuu4/Dhsjljv/nmG6ZMmUJCQgILFy70KHnUN13iqETT5m3d9u3F/gSf2N1AudE0rTGYNGkS8+bNc+7Pnz+fW265hQULFrBx40ZWrlzJww8/XOFstxXdc+7cuaSkpGA2m+nYsaPb8Xnz5nH99ddzww03MGeO+/JF06dPd1ZVTZ48uW4P56BLHJVo2qoDxx3bx9oG4Fdko11hUoPmSdO06qusZOArvliP49JLL+Xpp5+mXbt2Hiv5xcXF0aZNG7p27UqnTp249dZbOXHiBC1atACMqqprrrmmXp9RlzgqERTSzLld0L4ZgUXQgXRys49XcpWmaWe6+l6PIyAggKFDh/Lmm29y9dVXux2bM2cOu3btolu3bkRGRpKTk8P3339f34/kRgeOSphMJo43N2MH7GFNCSmwA5C6p37nttc07fTii/U4Hn74YV599VVatSrrtGO32/n222/ZunUrycnJJCcn89NPP3lUV9U3HTiqMHD5KsLX/IK0bkmzfEWBTchO1nNWaZpWMW/rcZQ2bn/99de1Wo+jb9++TJ061S1t9erVhIeHEx4e7kwbPXo0O3fu5MiRI4B7G8egQYOwWCx1ezj0ehzV9ufct2k58yPyL83F2msCMXd/UE+50zStPun1OGpHr8fhAz3PHg/AodRmBOSlNnBuNE3TGo5PA4eIXCoiu0UkUUQe93K8t4isFZFiEXmk3LFkEdkmIptFJN4lvaWIrBCRvY5/W/jyGUq17dwLgN7bFDkZB0/GS2qadobQ63E4iIgZmIWxbngKECciC5VSO11OOw7cB1xRwW0uUEqVn1nwceBXpdQrjmD0OPBYvWa+KgW5J/XlNE2rGaUUItLQ2ai2hl6Po6ZNFr4scQwHEpVS+5RSFmAu4DZUUimVppSKA7cB2lWZCMx2bM+m4qBT76wf/svYsFg5vL9+R6NqmlY/goKCyMzMrPGH4ZlKKUVmZiZBQdWfvNWXAwDDgUMu+ylATcpeCvhZRBTwoVLqI0d6O6XUEQCl1BERaevtYhG5A7gDoEuXLjXNu1dd+48kFSgqMnMw9gc6Rpz8wUWaplWuU6dOpKSkkJ6u18+prqCgIDp16lTt830ZOLyVE2vyFeBspdRhR2BYISK7lFKrq3uxI9B8BEavqhq8boVCm7fF4gfWLH9Sdq6vj1tqmlbP/P39iYiIaOhsnNZ8WVWVAnR22e8EHK7gXA9KqcOOf9OABRhVXwDHRKQDgOPftHrJbTWYTCbyQs1E7jbT99vdpKfqpWQ1TTvz+DJwxAE9RSRCRAKAScDC6lwoIk1EpGnpNjAGKJ2WdiFQOgpmKvBTvea6CoXNAp3bSet+PpkvrWmadkrwWVWVUsoqItOA5YAZ+EwptUNE7nIc/0BE2gPxQDPALiIPAH2A1sACR68IP+AbpdQyx61fAeaLyG3AQeBaXz2DN5ZmIUCBsZ2ddTJfWtM07ZTg09lxlVJLgCXl0j5w2T6KUYVVXg4wsIJ7ZgIX1WM2a8QeGuzczjy4t6GyoWma1mD0yPGaatrEuWnJKT/ERNM07fSnA0cNmZo1dW6r4sIGzImmaVrD0IGjhszNwsp2dODQNO0MpANHDQV3KFuyUephemJN07TGRgeOGmrTc4BzW0pqMlOKpmna6UEHjhrqPug8kvu0BMBstTZwbjRN004+HThqKDA4lHE//ElWEzBbbQ2dHU3TtJNOB45aKgoUwvfB0eSdVZ+saZp2GtGBo5aUyURoEWz659SqT9Y0TTuN6MBRSx0yjGoq//ziBs6JpmnayaUDRy0dvPcKAAqamBs2I5qmaSeZDhy1NObul0jurOiZVMTW379r6OxomqadNDpw1JKYTJhLjLWqTjz9fAPnRtM07eTRgaMOLIHG22cN0NVVmqadOXTgqAPTuT0AKOxZ/bV6NU3TGjsdOOqgZae+ZIeAsukR5JqmnTl04KgDv5ZdKPFX+KWkcfzogYbOjqZp2knh08AhIpeKyG4RSRSRx70c7y0ia0WkWEQecUnvLCIrRSRBRHaIyP0ux2aKSKqIbHb8jPflM1SmRbcBWP2h2/4CksaNa6hsaJqmnVQ+WzpWRMzALOASIAWIE5GFSinXOTqOA/cBV5S73Ao8rJTaKCJNgQ0issLl2reVUm/4Ku/V1bnXEPY53sHQQtWwmdE0TTtJfFniGA4kKqX2KaUswFxgousJSqk0pVQcUFIu/YhSaqNjOxdIAMJ9mNdaCQgMojjAp8u2a5qmnXJ8GTjCgUMu+ynU4sNfRLoBg4F1LsnTRGSriHwmIi0quO4OEYkXkfj09PSavmy1FcZE+ezemqZppyJfBg7xklaj+hwRCQW+Bx5QSuU4kt8HIoFBwBHgTW/XKqU+UkpFK6Wi27RpU5OXrZGeo69i38ASiv1g26oF/H7eQHKOH/XZ62mapjU0XwaOFKCzy34n4HB1LxYRf4yg8bVS6ofSdKXUMaWUTSllBz7GqBJrMM3ad0f87QRa4dC7b9HumIWNCz5uyCxpmqb5lC8DRxzQU0QiRCQAmAQsrM6FIiLAp0CCUuqtcsc6uOxeCWyvp/zWSot2XTD7GQUpe+vmABQe2N+AOdI0TfMtnwUOpZQVmAYsx2jcnq+U2iEid4nIXQAi0l5EUoCHgKdEJEVEmgFnA1OAC710u31NRLaJyFbgAuBBXz1DdYS1bIvJETgoMqZY7zZ/LYvunNCAudI0TfMdn3YJUkotAZaUS/vAZfsoRhVWeWvw3kaCUmpKfeaxrkxmMzY/f2O7qGxtjshVSQ2VJU3TNJ/SI8frQUlgKACdtqU1cE40TdN8r1qBQ0TuF5FmYvhURDaKyBhfZ66xKG7eHQB/WwNnRNM07SSobonjVkd32DFAG+AW4BWf5aqRufi+WRzobG/obGiapp0U1Q0cpe0N44HPlVJbqKAN4kzUvFV7mvWzNHQ2NE3TTorqBo4NIvIzRuBY7pg/Sn/FduXfpKFzoGmadlJUt1fVbRgjtfcppQpEpCVGdZXmoIKaAScaOhuapmk+V90Sx0hgt1IqS0RuBJ4Csn2XrcbH1KRlQ2dB0zTtpKhu4HgfKBCRgcCjwAHgS5/lqhGS0PbVPtdms2It0W0imqY1TtUNHFallMKYFv0dpdQ7QFPfZavxUU1ae6RZigs80hI3/c6evv3Z23/gyciWpmlavatu4MgVkRkY04AsdizS5O+7bDU+5tC2Hmm/TLnUI63khrtPRnY0TdN8prqB43qgGGM8x1GMdTVe91muGqGAFh090iK2+m4dEE3TtIZSrcDhCBZfA2EiMgEoUkrpNg4XrbpEYdGLAWqadgao7pQj1wHrgWuB64B1InKNLzPW2HToFkXEFUfZ10PPO6Jp2umtut+RnwSGKaXSAESkDfAL8J2vMtbY+PkHcGLyL1zmdyGLLJ2JPKgDiKZpp6fqtnGYSoOGQ2YNrj1jdI0aymFpi1lKnGmH9mwgO/MIS2feRomlqAFzp2maVj+qW+JYJiLLgTmO/espt86GZrBIILZmxZTG1ZyJN5KnoBuwdfg8Qhoyc5qmafWguo3j04GPgAHAQOAjpdRjvsxYY1ViCuLcszKc+yZVdsxYJl3TNK1xq3Z1k1Lqe6XUQ0qpB5VSC6pzjYhcKiK7RSRRRB73cry3iKwVkWIReaQ614pISxFZISJ7Hf+2qO4znAxF5lDC/O0k9bZ6HCspyHPbt9t1INE0rfGpNHCISK6I5Hj5yRWRnCquNQOzgHFAH+AGEelT7rTjwH3AGzW49nHgV6VUT+BXx/4po8TfMaDe7OVYfrnAYfMMLpqmaae6SgOHUqqpUqqZl5+mSqlmVdx7OJColNqnlLIAczGmLHG9f5pSKg4oqcG1E4HZju3ZwBVVPeTJpMSIGOdEZWAt9+5ay5U4bFY9X5WmaY2PL3tGhQOHXPZTHGl1vbadUuoIgONfz7k+ABG5Q0TiRSQ+Pf3kjeBWjre0uZ+dHee6T3xYmLjXbb/EUnzS8qVpmlZffBk4vK0QqLyk1fe1xslKfaSUilZKRbdp06Yml9ZJ6/FPOLcDu3QA4GBPo3DWfck2t3N1iUPTtMbIl4EjBejsst8JOFwP1x4TkQ4Ajn/TOIV0i4p2bnfoHEnblUs4+6vFXs89tn8HJ9IOnqysaZqm1QtfBo44oKeIRIhIADAJWFgP1y4Epjq2pwI/1WOe65XpRBKtOkQQGuY55TqA7cZ7OXjB2JOcK03TtLrx2bR8SimriEwDlmP0MfpMKbVDRO5yHP9ARNoD8UAzwC4iDwB9lFI53q513PoVYL6I3AYcxJg/65Q0/IT3koarAD0ziaZpjYxP53NVSi2h3AhzpdQHLttHMaqhqnWtIz0TuKh+c+p7qXdPIPz9RQ2dDU3TtDrT8035QInyHMRx8f16+RJN004POnD4QNrUP53bymV0eN7rDxv/Brt3GtPrj2ua1pjowOED4d2j2BQyCoCiwnxn+pDxN3Po9kvJuTrC7fyfn73tpOZP0zStLnTg8BFL1/MAKMwvm5nFbPZjzMNvc5F1DfsGl5UyAtbvcG7H/vBfDu3ZcPIyqmmaVkM6cPiIKTAUgMI89ym9SquuApuUzVMVnlLIoqmXkLxjLWFPvEvatVNOXkY1TdNqSAcOHwloZozdOPjHV27pJY72jBHt3QNK5LoUCq++FYCQYqVnztU07ZSlA4ePNG1rtGOM3P8eSVv/Yt27UykqzMdSXGgc97MTuWkDAfM/osTLTLrrvp91MrOraZpWbTpw+Eirjt2d25E/jGNE5o9s+3k2JcVly8cGBIcQOeBcBuxIIGms+4zzRSeMxaB0yUPTtFONDhw+EtayDcmmzm5pJv/gCtcdH/7Iv9z28zdtZNGtl7K7T1+f5VHTNK02dODwofSm7h/6fkHBbiUOV20792L/1cOd+00SDhH51wEACvKyfJZHTdO0mtKBw4fsAaFu+0U7lmC1FFZ4/viXZpP1wj1Y/CDseNlaHYf3bqr2a64+ZwDL/hZT88xqmqZVkw4cPjTwlnfc9kdk/oS1gqqqUiOvvZdjN11CsMtg8uRVHlN2VahNRgld92bXKJ+apmk1oQOHDwWFhLItcIhbWkklJY5Snc91n2o9/AM9OaKmaacOHTh8rP+MlW77uX98WOU1USMv49j0G0gaE+VMyzyy3+2cTT9/zarPXqyfTGqaptWAT6dV1zwNy17u3LaWWPDzD/B63vm3PQPAkqduJuK7daRdMJ51A9rQflc6wRYIwvjJHDeZ9fdMJvLJ5zkr+uKT8ATamcJut7Pk/qvpfsNt9Bk1oaGzo51CdInjJFjb6Vav6fEf/7PKa2OmPefcjtia7tb2ARD36St0SzhBwc331imPmlZezvEjRK7YReHdjzZ0VuqkxFJEQuzShs7GaUUHjpMg5tY3vaZ3Sl9d5bUt23cl+e/nsL+f+/Kzh8ODAOj6lXGPQCssuuOyOuZUq4m9G35l8d8vwFJc0NBZ8SlRqqGzUCc/PzEVbn6IxE0rqz5ZqxafBg4RuVREdotIoog87uW4iMh/HMe3isgQR3ovEdns8pPjWFYWEZkpIqkux8b78hnqg5hMHo3kAAXmZtW6ftwzHzP+uz/YN7QD+y4bQNSuBEb93yqP8yJX73Nuu444j/1+FglrF7Plt/kUF+bV4gk0bw48/ijdNx5ld+zyqk+uo91xP7P6y1d9/jqubI551UyNfPICvwSjfTDrcHLDZuQ04rM2DhExA7OAS4AUIE5EFiqldrqcNg7o6fgZAbwPjFBK7QYGudwnFVjgct3bSqk3fJV33/D81naWdQ/b//iJfudOrNYdLvv6N+d2cEgz0lv50yazxOu5G4f04+iQLpjy8onYakxfEgCsGPUpEz7z/QfdGcGxHpdStV84Pj01kdAWbQkOqfxLhH3K/bQBuOkxr8e3/v4deY8+S58lP9O8dXit8+PKZjUCR6AVsjOPENaqQ73cV2v8fFniGA4kKqX2KaUswFyg/CfkROBLZYgFmotI+d/Oi4AkpdQBH+bV54r6XOc1vfcvN9f6nsEzHqjwWJMiReRfB5xBo1TrrSksuv9qll51NnnZmbV+ba2MqsN8YhkX/Y3V111S7fOXvXS31/TUd96iRY6dXat/qnVeyrNaygahZh07WG/3PelEqj6nnmxc+iVLnpx60l6vofgycIQDh1z2UxxpNT1nEjCnXNo0R9XWZyLSwtuLi8gdIhIvIvHp6ek1z309GzbxHmLbXAtAgQp0pvtJ7T90hk24lcBvPybkhy+8Hs9qaiKrqft/cViencjlO+m28zh/vP0YcYP7kNA7Ckvhya2nP7xvG/GLP8dms1Z98ilKlX4g1bEJoEtiTtUnOXT93+/eD5R+Ntrrrz3CWlIWOEx+jb8Dpojvm3SDH3yZiO/X+/x1Gpov30lvYb78b3Wl54hIAHA58K3L8feBSIyqrCOA15ZnpdRHSqlopVR0mzZtapBt3xlx90cUTk8h5Lk0t3S7rfZVHd37n0PXPiM4a8c2Dt02xu1Yq/ffIfe6irvoBq7eQGih8XZvWPQpdrudRfdcTuwP/611fkptW7WA2Eqmhs8efx1NHn6Nn1+4q86v1WBK44a9dv9/9TrzsSOI2WuZF29s1rJqULvVPcCn7N3EkutGn/Kl1rzsDMRaf+/JqWTRtCtI6B1FemriSX9tXwaOFMB1ethOwOEanjMO2KiUOlaaoJQ6ppSyKaXswMcYVWKNgphMBDdpCsD6gS9wjFYA7IpbUeE1u9b9zIn0I1Xe22z244L7X+XAjaMJWzyPqF0JnBV9MRc//DZn7djmPO/A5HPZd+VQks7uRofDZdOfNH/6v6x4dRqRv+0l7Il32REVRULvKHb8udB5zrKJI9k4IIpF/5xIYYH3b8l2ux273Y7fnU8Q9uR7ZBxOqjTffrGbq3w2u93Omq/fqLJUZLNZK5x9OCsjleNHq1/buWPNTyx78U4AEmKXsvixyR4f9KXfcEobkXOOH/Vagjq0ZwM7//Ic/b915fxq56cqqvTbdC16QK388BkSekd5BAGbS4mjpMT9fd0y82Eitqaz8QfvA1ozj+zn1/dmOPd/+fd0EnpH1WrCztysNBbfeFGVv0veHBpxLp2T8wEwPjK8sxQWVPi7UxsnYzmEyF92A7D+kX/4/LXK82XgiAN6ikiEo+QwCVhY7pyFwE2O3lUxQLZSyvVT8gbKVVOVawO5Ethe/1n3veFX3sehaKOjWZ9l1wNQVJDH2k8epKjA6Plkt9novfRaTrx/abXu6R8QxKVPfUjHyAHONJPJhNnsR9F/nmL/wLZc+Mi/uezlr/DvGelxfdtvyrormhyfP8enPwlA4qbf6bo7i2ALRP66h5UvlY0bsdvt2GxWFv1jHHHD+pGdmeo8lpacUHmeC7037gNYigtY/cXLxC/6lFYvfMqKZyv/A1l66zg2jxji9cMp9ZyLOXZ+9d5Hm82K6R+PO7s6F97xEN1/2kh2Rgpb+0bx+6cvGCc6vuVbiwvJy84kddQFLHvkBgBOpB8ioXcUP79+P3mX34jcOt0ZjEsF/vM56o3jLzlnj7F+/bbfvycrI7WSC8qYv/wRgKP7trmlW0vKBg3ZXNo7jNcrK+F4+5Bcf89kOr73o7MLbMg3xnxrWWlGzfSKtx5mR++oCqsq7XY7sT/8F7vdzl8fvkD3+MPEvjK9Ws9TEXsl1aJJg4eyetzIOt3fVWnHAo882O0kbvq93l4HwFRc8d+Qr/gscCilrMA0YDmQAMxXSu0QkbtEpLR+YgmwD0jEKD3cU3q9iIRg9Mj6odytXxORbSKyFbgAeNBXz+BrfoFls+daiovY/P1rjEz5jE3fGd0uC/KNb/Xd7cl1fq3BYyYzft4qAoJDADh32ouk3j2BlC4hznOCvPz+tT5uJXHLKna985JbeujvmziyfzuLH/0760b05+drzyNyTTLN8hX7NvzuPC8/82il+fIvrrga4Zfn76LNK1+S9t08I+HIMa/nHdm/nY1LvyRyXQqhhYr9WzzHx1T3F33lx8+xp29/577NZsXf8XlzYNtf+Nug3evfkNA7ivBkI8BbiwspyDW+rXdfup2E3lH8+djtxvMtLus2XRqMszJS3T6UXZVYijxKVkcP7HTbP7Rng+eFjhJH16//4I//vYbfXU+xfsoVACy6cwK/XjQYgF/fm8H2P34EIC1lD9tWLcBudgTAEvfg4FriSPzmYwDi/u8Tll0e42xLCXp/Lrv79MVaYmHRTRc7S6iBWcacbJbCfLb8Nt/ZHmSzWrDZrHT6aAkmoMhLyXXLb/P55a2HCHviXVZ9+gKUBiaz5/+ipbCAtJQ9AOxav5zFD15b4bf9Ezs2k9A7il3rvfcq7Jha/RLHqnMHEDe4T4WllMQBgzmQ4NnW8fPL/6TkhrtZN7SPl6vKpOzdxMbl7stOWwoLnN3pszNdvl87qkwX3XQxi+67qtrPUBc+bfFSSi3BCA6uaR+4bCvA6/BppVQBOOpy3NOn1HM2G0zEkIvgT2P7eFoKymr8oYrFKFoX5GYRWtHFdRQS2pyL738d7odf3pmO9Zc/6Lo3m+xQE2F57n94e779nFY7DpPWxp+26UZ0aZNZQta4ayld57D5zuPO8499/gkRju2MDbFsDAiiIOMoWSt+hibBSGCg87qWWTYW3XwJ578zh9Cw1tjtdpY+egO9Jt+FPdX44zDnOSaGrKAW5uA119Esv+yg6bbHsO0Yj9ns/df70J4NbHnzWcb8Zz4BgSFux4oXLXPfL8xDOf4wD/+21PlcUBYIbJYitx5IgHMtFeWlR8+Rcy4mtXOIWy+QhN5RhP+1kg1XXUr7o8VE7TJKastfmUaXL351uz7v8htZdE43zntjNk2btzUSXV6n9UufA9DhQB552RlEriqr4un43o/Aj+StO4fMiyfiB9g7GoNJLQW5LLr5Etpf+3eiL7sFe0mJM+B2X7od2xtW5Om36FqkONDbOFL6u3Jw13oi16fC+sdI4DGUY4Dqvq8+IvK3vbQsfT/zc9i55v+cHzwFOcdp0rT0KKQmbibgnmed9dfmL75DjT/H8YhlgSOhd5Qxl1t2LpHrUmi5bQvZdz9I93zFiUcP0KpDhEdpxrwyFoCk72bTe/hYSixFmMx+rP7kedp7/C9VrvTvIO7Hjxh13X1YCgvYu/EXty8oB+JW0jXKvSbdvsmoIHH9ffUm88q/E2yF2JeyCXvyPQrfnkHRs6/SIsdO1K4EDp57YdmHt+P/PnJ9KsbIBd/TI8cbUFirdmw9/zMAjuz80/kLUDouoDD3BAAlysui5PXo4vtfJ+TaK7GYIWdSWddQmf02ABHfraN5rp2CC6JJf+ImkiedXen9IraUNf53m/snwfe/RKsXPiUy9hCRv+6h+xL3KpHI2BRWv/ogJ9IPsezvF9J90VaO3XWv81ttt9KgpBQ/v/kgqz//F1t+m8/hfds4emCn1z/C397xPt4BYMf0aUSuSmLFs7ezZNJ5HNm/nR1rvHdjLS7MdcarinrL2IuLsVQwsLLDEe/fSMMPebbXHEnaSvuj7gGofNAoFbkmmdWvPsTab98lLzsDZfIMUHaBdVeV/X+6lnJ2XjC67DzHN/mMnZuIjE1BPfU6y1+ZxsFF7m0wboNHy7WlWMstUNbe8e09YL97+1ze8WPku3xbTrjO/RtyQbl2ljaZVnA0+Pvv3MfqsweQl210MY/8OYHIdSkAbBo+CHFkyWopwlpiobBclaXYjCAnB1JZdPt4EgcMZsXVown65HvK2/HnQhJ6R5G4xXOgrWtAsju+MPw84yZMt7n/zuUnezZam1wa6kufo9TGpV/y23+NquEAx0uEPfkeAEe/+JQWOWVf6Pxcvtspr32MfKvx97Fr5HoOGwO/w+C19znT2hz9A4Aixy++DRP+Ps7H6Jsew37jdAaaTCR8YtTDnzVsDLtdzgnuGsHom2bw5zdv4Swq1UHSqC5E/mWMD4j4IZ4/c+4lcrNRHRVYbHd8gypjziuk88dlJYLKVh3p9NESki6+gsgB57qlL71yFN12ZwHQ/ceNAGSNuxYTEPd6Ol0dx0qdOHqAgCo65eT9+RfFg0ZVflI1pN/3kGcRuxLmhH00X7CB35ctoeN2zyrBAJt79cuy28ZT2rLVtKDsg780iBVs3gxATstArwHrQPRImji2TRb3b/Npuza55b30G6nJ6l56Dfznc+Q8VlZp0CazxNkmFRLa3GuvsJYL1gA4G7ljP3/Vo89+ae9AgKL8HP46P9pjcKzJZpzj+sWm664THA/z/GK2f+7nRAJJy76jx8DznOkJaxeT9M0nzvcx9/sFxIY0wT/xkMc9un2zhtg+s4i5pqxSxbWH1+/3/53xny3jlzcfRNlsdPniV4KBXdGjPe7ln5XvkVZ2U/fd2O9mMfyquzGZfFcu0CWOBhbcpClrO97kltbDlgQzw7AUGB+NNupW4tizcRUZh6vuUVT6i3bw5otInjQKk8mEfPlvLI6X7zHamCG10yCjxHF85h3sH9iWY23LZvhNurCnczu7iXOTIy51r/uGtOesHdtocYn7uiOlvUTAGMBYXvDxSv54vLBcdweL7riMRXeWzezaLeFEheeHTvfs2Z308P1Vvk6HTSlYCmqWN29anXD/0KxqYr7QY0b7QOSfyR6TX3pTPhCX1+VPY8qa6tT1d97vXsJq9eJnXs8Lzin2SGvz6v/c9g9Ej2TXKKNh2tv76BrkoOr1aYrys73OqCAVjHHxOhdXiREYTQGBbslFdzxC5Ipdzv1uCScIe+Jd7AHe/0bDnnqPYwcSWHFpNMuuGOVW4gg8cpzUxE10/vRnt0B96KknPO7T6UDZ+7Jv2xqvr+X6mqs+nlnpOXWlSxyngBG3/ZvsF74nDPc/mpLSwCF1CxxnLbycEzSDmZ7firwZ+/h7zu3ew8eSsWIRe9YsJqqn0cDatc8IrNu24OcfgO3ae1F2O3v7DzTOv/Nhur0zkgO7txDz3cX8kduOka9sJ8o/AO4xGthL+xU1aduxRs9RWq9cmeyXpmF77X1aZht/oK7zd9VGq6NVD4wMKVYcjP2NLnV6JXdLrzmHbtsrHyNRPtDUlb8PhjuU/j9UJdgCK956iOZn9atzu54lP9frB1u7NO/R1bUKqOwmxu+aObAscKxf+DFNK/gVVP4V1wkcH3sVnQDId05OCkYwyDy0l8By59uCA4CKf++Kr73dPcFLTVX7t78l4e1v2X/NCMa/+EWF96otXeI4BZjMZgKm7/ZItyQbdep1LXEAtKD6o5PLa90xklHX3eeWVrqOiNnsh59/APvG9SM71ET3/ufi5x9AUIjx5x/ZTFW45siAC66j6D9P0X1TXK3zVp5/k2ac9cOPHJx6Yb3cz/WbfGqXkArP6/L5L/XyeqWqChqno04fLSXz44/rfB/L/U/V+tp1Cz4gNyuNFjuMthOTIyAsvWoUTR99q8LrVED1voOXL82lveFZyjUXVqP46ELsiuUve1+iIeK7dTW6V3XpwHGKCG7SlPUt/+aWFnP0awBCVX6150NaN+9V4heX/fFV1O2zvl329rcMX7/NpV61NL8VN9yZTCYGj5lMYHCoW1WWq0MRoc5pU5LG9SXdpX681YofOTztCtIfv4kDvZoDYC3Mp014D8bOmIV8+W+3eyUND2f/gLJZBAre8piwGYDsUM8/i0MRoVz8s2c32JSuTTzSAE40039atVG+jak2Qjxrx6qt2Yx3SIk5z1lSavfmPP785i267ay4ihOge1z5sc3VU77KD6DTwZpN/xOUkUeX2b9VeHzDktk1zldV9G/3KWTYtC9Rz5xgxxj3qbn8xcbRQ3tRdjvplUwNrex2RiT8i+i4R5xphQUnbxp118Y41+kqquPCe16i/R8/u/XYSjqnG2OWxjEybgdRuxKY8PZ3jL6lrP63bedeXDTtZUbfPIOIp54jtXMIUedd4Tzee/hY9k0cwrGHr8f0v3c4/915jJ3zG9YPXiT8r5UMHT+VE83cS3O9du4gJn4Hh//pPh9n1DtGL3JbuTjYboZ78Nl/XQxB333KqPU7yq7dlUD6Y1ModvlSmnROt5q8PYAx91hmC9/2sDsZ8t9sXAtDtXy+7qWg8nKa1F9PqPI98cpr2aVnpcdrQweOU4iYTIjJRN9RnkuMdPh8OHEL3qHNRwNJ3GI0jmVlHGXt7CewOeYRSj/i2QC+Y3HF80X5UungsZpMgNGiTWfGzfyEHls3GYHik7LG4ayMoxTkGW0+ua89hP2TV9yu7TVsDBev2ECzlu498i979WvOv30mvYaNITSsFWazH/3Pv9p53qj12+m8bg2tVvxIu9+XOYNf087GiI19wzqS/eI0Op81FIDgeR+Rcudl8PkbZDx5CwPOv4bcVx+k2aI5JF3Sm4ufnEVEv7IeVsWOqu/RtzzBoO0JmL96F8t/n2PCJ0vpvO4PbB+/7Dw38+nb2H9dDPZPX2XfEM+RBZnDe9Bjbs2mKbFUEGeOPXy9czvjyVuc23nBZR9o+we2Zd/4/tS3yOGe86flvTHdrf6/PnWNX+u1FOlrx6bfUOGx7gvLT6LhO137xNT7PXXj+Ckqtu31xKTNo1AFECxGddPwbTMBOL5vEww8h8TZ9zAy91d4cRZFjx2mIMezXjxmT8MsW1KXKjL/AM8PkObv9eKQdCTk2QSGX367l6tqLzSsFaFh7h1hh19xJzvbhjMuZrxbSSpywLllXXxHGisuDp94BwDh7y5wu0fndX9QvqrOdV340LDWRI2awIqer9D8lps456p7ys4bNoaighysliJ2rfoJu7WEMVfdhZ9/EK6VJmmPTqbta0aV5oEp56NsVrp9swa7wLEOQfSbPZec40fJyzhC6rIf6f5/WwA4//aZ5F57DwGBIUQFh7Jk4f/hl1eE5awuhC43Rqrb27VizMtfkLRkqNszJE86m5HTnmPNc9PcehiVspqg6befUXi1sWRy2OJ5bHzhYSJjjXaDJqGtKHx7Bv4hTfG78wlSujbhkgm3sqttOOqmB8gPErJuuYzOoy7BPqXqXm3lHX14Eu3fnAtAyp2XERXa3DmIszIF/36CI3O/dOazLg72bMbY257h16IiOpb7vdh3+WCiwnuQUcG11WHxg4HbE1j58XPOZ/Um6exuRPmgW64OHKeomHs+wlryHrbCfNbNfoARmT86jynHPDj+1lxn2tHXR1A07t8nOZcVs5XUoaK5Ap1V7eqRa6vPqAlVn1SJ0LDWVZ5jNvtx6f/FeqT7BwQ5A+jIa93Xkz/64LUEtmhN9MR/EBUYwvHxUwhs0pSopi1Z9oIRxJLHD+CyN42pWtp27gXAoIsmkXzzWrr1Nbq+OkedA5fOKxvodmh3PPtWL+LCyQ8REBhC5tO30eqFTznUrQkB105k3G1PAzDh3QX8OusJOr67gKRRXRnz/g/8fPvlBA0dTP++IymdpaxJ8zZM+GKFc54uv8AghowzuqAnzW/NiE5GVUr3geeSBKRdFs34+18nNyuN0o/w9MemUPLVtwTdfhPKanXr/nukQxDd3/uvM1BdcPuzWG6czsE9cVziGINhf/gfMPOjCv8f8oKFYZdO4Y/0IxD7OVlNTTTPrbpd8Wj7QI+qoqhdCc6egxfc/SI7+g3j6MY/6fThYpJGd2fCa984X9N1/ElNHOtktK11HDQSO+6B49A/xhLYsjVtX/saKay/iRtd6cBxCvPzDyDUPwDl794AqzKTSE6Ixy5lXQC72Q+xb+nDzv2krX9RkJVO/Vc0VE/pjLENMar1dHfBnc+77bds37Vsp/TbZQVve2nQKM+1VNU1arjbVBmjbniI1UWFnH/jwx5TtLQ6qz+wgODBgwgIDGHCl2W9y46HmWmZbSOkqbFkjv3TVzn0+xK3b8CuAzQDAkPosXUTvfyMXnhNm7cls4WZVidsdBt5CV1c2reW7NmJbNvNRXN/oYeYyMk8QiFlbQcBwSFuA/fOnvQgizesI6BjJzp9uNiZnhzVAlv7Vpz/ijFNy6i/P8TqwnwGXXEbR0e7jzPy5oLfN5OWsofMi402seJ3n/F4X/ufdyUlBbnAYswdy6oguy9ZTMol48m4cyIdZ3nOXGD94EWK8rIJfeR1j2O2UONLRa9hY8hcuYS0C4zq7WJ/6D1hMilb1xqvX+ybzjGiGvlC9NURHR2t4uPjGzobtXYi/QgHP53CwKI6dludWdlY6/q1bfUC+v92MynSnk7PenY1rrGZYY5/T94zNEZ52Rn8/vAUzn75I1q06Vz1BfUgecdaukSN8BipnHP8KPs3rWbgRd5Xv6yOw0lb2Tb/Ay557L0qR0Kv/PAZ+l52I207nVXpeTablU1DB9CkSBHywxd07TPC63mxP/wX7Iqwp96jyB/krWcozsumSev2NG3VgfysdGepdP3Cj+kefSGtO3rOOl0qfvHnDLj4eo/gC7B/+1/smv8JfrFb6HSwgKymJkbGGR0sdq1fTmiLtuT+7e/O8w9OvYCxM8rWzVl008VErk9FZr9N7xGXkp15hM1XjKXVv56n37lXVPp+VEZENiiloj3SdeBoPHbH/4b/kgdrNVvuCZrSYqZn3W364WSy01PpMbDy+adqastvcxm4+k5SpAOdnvWsB68xHTi0ehT73SyyP5/NxQv/qnAyzFLHDiQQEBJ60gJxblYaJrOf2+SPYHwp2LlqAU3bdKTXiHFugTQrI5UtCz/nvFtrP4bFm4oCh66qakR6RV/I0bbfkfr5ZYQr71OMV0Qq6N/U7MNo2kgJDKzfD2RbSWl33Lp/MVF2u67w0upVzDX/hGu8D5orr13XqKpPqkeubU+uQsNaV9gxpHnr8HoPGpXRgaORad+lJzxrrD9wPC2Vo0lbKVoziyH5xsSIG5uc69wuZVFmmpKP3WbDZHbvnxkovlkEpnSK+PpQUmLB+9hzTdMagh7H0Yi1bBtOn5HjGDJ9EWu7GmtjWUI7eZxXJEGYRbHjtYtOWt7szl5VdS8r1OeSnpqm1Z0OHKeJYTe+wNbzPqXZoIkex4KV8cHbv3gTh5O9N1Qru52kbbGs/+4tDj/Xk7gf3/N6XnVZjycDkG822iZys487ByqWivvhHbatKr/Ao6eSYh04NO1U4tPAISKXishuEUkUEY+JgRxrjf/HcXyriAxxOZbsWCJ2s4jEu6S3FJEVIrLX8W8LXz5DY+HnH8CAC66hz8hxxA1+2e1YhpQ1spm/GMe21T+xfsG7buccS91H5PdjGb79OTqqNIZtfpK1Xz5d6/wEnDAWsTFhw1pioenbEcS/f5vzeImlmGFbn6H/ylsquoVT+dX1NE1rWD4LHCJiBmYB44A+wA0iUn6h3XFAT8fPHcD75Y5foJQaVK5V/3HgV6VUT+BXx77mYtjEe2BmNuqZE8QNfpmia792HmtHJv1/u4nhW55yTuEB0P7ToR73GbnvP6TuK5tzKScrk9j/PeNRcvDGz2pMER9sy3XOlzU44/+cxzd+fI/X67yx6KoqrY72bFzlnKpHqztfljiGA4lKqX1KKQswFyhfjzIR+FIZYoHmItKhivtOBEqne5wNXFGPeT6tiMnEsIn30C1qGLFtryel3Fsb8kbVK0ikJW5ybu+c8wQxSe+w/utnq7zObDdKCZ3UUXYu/dDIj8vx9pmeo6UrYivRgUOrm7MWXk6PBZc1dDZOG74MHOGA68pBKY606p6jgJ9FZIOI3OFyTjul1BEAx79e+66JyB0iEi8i8enp6XV4jMZPTCZi7vmIJvesrPG11oIswBjv4VdozIU1cv97HDlQ+aA+P3vZiNXuu0oDR1nXXFWDXz2rLnFo2inFl4HDW3ea8p36KzvnbKXUEIzqrH+KiOdCvJVQSn2klIpWSkW3adOm6gvOAC3adGD/db+wvsUEcvC+jkR5tixjfqg2Hw0kOmeFM/1IwtpKr/Ozl7VLBGIEEdfAke/XvLrZPmlriminp6LCui/rq7nzZeBIAVyHWnYCys9SV+E5SqnSf9OABRhVXwDHSquzHP+moVVbRJ9hDL//a+TB7Ry5Zb0zfUPo+V7Pj0meRcZRzyVnLellS7LuXLuU2E8ecjvupyxsCzSWmm3mWBLX9VtCbgujueugqXwh1JNNlzi0OsjPqXwRJq3mfBk44oCeIhIhIgHAJKD8JPQLgZscvatigGyl1BERaSIiTQFEpAkwBtjucs1Ux/ZUwHN2MK1KTcNa0qFrL7Lv3YNlxjE6XP0qdiUcMBnjQNa3KKsPNn/gOTFeTNI7pB9OJnHLGvosn0RMyqdujeYBykJxYGu2Bw5yppmkrMQhtuqXImy6xNHgbFZrtVehPNXocUD1z2cjx5VSVhGZBiwHzMBnSqkdInKX4/gHwBJgPJCIsTp7ad/MdsACESnN4zdKqWWOY68A80XkNuAgcK2vnuFMENaqHQAdI3rDc1m0zc9l/c+fM2ziNHje6Oncglyv1x6dfQv9izc695N3rid9yzJGTJ6Jv7Jg9wuiX85mr9eK1fhj9lNVj1zXjeMNz/xiKzaFjGLwo0urPvkUY9XjgOqdT6ccUUotwQgOrmkfuGwrwGPCGKXUPmBgBffMBE7eEOgzTHCTpgy/8j4Asu9LJGH5x8TsfhWAFOlAWpOzKG5xFiMPfUyvoi1u9U+RP4wjElg7u5iRnGCfOdDra2SfyGB4lvFrEaA8SxP7d8aBshPR15i11G7VJY5TweCCvxo6C7Vi1V886p2eq0qrUFjLNsTc8ASxX+SBfyAxk5+ldEKT2A8KiDn6tdfrRh4wvhsocyBbg4YyoGgD+03diLAns27uyzTZvwzHXLf441niiJjvWCWvrzHOxH6K/uEru53Yzx6m2yV30aFrr4bODpt+/oruQy9xliI1g+6VV//0lCNalWJu/hcxk93Hbpjblx/L6UkFNaPHtAUcuWU92aOMcZojdr1Cv+LNznMCVAkblnxKWur+Cu9j2V9xDy5LcRElLiPLd8X9Quz7d52U+vjkhDhGpnxG7v9u9PlrVeV4WiqD//onqR9e3dBZOeXowFH/dODQaiUi5vIqzzE3bUdIaBgduvaiRWfvU1MHi4Wh6x9CfXwR2ZnuU8XbbTb2vhhNTNo8Z1pxUYHbOdZ/dSHzX32d+20W30rMsTlkHD1Yk8epldKlbPztDT8lit1uA6C95UC937uxd4e2WgobOgunHR04tFpp3b4LJU+kUfTYYdZ2uYNDN65hY8w7xA95xeWssgaQDt16V3q/dmQS+J++bmm743+hp3WvW9q2/94EM8PYsMRY6jNEimlP2QDPQgkGYN+a+W7XpR9OJvbr591KIimJ27HbbFU/bBUqWuukOpTdXi95KL2Hmbrfy9WJ9CNs+OHter3nyWbXc53VOx04tFrzDwgkKLgJI299nc49+jPk0puJvvxusu/dw7rWV9FvbNkEhgGBQR7XbwoZ5bYfJCUkvFTW9TfnwBaPa0oHIQ5d/4DHsb2b/6CTOgrAiJ0vuR1L+epuYva+SeKWNRQV5MHMMDp9dTbr5zzvcZ/qKq0CqUvg2P7qRZheaFn1iVXmxfhw9FP1GzgOf3w9IxL+Va/3PNl0r7z6pwOHVu/CWrVjxLTPCQkNc0vfNPI/bD77fbIIZW3HqQx+dCkHrv+N2HY3OM+JKtnp3C7/4V+VzLVfVXhMlFHSyDm8h6yMI870wMPrK7qkStbi0mqz2gcO1+7MdVHac8ivnkscrS2eyw03NnaXRcUa61iUU40OHNpJM3jsVAZd8ndCZiQR849/A9A1aigj7vwvse0m1fh+rh8Cm3+dS3B2ktvx2P8949y2+hlTrJTkpGEpqngKCktxEYlb1rB/xzqYGcau9SsqPLc0cJSWOI6lJHH0UGKNnwPq/oFmcyyc5UfVMxeXys/NqnLOsQAvvd4am7JFxcBmq/77o1VMBw7tpAsIDEJMZb96YjIRc/eH7J6wwOPcda0mknHXdg7d6Dkl9qHErc7tQX/cycCiOLfqr5ikd8pew1GFo4pzKMpzXV/dfbq0LUs/pceCyyhZMA2A7PXfVPgctnKNru0+GeJ1enqoOjDUdT4lm9X4gDdL9Us/h/99ER0+H17pOd7G2TQ2rssYl+j2jnqhA4d2yugVfSEpN/7JnssXYn0ynfX9nmXgP96ndfvOdO7Rn13jviWu+Ti2BhnLs3T55jyPexSHe06PAmC2GVU5I5Pf56yFLj3CxD1wWLOMebnCS4xeWSZrobEmiZfSh63ECByiKv+w3vjG5RQ/5zmJs+v6EHnZmZXeoyrWEvcPxAO7N5O45c9Kr+lpq7p05G2cTWPjGjjys483YE5OHzpwaKeUTj36cdaQ8/DzD2D4NQ8RFFw2i2/vEWMY9sBcbEPcVw3cb+rKtkBj8cjOI68lLuzSsoMzw4h7+3q6FW7HG39rHhuWfM7Wld+xb/s6RiYba4k1EUfDt72EQ2vmApAdN5fY/97hDCJ2R+O4uVz10Prv38ZSXMT2P36CmWEMyVtFkJRgf7Y5hfll07e4rg+Rn51R6fuSum8H216+gONpqV6P28t1me065zx6LBhf6T1LVbYwV4BU3maSm328QRZIshQXVbs3mmvgyM3Sc6LWBz1yXGt0Bl50A/GWAvy3z6eg3VBG3vIqWRlHSc3JJLx7FCn+IW7nD8teVsGdMAYjOnpore1wI93LHRe7FfKN7r4j0r9zpvdecg3xzS4BjOocm9WK2XFs+LaZrM095gxCpUyiSDu4h65RntVZRTmVfxPOmH8/A4s3wn/7kHHXNlq3d1+Ey3Valg2LP8F7hZl3xUX5Hh0ZquvQrMvpY9lGSVQa/gHep5jxhYCX2xHf7GKiH/q+ynNdA0fBCR046oMucWiNjslsJnrCHQx8/BdG3mLMo9W8dXvCuxvjQDqOfYBi5c9+U1e367YEDXObrTcH9wDTLHObx2v5W3MrnMm3tGuwGRvZx90HL5pyj3i7hKyj+5yDE7Npwl6/ngAU51ceOEob9wEyDu0BjLEbJ9KN17G5BI6hcQ9Xeq/yigsLvKZ7a5cpfb1SfSzGe5adcbRGr1kfonN+qfKclMTttDj0m3O/ONdzUbc9G1ex4c0rGv1Ax5NJBw7ttNO550ACn8sg4pmtMDOb/df9wt4rFjHw8V/oN2MVW4KGka+CSPF3L1/0tXiOGwmy5mK2ZHuku2pBLge+uN0tTSoYTzFw1T9o/UF/krb+RbAqJjfQWM63JC+r0tdwvV9W/LcArPvyCVrM6k3G0YNuPYdqylLsPXAU5Od4pO359Quv52Zneg+UFTl6cC9xP/23RteUqsmAyU5fnU1va4Jz31roOdNz0KK7GZq7ktQk79WZtXHkwG4s9TQr7/4d6+plkGh90oFDO+1F9BlGz0HnOvf7T19OwJMHCbz8TXYEDMCiympsY3s9SqEKcO6fZd1TrW+2gwvcG6LbZxnjM9Z2/od7m4tD5A/jCBArlhBjQsLIjS+x/eXzvH7LX7/gXYbk/+HcjzlmtLm0TfkZgNTZ/0DZat+IbSnyHjiKvfT0GrHrFRLWLfdILzhRs8Bh/uwShm2aUaveZJbi2k8hoko8r83zMwZg2uff4nGsNgrzc+nw+XC2/PemOt8raetfRHw7hnX/e7IeclZ/dODQzjgmsxn/gEAi+8fQ94k/MD99jOz7k4gb9C8GX/kgey8wZvc9QtmSw1uChrG2w43Etp/MjoD+zvSKluDtYjcasU3NOjDswXlYZhzzeh5NjRJHC3LoV7yZExnuH8AZhw8wfMtTHpelpe6npc2odhlYuK7CEseejavY9WIMaz99BDC+rZdvDC+pIHBU9AEdtfQ6sk+4N+YXZ3k+X1FhPuveneq1Qb8Nxqp8tVmdr7gO3+S9Bo7QbgBE2JNrfV9XpQG3d9bqOt8r56ix0mZQmmdpuCHpxnHtjGf28yOsRWuGXWEsDTPg/KtRo6+kg8lEwrrl5B1N4qzR1xHWorXzmuSEePj2ZjKHPkDrHtF0nePZNRggpF0kYIxdSTJHEGlznwVYgsM4SmvaY3wQ71n+Id2SviHf3JTMsL50P/6Hxz0B2n48yG0/euNjXs9zdj0+lAC8wZY3Jxjraswsq35LW/0p3fsZa59s/+MnSgqyGDx2KiWVDJQ8fmS/2/thzU0jccsaTGZ/jm1YyICrprPjl/8xIvNH1s21M3zabNbNfYnWfS/EWlxA6cxlhblZ0K6T19dwVWIpxmz2w2Q2U1LNEoey28uN0gFl8QySdv9QAHb696PqOZ+rVuLsbed97E5yQjy2EguRA0Z5Pe6mtIpSTq3v+DpwaJoXpQMUo0aM9Xq8W1Q0PLOdbqUJjg/iTctnEzF0LElf3MnQvN9p2alscscWdy6meNZAAqWsWskc2ISi6+ex7cdH6F+8qWzQoi2dyONl67rXh3XvTmWEy2JMRcqfICkhJm0e694rIXTItfT71ahesV00GUtRxR/QuccOYO81xFllYcrcQ48FbwLQHTj01g8MV4cBo2da4tY/idnzBux5w+0+RflZFb6GpbiIg7s24B8YTNe5F7CpyTkMnr6YknJtMnk5J8jLzqR95x7OtF3xv9J70VVu51mVCayepRWxG/8fgXbvJa+KFBXmu3UXd+bb8b5VNP1Lt3mOdegGVN52BmC3GcFHnWKBw6e5EZFLRWS3iCSKyONejouI/MdxfKuIDHGkdxaRlSKSICI7ROR+l2tmikiqiGx2/FSvs7qmnQSDx06leev2DLhvPnsu/4nw7mXTybdsG07+P7ewvuXf2NhkNLv9etG+z7l0i4qm/4zfWd/yb273ylPBbvsbR75HyRPV6066ro9nnfiIzB+d2wee70eQSwAbkfEDfX8umzPs8Ev9sf5krASZaI70uFf+oS2s/6hs8c6W2Tvdjnd2BA2AiKy1br2+XBXnVfzhuf91YyxK17kXADA43xgv4rq+xrGUJELf6uYxYj/7ry887ldEIH1Tv2Xn2qXONdSTE+LB0WsuyF55e0ta6n7WfvoIdpuN2C+eIOjVjh7T929b9QMtZ48Gqp6pOP7Nqyo9DqAcQU2J2eNY0rZY1r07tUF6g/msxCEiZmAWcAmQAsSJyEKllOtv2Digp+NnBPC+418r8LBSaqOINAU2iMgKl2vfVkq5f3XRtFOIf0AgZw053yO9Zdtwht/nfTLG4fd9xYFdGzm27HXC8pKwX/ICUUuvA4xqlCFjpwBGAFHbv2do7koA5+qKADsD+pN31lW07DEMHH8tW4OiGVAU7/ZaXe2HKs1/Z3WY0nGNRRc+x8a/PnRroB+57z9u5/ewuc8T5qoNJ8hY7tlOA1CcV3E35F7WXV7TU+P+j86O7bzPr6Z0vcPC/FwsxUWEtWyDPbQ9lLt1kQTSmiz6LJ/EltUjsA24gSHrHqCNCgKBEFV5FdiRr+5gZOF6dm0YS7/9n4FA+oEE55iawvxc+q+8xTmLjbfpX+w2m/PbenTurxQXFRAYFOJx3trPH6PJsQ2o3lcAoDCh7HaKiwudpZycZS8wIn8Naz9vxsg73q007/XNl1VVw4FEx/rhiMhcYCLOX2dw7H/pWHs8VkSai0gHpdQR4AiAUipXRBKA8HLXatppp2vvIXTtPacsYUQ2+3fG0TykmTNpyNgpMHYK8Ys/RhUXEH3FvSRtj6UwO51+5050nrc973+06daXAZ0iWfftG4zY8YLH6+WpYEKlkFwVTFPx/sHpFxhC34cXsivuF9p170+LWe5rq2wKGVXleuSusx67GrJ2GnvadOH4um/oPPY+Mg7sZMB5V2OxFFHRcMKYPa87t7taDzg/qBPjV9B/5S2kSAek7fmV5mdg4TossRtAymYJCFX5xge72fPbPZTNsHwi4XdaSjChFFKQWVay2vLTv4kpd83aj+9n5O3vsHfzH5jM/rQOj8R1qGVe9nGvgaN0+eXYfKP00iV3E+vmvEDM3rfImrabsJZtnSWwEan/w1L8utelC3zFl4EjHHD9WpOCUZqo6pxwHEEDQES6AYOBdS7nTRORm4B4jJKJR9cMEbkDuAOgS5cu5Q9rWqMR0WeY1/Toy8rGjnhraO13TtmcXMOuepBt7SJp1TkK25dX0lkdZst5n2DJSWfYphnsiLiVPlc8TEZKIuYfbnMrkfgHBCMmE71HjHG7//qBL2AvysWvSSvYWHngqEzhzy8QUxQHX84lHNhQkE3XoWMJBFKkvXONFTAalru5XLs7sC99HYMQ+680utN2UkfodMwl+DrYcA8IAeLeu8xfbCRuj6XHwLMB2LLyWywnDjPsKqOmvMS/KRTByP3vcRwjkPdZ9yi2MVNITog32nDKGZn6BfAOPX+cAMDhm9e7BY6C3BO0Ktc5oMRSjL9jO2av0W7UluOw9wsAjh89QPqhPfR0nGMSxcFd8WT89T+UOZCelz/iMbNAffNl4CjfoQE8Fy6o9BwRCQW+Bx5QSpWORnofeMFx3gvAm8CtHjdR6iPgI4Do6OjaL5igaacBk9lM/9FXAqCe3sHxjCMMbBtOiaWYLU1bEn3uVfj5B9CseSvot52crEx2Ln6P0IO/ERHh2dfogKkTw6802kAyDh+AjY+RbOpMN/shr1VjpbYGDWNAUZxb2sBy+0PjHmbjzh9pDaRETqJo//85q8KcDcsOQbY8MgmjFVU3NGf5taGdtfLJJP1+uhMGbqfEUszAVf8A4GC/8zCZ/LA5el8BtMT4OAoWC3HvTsa/pOLXP7x/Fx0d2ykblji3AYpyje+8216+AEtAGJZWvfE7sQ9vXxXaOureun83hrgB7guQFS+eQYzFMVv0B7Pdes35gi8bx1PAWRUJ0Ak4XN1zRMQfI2h8rZT6ofQEpdQxpZRNKWUHPsaoEtM0rZrEZKJl23DAaIsZeOEk/PwD3M5p1rwVMZOfpd+MVTRp2tztWN5DybSbXrYAVuuOXTl+z046P7GZjLu20+0uY9ne2F6Pwcxs9lz+k/PcftPLBg9uv+jLCvNY2p4S3DGKHk9v5MCklW7Hd/kZnQ4ibftJ9w+v9Hnjm13MjjFzUGNf4iitWdfHs73lkBgf54VmoyRx9EBZ+8qR5W/T6auzGX78/7zef1j2MgYVrAVwW5SsVMfZZRUtw7fNdDuWl36Q3Ozj9C/eyNDclYxMfp9h2Z4DLMuzFRqBYcPwfwPQosR9ypfy42zqmy8DRxzQU0QiRCQAmAQsLHfOQuAmR++qGCBbKXVERAT4FEhQSr3leoGIdHDZvRKov3kCNE2rUmizFh7dUFu2Dcfs50fr9p2NUsvMbGJueAKAnoNGE9vjAQ7fvB6T2cyWoGHs9etJv3MnOhfw2ho0jMPiOfV8h17Gh27X3kPYduEXzvQTHUc7ty3mJqxrbfRQigvz7D496N459B01nt7DLqb9zCRGXDedJLP7dDOd1WG2BA3D327Mapz+Y1mvNNfeaFWJufsDdk9YwFFas/ncD6s8f/Bf/6Tp2xEe6fmq8vaKwFQjUA0aM4WtQUPpqNx72+3fsIL9O9axf2ect8vrTFQVawnU6eZGV9l/A2bgM6XUSyJyF4BS6gNHgHgPuBQoAG5RSsWLyDnAH8A2cI6ieUIptURE/gcMwqiqSgbudDSmVyg6OlrFx3svOmua1rCKCvJABJPJTM6JdPbNfZToE0tJv30D7Tp5dgXeFf8rPQedR9wXjxKT8imHp66jfZeepO7bTueeA9n94gh6WXexNvwWWgz+G72jL/LyqsYAwdhPHmDk4dmsDb8ZseQTk/5tpXlNkfakRN5ATOLbHscyaE7rmQec+9mZxwh796wavhuOa2lC1qRFzq7IpWJ7PcqQXW8RIFYKVQDBz6UT/9bVlU6LU/z4Ea8N8NUhIhuUUtEe6b4MHKcKHTg07fTkrTvr1t+/Z8Dvt5J+xxbadOxW5T3yck7QJDSMPRt/p9eiK92OWZUJPykbAb42/GZaD7vG2dgNsGX0h5jWfUiLa9+lU49+btdnzuzibH+JbXcDMS6N9iXKzLamZzMkz/vUJNn3JRL2nx7s9O9Hbo+/Edp5AH1HjSdnZkea4RhzMjOb+Leucc7U7E3ilUucDf41VVHg0CPHNU1rtLx9kx5w/tVw/tUuM41VLrRZC8BYgXJL7if0/P2fJF30Ib1GjCNl7xbSd65m4N/uYefv8xl28WT8/ANYt/dpWvYcgYiJgQPPhgsneb23330bSJo1hkjbPtqddxubUs6hOCOZmD2vE9/lVkbe9gbKbudwcgLhX5b1jEs2daZbyzYkjJtP9/5nExRS1jB/zK8jzax7jRJOudeLbXs9YSe2uXV/LinKq+Y7UX26xKFpmuZDJ9KPsHvFp4yY9IRzKpuUxO106NYbs1/Zd3e7zUZW5lES//yBYRP/6Ty3vIyjB8lMSaTHoNGY/fyI/eYFYva8wY5LvqHv2Zex9ovHnYuIxQ95hejL76513nVVlQ4cmqadhuw2G3s3raJX9IUAHD2UyMEfnqXdpdPp2mtQne6tA4cOHJqmaTVSUeA4taZc1DRN0055OnBomqZpNaIDh6ZpmlYjOnBomqZpNaIDh6ZpmlYjOnBomqZpNaIDh6ZpmlYjOnBomqZpNXJGDAAUkXTgQJUnetca8O3k9qce/cxnBv3MZ4a6PHNXpZTHtF9nROCoCxGJ9zZy8nSmn/nMoJ/5zOCLZ9ZVVZqmaVqN6MChaZqm1YgOHFX7qKEz0AD0M58Z9DOfGer9mXUbh6ZpmlYjusShaZqm1YgOHJqmaVqN6MBRCRG5VER2i0iiiDze0PmpDyLSWURWikiCiOwQkfsd6S1FZIWI7HX828LlmhmO92C3iIxtuNzXjYiYRWSTiCxy7J/WzywizUXkOxHZ5fj/HnkGPPODjt/r7SIyR0SCTrdnFpHPRCRNRLa7pNX4GUVkqIhscxz7j4hItTOhlNI/Xn4AM5AEdAcCgC1An4bOVz08VwdgiGO7KbAH6AO8BjzuSH8ceNWx3cfx7IFAhOM9MTf0c9Ty2R8CvgEWOfZP62cGZgP/cGwHAM1P52cGwoH9QLBjfz5w8+n2zMBoYAiw3SWtxs8IrAdGAgIsBcZVNw+6xFGx4UCiUmqfUsoCzAUmNnCe6kwpdUQptdGxnQskYPzBTcT4oMHx7xWO7YnAXKVUsVJqP5CI8d40KiLSCbgM+MQl+bR9ZhFphvEB8ymAUsqilMriNH5mBz8gWET8gBDgMKfZMyulVgPHyyXX6BlFpAPQTCm1VhlR5EuXa6qkA0fFwoFDLvspjrTThoh0AwYD64B2SqkjYAQXoK3jtNPlffg38Chgd0k7nZ+5O5AOfO6onvtERJpwGj+zUioVeAM4CBwBspVSP3MaP7OLmj5juGO7fHq16MBRMW/1fadN32URCQW+Bx5QSuVUdqqXtEb1PojIBCBNKbWhupd4SWtUz4zxzXsI8L5SajCQj1GFUZFG/8yOev2JGFUyHYEmInJjZZd4SWtUz1wNFT1jnZ5dB46KpQCdXfY7YRR7Gz0R8ccIGl8rpX5wJB9zFF9x/JvmSD8d3oezgctFJBmjyvFCEfmK0/uZU4AUpdQ6x/53GIHkdH7mi4H9Sql0pVQJ8AMwitP7mUvV9BlTHNvl06tFB46KxQE9RSRCRAKAScDCBs5TnTl6TnwKJCil3nI5tBCY6tieCvzkkj5JRAJFJALoidGo1mgopWYopToppbph/D/+ppS6kdP7mY8Ch0SklyPpImAnp/EzY1RRxYhIiOP3/CKMNrzT+ZlL1egZHdVZuSIS43ivbnK5pmoN3UPgVP4BxmP0OkoCnmzo/NTTM52DUSTdCmx2/IwHWgG/Ansd/7Z0ueZJx3uwmxr0vDgVf4DzKetVdVo/MzAIiHf8X/8ItDgDnvk5YBewHfgfRm+i0+qZgTkYbTglGCWH22rzjEC0431KAt7DMZNIdX70lCOapmlajeiqKk3TNK1GdODQNE3TakQHDk3TNK1GdODQNE3TakQHDk3TNK1GdODQtFOQiJxfOouvpp1qdODQNE3TakQHDk2rAxG5UUTWi8hmEfnQseZHnoi8KSIbReRXEWnjOHeQiMSKyFYRWVC6ZoKI9BCRX0Rki+OaSMftQ13W0/i6dL0EEXlFRHY67vNGAz26dgbTgUPTaklEooDrgbOVUoMAGzAZaAJsVEoNAVYBzzou+RJ4TCk1ANjmkv41MEspNRBjbqUjjvTBwAMYayp0B84WkZbAlUBfx31e9OUzapo3OnBoWu1dBAwF4kRks2O/O8bU7fMc53wFnCMiYUBzpdQqR/psYLSINAXClVILAJRSRUqpAsc565VSKUopO8bUMN2AHKAI+ERErgJKz9W0k0YHDk2rPQFmK6UGOX56KaVmejmvsnl9Kluus9hl2wb4KaWsGIsNfY+x8M6ymmVZ0+pOBw5Nq71fgWtEpC04133uivF3dY3jnL8Da5RS2cAJETnXkT4FWKWMtVBSROQKxz0CRSSkohd0rKMSppRaglGNNajen0rTquDX0BnQtMZKKbVTRJ4CfhYRE8Zspf/EWDSpr4hsALIx2kHAmO76A0dg2Afc4kifAnwoIs877nFtJS/bFPhJRIIwSisP1vNjaVqV9Oy4mlbPRCRPKRXa0PnQNF/RVVWapmlajegSh6ZpmlYjusShaZqm1YgOHJqmaVqN6MChaZqm1YgOHJqmaVqN6MChaZqm1cj/AxKBXUlE/+lpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot()\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그림의 저장\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "plt.savefig(\"modelsave/Model\"+ str(now.month) + str(now.day) + str(now.hour) + str(now.minute)+ \"epochs.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    }
   ],
   "source": [
    "y_p = model_1.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.7528076 ],\n",
       "        [0.60737467],\n",
       "        [0.6896039 ],\n",
       "        [0.43997076],\n",
       "        [0.39980727],\n",
       "        [0.44037652],\n",
       "        [0.715752  ],\n",
       "        [0.6378025 ],\n",
       "        [0.85962665],\n",
       "        [0.35394782]], dtype=float32),\n",
       " array([[0.76728813],\n",
       "        [0.65214751],\n",
       "        [0.76377719],\n",
       "        [0.43681026],\n",
       "        [0.33958441],\n",
       "        [0.45913619],\n",
       "        [0.78610313],\n",
       "        [0.635187  ],\n",
       "        [0.98703655],\n",
       "        [0.28989119]]))"
      ]
     },
     "execution_count": 727,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_p[:10], y_test_scaled[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 847.5       ]\n",
      " [ 737.24137931]\n",
      " [ 844.13793103]\n",
      " [ 531.03448276]\n",
      " [ 437.93103448]\n",
      " [ 552.4137931 ]\n",
      " [ 865.51724138]\n",
      " [ 721.        ]\n",
      " [1057.93103448]\n",
      " [ 390.34482759]\n",
      " [ 280.        ]\n",
      " [ 626.20689655]\n",
      " [ 437.93103448]\n",
      " [ 647.5862069 ]\n",
      " [ 560.        ]\n",
      " [ 544.82758621]\n",
      " [ 350.34482759]\n",
      " [ 600.        ]\n",
      " [ 573.79310345]\n",
      " [ 354.66005857]\n",
      " [ 513.79310345]\n",
      " [ 568.96551724]\n",
      " [ 724.        ]\n",
      " [ 707.        ]\n",
      " [ 327.5862069 ]\n",
      " [ 475.        ]\n",
      " [ 445.        ]]\n",
      "[[833.6335 ]\n",
      " [694.3669 ]\n",
      " [773.1096 ]\n",
      " [534.061  ]\n",
      " [495.60043]\n",
      " [534.4495 ]\n",
      " [798.149  ]\n",
      " [723.5046 ]\n",
      " [935.92334]\n",
      " [451.68542]\n",
      " [248.782  ]\n",
      " [560.60455]\n",
      " [378.78098]\n",
      " [629.3171 ]\n",
      " [677.9102 ]\n",
      " [492.51254]\n",
      " [408.12665]\n",
      " [501.65594]\n",
      " [580.1611 ]\n",
      " [292.46924]\n",
      " [572.7859 ]\n",
      " [524.9748 ]\n",
      " [720.36554]\n",
      " [703.456  ]\n",
      " [322.28787]\n",
      " [470.3987 ]\n",
      " [431.95575]]\n"
     ]
    }
   ],
   "source": [
    "y_test_unscaled = scY.inverse_transform(y_test_scaled)  # scaler.inverse_transform(): scaling을 환원(unscaling)\n",
    "print(y_test_unscaled)\n",
    "y_p_unscaled = scY.inverse_transform(y_p)\n",
    "print(y_p_unscaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "# model_1 = load_model('modelsave/Model7251545file.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c6d60f7400>]"
      ]
     },
     "execution_count": 730,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "\n",
    "ax.plot(y_test_unscaled, y_p_unscaled, 'r.')\n",
    "ax.set_xlabel(\"y_test\")\n",
    "ax.set_ylabel(\"y_predicted\")\n",
    "x = np.linspace(0, 1000, 100)\n",
    "y = x\n",
    "ax.plot(x, y, 'b')\n",
    "#ax.set_xlim([y_p_unscaled.min(), y_p_unscaled.max()])\n",
    "#ax.set_ylim([y_test_unscaled.min(), y_test_unscaled.max()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그림의 저장\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "plt.savefig(\"modelsave/Model\"+ str(now.month) + str(now.day) + str(now.hour) + str(now.minute)+ \"comparison.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[661.          88.8        225.5         22.2        366.\n",
      "   22.2         29.2        277.2          2.          59.2\n",
      "    5.          88.8          1.        ]\n",
      " [799.31034483 277.876       40.68965517  25.4        447.04\n",
      "   62.23        85.09       271.78         2.         260.35\n",
      "    7.5         76.2          1.        ]\n",
      " [827.5862069  241.3         40.75862069  25.4        482.6\n",
      "   99.06        82.55       233.68         2.         260.35\n",
      "    5.         101.6          1.        ]\n",
      " [827.5862069  363.22        38.4137931   25.4        439.42\n",
      "   63.5         86.36        70.27333333   4.         260.35\n",
      "   10.5        363.22         1.        ]\n",
      " [958.62068966  96.774       33.17241379  15.875      330.2\n",
      "   63.5        135.89       171.45         2.         133.35\n",
      "    5.          88.9          1.        ]\n",
      " [827.5862069  139.7        110.55172414  25.4        429.26\n",
      "   62.23       119.38       254.           2.         260.35\n",
      "    5.          76.2          1.        ]\n",
      " [958.62068966 107.188       76.06896552  15.875      332.74\n",
      "   64.77       121.92       171.45         2.         133.35\n",
      "    5.          44.45         1.        ]\n",
      " [649.         127.2        129.9         31.8        428.\n",
      "   47.7         43.8        269.           2.          84.8\n",
      "    5.         127.2          1.        ]\n",
      " [889.65517241 308.102       83.31034483  25.4        378.46\n",
      "   60.96       114.3        205.74         2.         260.35\n",
      "   10.1         76.2          1.        ]\n",
      " [931.03448276 317.5         39.72413793  35.814      553.72\n",
      "   68.58        78.74       344.932        2.         508.\n",
      "    4.9        101.6          1.        ]\n",
      " [889.65517241 152.4         34.          25.4        317.5\n",
      "   64.77       177.8         55.88         3.         260.35\n",
      "    5.1         76.2          1.        ]\n",
      " [799.31034483 492.252       37.44827586  35.814      553.72\n",
      "   64.77        96.52       158.369        3.         508.\n",
      "    5.5        101.6          1.        ]\n",
      " [889.65517241 250.952       51.10344828  25.4        434.34\n",
      "   64.77        86.36       254.           2.         508.\n",
      "    5.1        250.952        1.        ]\n",
      " [827.5862069  236.474       41.10344828  25.4        419.1\n",
      "   63.5         87.63       241.3          2.         260.35\n",
      "    5.          76.2          1.        ]\n",
      " [889.65517241 305.562       85.24137931  25.4        383.54\n",
      "   62.23        78.74        52.49333333   4.         260.35\n",
      "    5.1         76.2          1.        ]\n",
      " [958.62068966 103.124       33.17241379  15.875      327.66\n",
      "   63.5        133.35       168.91         2.         133.35\n",
      "    5.         103.124        1.        ]\n",
      " [931.03448276 319.024       27.93103448  35.814      558.8\n",
      "   69.85        86.36       347.472        2.         508.\n",
      "    9.6        101.6          1.        ]\n",
      " [827.5862069  241.3         70.20689655  25.4        505.46\n",
      "   63.5         78.74       151.13         3.         260.35\n",
      "   10.5        241.3          1.        ]\n",
      " [889.65517241 248.158       78.89655172  25.4        350.52\n",
      "   62.23        81.28        74.93         3.         260.35\n",
      "    5.1         76.2          1.        ]\n",
      " [556.         285.          32.3         35.8        305.\n",
      "   76.          76.          81.4          2.         280.\n",
      "    2.95053326 285.           1.        ]\n",
      " [931.03448276 424.688       27.93103448  35.814      543.56\n",
      "   63.5         96.52       344.932        2.         508.\n",
      "    4.8        101.6          1.        ]\n",
      " [799.31034483 495.3         37.44827586  35.814      558.8\n",
      "   71.12        93.98       154.559        3.         508.\n",
      "    5.5        495.3          1.        ]\n",
      " [649.         127.2        129.9         31.8        396.\n",
      "   31.8         43.8        268.8          2.          84.8\n",
      "    5.          64.           1.        ]\n",
      " [649.         127.2        129.9         31.8        396.\n",
      "   31.8         43.8        268.8          2.          84.8\n",
      "    5.         127.2          1.        ]\n",
      " [889.65517241 159.766       34.          25.4        426.72\n",
      "   71.12       177.8        104.14         3.         260.35\n",
      "    5.1         76.2          1.        ]\n",
      " [606.         559.          45.8         43.         344.\n",
      "   43.          56.         172.           2.         272.66666667\n",
      "    5.         559.           1.        ]\n",
      " [583.         573.          76.9         57.3        584.46\n",
      "   57.3         56.         355.26         2.         289.\n",
      "    5.         573.           1.        ]]\n"
     ]
    }
   ],
   "source": [
    "X_test_unscaled = scX.inverse_transform(X_test_scaled)  # scaler.inverse_transform(): scaling을 환원(unscaling)\n",
    "print(X_test_unscaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0449 - MAE: 0.0449\n",
      "test loss, test MAE: [0.044938985258340836, 0.044938985258340836]\n"
     ]
    }
   ],
   "source": [
    "score = model_1.evaluate(X_test_scaled, y_test_scaled)\n",
    "print(\"test loss, test MAE:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9097926641021887"
      ]
     },
     "execution_count": 734,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test_unscaled, y_p_unscaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10085150692422437\n"
     ]
    }
   ],
   "source": [
    "division = y_p_unscaled/y_test_unscaled\n",
    "cov = np.std(division) / np.mean(division)\n",
    "print(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 모델의 저장\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "model_1.save(\"modelsave/Model\"+ str(now.month) + str(now.day) + str(now.hour) + str(now.minute)+ \"file.h5\")\n",
    "plt.savefig(\"modelsave/Model\"+ str(now.month) + str(now.day) + str(now.hour) + str(now.minute)+ \"file.jpg\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
